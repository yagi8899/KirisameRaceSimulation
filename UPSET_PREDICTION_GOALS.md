# 穴馬予測モデル 目標設定ドキュメント

**作成日**: 2026年1月19日  
**最終更新**: 2026年1月21日  
**精査・改訂**: 2026年1月21日（収支観点での目標再設定、競馬場別改善案追加）

---

## 📋 目的

競馬予測モデルにおいて、**7-12番人気の馬（穴馬）が3着以内に入ることを高精度で予測する**ことを目指す。
従来のランキング学習（相対順位予測）に加えて、**穴馬検出**に特化した予測能力を強化し、高配当獲得の可能性を高める。

**重要**: 最終目標は「Precisionを上げること」ではなく「**収支をプラスにすること**」である。

---

## ⚠️ ランキング学習と穴馬予測の関係性（重要）

### なぜ通常のランキング学習では穴馬が出にくいのか

本プロジェクトはLightGBMの**LambdaRank（ランキング学習）**を使用しており、これは本質的に：

> **「上位に来る確率が高い馬」を正しく並べる**

評価指標もNDCG / MAP / Hit@k など、**「人気馬を安定して当てる」方向に最適化される**。

つまり：
- **穴馬** = 勝率は低いが、オッズが高い
- **ランキング学習** = 勝率（または着順期待値）重視

👉 **この2つは目的がズレている**

そのため「的中率はそこそこ、回収率が伸びない」という症状はほぼ必然。

### それでも「可能」と言える理由

重要なのは：

> ランキング学習 = 着順を学習するもの、**ではない**  
> **「任意のスコア順序」を学習できる枠組み**

という点。

つまり、
- 「期待回収率が高い順」
- 「オッズに対して過小評価されている順」

こうした**歪んだ順位**を正解として与えれば、ランキング学習でも穴馬志向にできる。

**ただし、本プロジェクトでは以下の理由から段階的アプローチを採用**：
1. **現状の設計**：着順スコア（18 - 着順 + 1）をラベルとして使用
2. **オッズの扱い**：速報予測対応のため、意図的にオッズを特徴量から除外
3. **実装戦略**：オッズを使わずに実力を予測 → オッズとの乖離を後処理で計算

---

## 📊 現状分析（過去10年データ：2016-2026年）

### ベースライン（ランダム選択時の期待値）

| 人気帯 | 3着以内率 | 出走回数 | 1着率 |
|--------|----------|---------|--------|
| 1番人気 | 70.26% | 56,008 | 39.14% |
| 2-3番人気 | 50.09% | 111,999 | 16.24% |
| 4-5番人気 | 30.45% | 111,942 | 7.39% |
| 6-9番人気（中穴） | 14.16% | 214,650 | 2.91% |
| **10番人気以下（大穴）** | **4.35%** | **200,126** | **0.81%** |

### 重要な発見

1. **年度別の安定性**
   - 10番人気以下の3着以内率は**4.1〜4.7%**で推移（予測可能性あり）
   - 2016年: 4.40% → 2025年: 4.30%（安定）

2. **競馬場別の差異**
   - 最高: **函館 6.10%**（穴が出やすい）
   - 次点: 小倉 5.32%、札幌 5.25%
   - 最低: 東京 3.98%、中山 4.07%（堅い傾向）
   - **函館は東京の1.5倍**穴が出る

3. **路面×距離別の傾向**
   - 芝右短距離: **5.41%**（高め）
   - ダート左長距離: 9.52%（サンプル少ない）
   - ダート右短距離: 3.94%（低め）

---

## 🎯 穴馬の定義

本プロジェクトにおける「穴馬」の定義：

| 分類 | 人気帯 | ベースライン3着以内率 | 対象 |
|------|--------|---------------------|------|
| **大穴（メイン目標）** | **10番人気以下** | **4.35%** | ✅ 主目標 |
| 中穴（サブ目標） | 6-9番人気 | 14.16% | 補助目標 |
| 超大穴（参考） | 13番人気以下 | 約2.5% | 高リスク |

**採用理由**:
- 10番人気以下は母数が十分（年間約2万頭）
- 複勝平均配当が3.5〜5.0倍程度（高配当期待）
- 年度・条件による変動が比較的安定

---

## 📈 評価指標（KPI）

### ⚠️ 収支観点での重要な考え方

**Precisionだけを追求してはいけない理由**:

```
期待収支 = (TP × 平均配当) - (候補数 × 購入単価)
         = 候補数 × (Precision × 平均配当 - 購入単価)
```

| Precision | 候補数 | TP | 複勝収支(350円) | 判定 |
|-----------|--------|-----|-----------------|------|
| 10% | 2000 | 200 | -130,000円 | ❌ 赤字 |
| 10% | 500 | 50 | -32,500円 | ❌ 赤字（損失小） |
| 15% | 1000 | 150 | -47,500円 | ❌ 赤字 |
| 28.6% | 1000 | 286 | ±0円 | ⚖️ 損益分岐点 |

**⚠️ 28.6%は「複勝100円購入・平均配当350円」の場合の損益分岐点**

損益分岐点は平均配当によって変わる：

| 平均配当 | 損益分岐Precision | 備考 |
|----------|-------------------|------|
| 350円 | 28.6% | 人気馬の複勝相当 |
| 500円 | 20.0% | 中穴の複勝 |
| 700円 | 14.3% | 穴馬の複勝 |
| 1000円 | **10.0%** | 大穴の複勝 |
| 2000円 | 5.0% | 単勝相当 |
| 5000円 | 2.0% | 馬連相当 |

**重要**: 7-12番人気の穴馬の複勝配当は350円より高いことが多いため、実際の損益分岐点はもっと低い可能性がある。

---

### 🎯 性能の良いモデルの目標値

馬券戦略によって目指すべき数値が異なる：

#### 複勝戦略の場合

穴馬（7-12番人気）の複勝平均配当を**700円**と仮定した場合：

| 指標 | 最低ライン | 良好 | 理想 |
|------|-----------|------|------|
| **Precision** | 14.3%（損益分岐） | 18-20% | 25%以上 |
| **Recall** | 30%以上 | 40-50% | 50-60% |
| **F1** | 18以上 | 22-25 | 28以上 |

#### 高配当馬券戦略（馬連・3連複）の場合

穴馬を「相手」として使い、軸馬との組み合わせで高配当を狙う戦略：

| 指標 | 最低ライン | 良好 | 理想 |
|------|-----------|------|------|
| **Precision** | 8%以上 | 10-12% | 15%以上 |
| **Recall** | 40%以上 | 50-60% | 60-70% |
| **F1** | 12以上 | 16-20 | 22以上 |

**この戦略のポイント**:
- Precisionは10%程度でも、高配当馬券なら十分黒字化可能
- Recallを高めに保ち、収益機会を逃さない
- 候補数が多くても、馬連・3連複なら1点あたりのコストを抑えられる

#### 推奨: バランス型（現実的な目標）

| 指標 | 目標値 | 理由 |
|------|--------|------|
| **Precision** | **12-15%** | 複勝でも損失縮小、高配当なら黒字 |
| **Recall** | **45-55%** | 約半数の穴馬を検出、候補数適正 |
| **F1** | **18-22** | バランスの良さの指標 |

---

### 主要指標: Precision（適合率）

> モデルが「3着以内に来る」と予測した穴馬のうち、実際に的中した割合

$$
\text{Precision} = \frac{\text{予測的中数}}{\text{予測総数}} \times 100
$$

**例**: 100頭の穴馬を「3着以内」と予測し、10頭が実際に3着以内に入った場合 → **Precision 10%**

### 副次指標: Recall（再現率）

> 実際に3着以内に来た穴馬のうち、モデルが事前に予測できた割合

$$
\text{Recall} = \frac{\text{予測的中数}}{\text{実際の3着以内穴馬数}} \times 100
$$

**⚠️ Recallが高すぎる場合の問題**:
- Recall 90%超 → ほぼ全ての穴馬を候補にしている → 選別能力がない
- 候補数が増える → 購入コストが増加 → 損失拡大

**⚠️ Recallが低すぎる場合の問題**:
- Recall 30%未満 → 収益機会の7割を逃している
- 候補数が少なすぎる → 的中時のリターンが小さい

**Recallの適正範囲**: 馬券戦略により異なるが、**40〜60%**を目安とする

### 補助指標: F1スコア

$$
\text{F1 Score} = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}
$$

**F1スコアの目安**:
- 15未満: 改善が必要
- 15-20: 基本性能達成
- 20-25: 良好なモデル
- 25以上: 優秀なモデル

### 実運用指標: ROI（回収率）

複勝馬券での期待回収率（平均配当別）：

| Precision | 配当350円 | 配当500円 | 配当700円 | 配当1000円 |
|-----------|----------|----------|----------|-----------|
| 8% | 28% | 40% | 56% | 80% |
| 10% | 35% | 50% | 70% | **100%** ✅ |
| 12% | 42% | 60% | 84% | 120% ✅ |
| 15% | 52% | 75% | **105%** ✅ | 150% ✅ |

**結論**: 穴馬の平均配当が高ければ、**Precision 10-15%でも黒字化は十分可能**。

---

## 🎯 目標値設定

### ⚠️ 目標設定の考え方（2026年1月21日更新）

**現実的な認識**:
1. 複勝単体でのROI 100%超えは困難（損益分岐点 Precision 28.6%）
2. Phase 1-3は「損失縮小」フェーズであり、黒字化フェーズではない
3. 黒字化には高配当馬券との組み合わせ戦略が必須

**目標の位置づけ**:
- **Precision**: 予測精度の向上 → 損失率の低減
- **Recall**: 適正範囲（40-60%）を維持 → 候補数の適正化
- **候補数**: 少なすぎず多すぎず → コスト管理

---

### Phase 1: 基礎モデル（3ヶ月目標）✅ 達成済み

| 指標 | 目標値 | ベースライン比 | 優先度 | 現状 |
|------|--------|---------------|--------|------|
| **Precision** | **8.0%以上** | 1.8倍 | 🔥 最重要 | ✅ 10.30% |
| Recall | **40-70%** | - | ⭐ 重要 | ✅ 45.90% |
| 候補数/レース | 1-3頭 | - | コスト管理 | ✅ 適正 |
| 予測件数 | 年間1,000件以上 | - | 実用性確保 | ✅ |

**達成基準**:
- テストデータでPrecision 8%を安定して達成
- Recallが70%を超えない（候補数の抑制）
- 全競馬場で4%以上（ベースライン未満にならない）

---

### Phase 2: 実用モデル（6ヶ月目標）

| 指標 | 目標値 | ベースライン比 | 優先度 |
|------|--------|---------------|--------|
| **Precision** | **10.0%以上** | 2.3倍 | 🔥 最重要 |
| Recall | **40-60%** | - | ⭐ 重要 |
| 候補数/レース | 1-2頭 | - | コスト管理 |
| Top10%予測のPrecision | 15%以上 | 3.5倍 | 高精度層 |

**達成基準**:
- 全体でPrecision 10%達成
- Recallが60%を超えない（閾値調整で制御）
- 穴が出やすい条件（函館、小倉、芝右短距離）で12%以上

---

### Phase 3: 高精度モデル（1年目標）

| 指標 | 目標値 | ベースライン比 | 優先度 |
|------|--------|---------------|--------|
| **Precision** | **12.0%以上** | 2.8倍 | 🔥 最重要 |
| Recall | **35-55%** | - | バランス |
| Top10%予測のPrecision | **18%以上** | 4.1倍 | 超高精度層 |
| Top5%予測のPrecision | **25%以上** | 5.7倍 | 厳選予測 |

**達成基準**:
- 競馬場×路面×距離の組み合わせで個別最適化
- 信頼度スコアによる階層化（Top5%, Top10%, Top25%）
- **馬連・3連複戦略と組み合わせてROI 80%以上**

---

### Phase 4: 収益化モデル（長期目標）

| 指標 | 目標値 | 備考 |
|------|--------|------|
| **複勝ROI** | 50%以上 | 損失半減 |
| **馬連ROI** | 80%以上 | 高配当活用 |
| **3連複ROI** | 90%以上 | 穴馬×軸馬の組み合わせ |
| **総合ROI** | **100%以上** | 黒字化達成 |

**戦略**:
- 穴馬予測を「相手」として活用（軸は人気馬）
- 高配当馬券で的中時のリターンを最大化
- 候補数を絞り、購入コストを抑制

---

## 🏇 条件別目標（Phase 2以降）

### 競馬場別目標

| 競馬場 | ベースライン | Phase 2目標 | Phase 3目標 | 戦略 |
|--------|------------|------------|------------|------|
| 函館 | 6.10% | 12% | 15% | 積極的予測 |
| 小倉 | 5.32% | 11% | 14% | 積極的予測 |
| 札幌 | 5.25% | 11% | 14% | 積極的予測 |
| 新潟 | 4.88% | 10% | 12% | 標準 |
| 京都 | 4.56% | 9% | 11% | 標準 |
| 阪神 | 4.31% | 9% | 11% | 標準 |
| 中京 | 4.25% | 9% | 11% | 標準 |
| 中山 | 4.07% | 8% | 10% | 慎重 |
| 東京 | 3.98% | 8% | 10% | 慎重 |

### 路面×距離別目標

| 路面種別 | 距離区分 | ベースライン | Phase 2目標 | 備考 |
|---------|---------|------------|------------|------|
| 芝右 | 短距離 | 5.41% | 11% | 穴が出やすい |
| 芝左 | 長距離 | 5.61% | 11% | サンプル少 |
| ダート右 | マイル | 4.46% | 9% | 標準 |
| ダート左 | マイル | 4.45% | 9% | 標準 |
| 芝左 | マイル | 3.75% | 8% | 堅い |
| ダート右 | 短距離 | 3.94% | 8% | 堅い |

---

## 🔧 実現戦略

### 現状のモデル設計（検証済み）

**使用中の設定**:
- ✅ **モデル**: LightGBM Ranker（LambdaRank）
- ✅ **ラベル**: 反転着順スコア（18 - 着順 + 1）
- ✅ **評価指標**: NDCG@5（学習時）、的中率・回収率（テスト時）
- ✅ **オッズ**: 特徴量として使用していない（速報予測対応のため）
- ❌ **人気帯別分割**: なし（全人気帯を同一モデルで学習）

**既存の強み**:
- ✅ `relative_ability`（SHAP値1位）でレース内格差を捉える
- ✅ `right_direction_score`（京都で2位）でトラック適性を捉える
- ✅ LambdaRank（ランキング学習）で順位予測が強力
- ✅ オッズを使わない設計で速報予測に対応可能

**現状の課題**:
- ❌ 目的関数がLambdaRank → 上位予測に最適化、穴馬検出には不向き
- ❌ 人気帯別モデル分割なし → 穴馬サンプルが希薄化
- ❌ Precision/Recallの未評価 → 穴馬予測の適合率を監視できていない
- ❌ 学習時の重み付けなし → 穴馬的中を重視した学習ができていない

---

### 穴馬予測強化策（理論的に妥当なアプローチ）

#### 戦略1: オッズを使わない実力予測 + 後処理での乖離検出

**方針**:
```
学習時：オッズなしで予測スコアを出す（現状維持）
　　　　↓
推論時：予測順位と人気順位の乖離を計算
　　　　↓
穴馬候補：乖離が大きい馬を抽出
```

**実装例**:
```python
# 学習時：オッズなしで予測スコアを出す
predicted_score = model.predict(X)
predicted_rank = rankdata(-predicted_score, method='ordinal')

# 推論時：オッズとの乖離を計算
popularity_rank = df['tansho_ninkijun_numeric'].values
value_gap = predicted_rank - popularity_rank  # 負の値 = 過小評価

# 過小評価馬を抽出（予測順位 << 人気順位）
df['is_value_bet'] = (value_gap < -3) & (predicted_rank <= 3)
```

**メリット**:
- ✅ 速報予測に対応可能（オッズ未確定でも予測できる）
- ✅ オッズの逆順を学習する問題を回避
- ✅ 市場の歪み（人気と実力の乖離）を直接利用

---

#### 戦略2: 二段階モデル構成

**方針**:
```
第1段階：既存ランキングモデル（全体順位予測）
　　　　　↓
第2段階：穴馬検出モデル（10番人気以下に特化した二値分類）
```

**第2段階モデルの設計**:
- **目的変数**: 3着以内=1、4着以下=0（二値分類）
- **入力特徴量**: 第1段階の予測スコア + 穴馬特化特徴量
- **学習対象**: 10番人気以下の馬のみ
- **モデル**: LightGBM Classifier（binary classification）

**実装例**:
```python
# 第1段階：ランキング予測
ranking_score = ranker_model.predict(X)

# 第2段階用のデータ準備（10番人気以下のみ）
upset_candidates = df[df['tansho_ninkijun_numeric'] >= 10].copy()
upset_candidates['ranking_score'] = ranking_score

# 第2段階：穴馬検出（二値分類）
X_upset = upset_candidates[feature_columns + ['ranking_score']]
y_upset = (upset_candidates['kakutei_chakujun_numeric'] <= 3).astype(int)
classifier_model.fit(X_upset, y_upset)
```

**メリット**:
- ✅ 人気馬と穴馬を別の土俵で評価（サンプル不均衡を回避）
- ✅ 穴馬専用の特徴量を追加可能
- ✅ Precision/Recallで評価しやすい

---

#### 戦略3: ラベル設計の変更（オプション・Phase 2以降）

**問題点**:
現状のラベル（反転着順スコア）は「順位を当てる」に最適化されており、「回収を最大化する」には不向き。

**改善案**:
```python
# オプション1: 対数変換付きオッズ重み
label = log(min(odds, 30)) * win_flag

# オプション2: 回収期待値
label = odds * win_flag / theoretical_win_rate

# オプション3: クラス別重み付け
sample_weight = np.where(popularity_rank >= 10, 3.0, 1.0)
```

**注意点**:
- ⚠️ ラベルの分散が極端に大きくなり学習が不安定になるリスク
- ⚠️ 対数変換やキャップで安定化が必要
- ⚠️ 速報予測への影響を検証する必要あり

**実装タイミング**: Phase 2以降、基礎モデルが安定してから

---

#### 戦略4: 人気帯別モデル分割

**方針**:
```
モデルA：1-5番人気専用（堅実予測）
モデルB：6-9番人気専用（中穴予測）
モデルC：10番人気以下専用（大穴予測）
```

**課題と対策**:
| 課題 | 対策 |
|------|------|
| 10番人気以下の3着以内率は約8-10%（正例が少ない） | SMOTEなどのオーバーサンプリング |
| 過学習しやすい | 早期終了、正則化強化 |
| サンプル数不足 | 複数年のデータをプール |

**実装タイミング**: Phase 2以降、データ不均衡対策とセットで実装

---

#### 戦略5: 二段階評価（学習時NDCG + 選択時回収率）

**方針**:
```
学習時の目的関数：NDCG（微分可能である必要）
　　　　↓
早期終了の判定：仮想ベット回収率シミュレーション
　　　　↓
モデル選択：回収率で最良モデルを選択
```

**実装例**:
```python
# カスタムコールバック：回収率で早期終了
def回収率_callback(env):
    predictions = model.predict(X_valid)
    roi = calculate_roi(predictions, y_valid, odds_valid)
    if roi > best_roi:
        best_roi = roi
        best_iteration = env.iteration
    return env.iteration - best_iteration > 50  # 50回改善なければ停止

model.fit(X_train, y_train, callbacks=[回収率_callback])
```

**メリット**:
- ✅ 学習は従来通りNDCG最適化
- ✅ モデル選択は回収率で判断
- ✅ 過学習を防ぎつつ実運用性能を確保

---

### 穴馬特化特徴量の追加

1. **人気と実力の乖離度**
   - `relative_ability` vs `tansho_ninkijun_numeric`の差分
   - レース内での相対的な評価ギャップ

2. **クラス降級フラグ**
   - `class_score_change`が負（クラスダウン）
   - 降級馬は穴馬候補の代表例

3. **休養明け×実力馬**
   - `kyuyo_kikan` × `relative_ability`の相互作用
   - 実力馬の休養明けは狙い目

4. **競馬場適性×人気薄**
   - `right_direction_score` × 人気度
   - 適性が高いのに人気がない馬

5. **成績の不安定性（NEW）**
   - `past_score_std`（標準偏差）
   - ムラっ気のある馬 = 当たればデカい

**詳細は [UPSET_PREDICTION_FEATURES.md](UPSET_PREDICTION_FEATURES.md) を参照**

---

### 閾値最適化

- **信頼度スコアによる階層化**（Top5%, Top10%, Top25%）
- **競馬場別の動的閾値調整**（函館は緩く、東京は厳しく）
- **条件別の最適化**（芝右短距離、ダート左長距離など）

---

## 📊 データ戦略

- **訓練データ**: 2016-2022年（約14万レース）
- **検証データ**: 2023年（約2万レース）
- **テストデータ**: 2024-2025年（約3.5万レース）

**重点サンプリング**:
- 穴馬の3着以内ケースを重点的に学習（SMOTE等）
- 競馬場×条件別に層別サンプリング

---

## 🔍 評価プロセス

1. **週次評価**: 2024-2025年データでPrecision/Recallをモニタリング
2. **月次評価**: 条件別の精度を確認し、弱点を特定
3. **四半期評価**: Phase目標達成度を確認し、戦略を調整

---

## 📅 ロードマップ

### Month 1-3: Phase 1（基礎モデル構築） ✅ **完了**

- [x] 穴馬検出用特徴量の実装（人気乖離度、クラス降級など）
- [x] 二段階モデルの設計と実装
- [x] 2024-2025年データでPrecision 6.83%達成
- [x] 競馬場別のベースライン精度確認
- [x] Walk-Forward Validation統合完了

**成果**: Precision 6.83%, Recall 80.39%, F1 12.62%（目標8%は未達）

---

### Month 1-3: Phase 1.5（SQL特徴量拡張） 🔧 **実装中**

**2026年1月20日開始**

- [ ] SQL穴馬特化特徴量の実装（フェーズ1・6特徴量）
  - [ ] `past_score_std` - 成績ムラで穴馬検出
  - [ ] `past_chakujun_variance` - 着順ムラで穴馬検出
  - [ ] `zenso_oikomi_power` - 追い込み力で展開依存検出
  - [ ] `kishu_changed` - 騎手変更で厩舎本気度検出
  - [ ] `class_downgrade` - クラス降級で実力差検出
  - [ ] `zenso_kakoi_komon` - 前走包まれで不利検出
- [ ] db_query_builder.py更新（訓練・速報両方）
- [ ] feature_engineering.py更新
- [ ] 穴馬分類器の再訓練
- [ ] Walk-Forward再実行・Precision再評価
- [ ] **Precision 8.0%以上達成**

**目標**: Precision 7.5-8.5%、Recall 70-80%

---

### Month 4-6: Phase 2（実用モデル最適化）

- [ ] SQL特徴量フェーズ2（必要に応じて4特徴量追加）
  - [ ] `zenso_agari_rank` - 前走上がり最速検出
  - [ ] `zenso_agari_gap` - 上がり良いのに負けた馬検出
  - [ ] `avg_oikomi_power` - 平均追い込み力
  - [ ] `kyuyo_after_bad_race` - 休養明けの立て直し
- [ ] 信頼度スコアの導入（Top10%で15%達成）
- [ ] 競馬場×条件別の個別モデル調整
- [ ] 函館・小倉でPrecision 12%達成
- [ ] 馬券戦略シミュレーション（複勝・馬連）

**成功基準**: Precision 10.0%以上、条件別12%以上

---

### Month 7-12: Phase 3（高精度化とROI最適化）

- [ ] SQL特徴量フェーズ3（効果検証後に判断）
  - [ ] 条件別複雑集計（turf_vs_dirt_gap等）
  - [ ] 厩舎・騎手統計（chokyoshi_upset_rate等）
- [ ] Top5%予測でPrecision 25%達成
- [ ] 単勝・3連複との組み合わせ戦略
- [ ] Walk Forward Validationでの安定性確認
- [ ] リアルタイム予測システムの構築

**成功基準**: Precision 12.0%以上、Top5%で25%、ROI 80%以上

---

## 📊 進捗管理

### 現在の状況（2026年1月20日）

**Phase 1完了実績**:
- [x] 過去10年データの分析完了
- [x] ベースライン（4.35%）の確認
- [x] 目標設定完了
- [x] 二段階モデル（Universal Ranker + 穴馬分類器）実装完了
- [x] Walk-Forward Validation統合完了
- [x] Precision 6.83%, Recall 80.39%達成（目標8%未達）
- [x] 閾値最適化完了（threshold=0.0005が最適）

**Phase 1.5開始**（SQL特徴量拡張）:
- [x] UPSET系ドキュメント3種の確認完了
- [x] 未実装特徴量15個を特定
- [x] SQL実装方針決定（速報予測対応のため）
- [x] 優先順位再編成（3フェーズに分類）
- [ ] 実装開始

### 次のアクション（Week 1-2）

1. **🔥 競馬場別改善特徴量の実装（Phase 1.6・最優先）**
   - `feature_engineering.py` に `track_upset_score` 追加
   - `db_query_builder.py` に `num_runners`（出走頭数）追加
   - 穴馬分類器再訓練 → 全競馬場Precision 10%目標

2. **SQL穴馬特化特徴量の実装**（フェーズ1・6特徴量）
   - `db_query_builder.py` の `build_race_data_query()` 関数にWINDOW関数・LAG追加
   - `build_sokuho_race_data_query()` にも同じロジック追加（速報予測対応）
   - past_score_std, past_chakujun_variance, zenso_oikomi_power, kishu_changed, class_downgrade, zenso_kakoi_komon

2. **feature_engineering.py更新**
   - `create_universal_features()` 関数に新特徴量の取り込みコード追加
   - fillna処理とデータ型検証

3. **再訓練・評価パイプライン**
   - `upset_classifier_creator.py` 再実行
   - `walk_forward_validation.py --config walk_forward_config_2026.json` 再実行
   - `calculate_precision_recall.py` でPrecision/Recall再計算
   - **目標: Precision 8.0%以上達成**

4. **フェーズ2判断**
   - Precision 8%達成 → Phase 2へ進む
   - Precision 8%未達 → フェーズ2特徴量（zenso_agari_rank等4個）を追加実装

---

## 📝 注意事項

### 🚨 競馬場別の課題と改善案（2026年1月21日追加）

#### 現状の問題点

| 競馬場 | 穴馬率 | 現状Precision | 目標達成 | 課題 |
|--------|--------|--------------|---------|------|
| **小倉** | 10.84% | 11.36% | ✅ Phase2達成 | - |
| **函館** | 10.87% | 11%+ | ✅ Phase2達成 | - |
| 京都 | 9.33% | 9.31% | ❌ | 10%未達 |
| 中山 | 9.32% | 9.10% | ❌ | 10%未達 |
| **東京** | 9.25% | 8.41% | ❌ | **最も改善困難** |

**根本原因**: 競馬場の特性を表す特徴量が `is_local_track`（二値フラグ）しかない

→ モデルは「東京・中山・京都・阪神は全部同じ」と認識している

#### 閾値調整の限界

分析の結果、**閾値調整だけでは主要場でPrecision 10%は達成不可能**：

| 競馬場 | 最高Precision | その時のRecall | 達成可能性 |
|--------|--------------|----------------|-----------|
| 小倉 | 11.62% (閾値0.10) | 90.65% | ✅ 閾値0.40で10.88%/Recall50% |
| 京都 | 10.20% (閾値0.15) | 93.49% | ⚠️ 10%超えるとRecall高すぎ |
| **中山** | 9.95% (閾値0.10) | 96.94% | ❌ どの閾値でも10%未満 |
| **東京** | 8.92% (閾値0.20) | 91.59% | ❌ どの閾値でも9%未満 |

**結論**: 全競馬場でPrecision 10%以上を達成するには、**モデル改修が必須**

---

#### 🎯 改善案（優先度順）

##### 🥇 1. 競馬場別穴馬傾向スコアの追加（即効性：高）

現在の `is_local_track`（0/1）を連続値スコアに置き換える：

**⚠️ リーク防止**: 固定値ではなく、**SQLで訓練データから動的に計算**する

```sql
-- 競馬場別穴馬率を訓練期間のデータのみから計算
-- db_query_builder.py で実装
WITH track_upset_stats AS (
    SELECT 
        keibajo_code,
        COUNT(*) as total_count,
        SUM(CASE WHEN ninkijun >= 7 AND ninkijun <= 12 AND kakutei_chakujun <= 3 THEN 1 ELSE 0 END) as upset_count,
        SUM(CASE WHEN ninkijun >= 7 AND ninkijun <= 12 THEN 1 ELSE 0 END) as upset_candidate_count
    FROM race_data
    WHERE kaisai_date < :prediction_date  -- 予測対象日より前のデータのみ
    GROUP BY keibajo_code
)
SELECT 
    keibajo_code,
    COALESCE(upset_count * 1.0 / NULLIF(upset_candidate_count, 0), 0.10) as track_upset_rate
FROM track_upset_stats
```

```python
# feature_engineering.py で特徴量化
# 穴馬率を0-1にスケーリング（最大値で割る）
df['track_upset_score'] = df.groupby('keibajo_code')['track_upset_rate'].transform(
    lambda x: (x - x.min()) / (x.max() - x.min() + 1e-6)
)
```

**効果**: モデルが「東京は穴馬が来にくい」ことを学習できる（リークなし）

| 実装難易度 | 期待効果 | 推奨度 |
|-----------|---------|-------|
| 中（SQL修正） | 高 | ⭐⭐⭐ |

---

##### 🥈 2. 出走頭数の特徴量追加（即効性：中〜高）

SQLには `ra.shusso_tosu` が存在するが、特徴量化されていない：

```python
'num_runners'      # レース出走頭数（連続値）
'is_full_field'    # フルゲート（16頭以上）フラグ
```

**仮説**: 
- 多頭数 → 混戦 → 穴馬有利
- 少頭数 → 実力通り → 人気馬有利

| 実装難易度 | 期待効果 | 推奨度 |
|-----------|---------|-------|
| 低（SQL修正） | 中〜高 | ⭐⭐⭐ |

---

##### 🥉 3. 主要場の個別フラグ追加（即効性：中）

二値フラグを個別フラグに分解：

```python
'is_tokyo'         # 東京競馬場（最も堅い）
'is_nakayama'      # 中山競馬場
'is_kyoto'         # 京都競馬場
'is_hanshin'       # 阪神競馬場
'is_major_track'   # 東京/中山/京都/阪神
```

**効果**: 競馬場ごとの個別学習が可能になる

| 実装難易度 | 期待効果 | 推奨度 |
|-----------|---------|-------|
| 低 | 中 | ⭐⭐ |

---

##### 🏅 4. 距離×路面の細分化フラグ（効果：検証済み）

提案書（UPSET_PREDICTION_FEATURES.md）に記載済みだが未実装：

```python
'is_turf_sprint'   # 芝短距離 (+1.81%期待)
'is_turf_long'     # 芝長距離 (+1.71%期待)
'is_dirt_sprint'   # ダート短距離 (-0.83%、穴馬不利を検出)
```

| 実装難易度 | 期待効果 | 推奨度 |
|-----------|---------|-------|
| 低 | 中 | ⭐⭐ |

---

##### 5. 競馬場別モデル分離（中長期）

主要場専用モデル / ローカル専用モデルの分離：

```
モデルA：ローカル（札幌, 函館, 福島, 小倉）
モデルB：主要場（東京, 中山, 京都, 阪神, 中京, 新潟）
```

| 実装難易度 | 期待効果 | 推奨度 |
|-----------|---------|-------|
| 高 | 高 | ⭐（後回し） |

---

#### 📊 改善案の実装優先度マトリクス

| 改善案 | 難易度 | 効果 | 所要時間 | 優先度 |
|--------|--------|-----|---------|-------|
| 競馬場穴馬スコア | 低 | 高 | 1時間 | 🔥 最優先 |
| 出走頭数 | 低 | 中〜高 | 2時間 | 🔥 最優先 |
| 個別競馬場フラグ | 低 | 中 | 1時間 | ⭐ 次点 |
| 距離×路面フラグ | 低 | 中 | 1時間 | ⭐ 次点 |
| 競馬場別モデル分離 | 高 | 高 | 1日+ | 後回し |

---

#### 🎯 次のアクション（Phase 1.6: 競馬場別改善）

1. **feature_engineering.py** に `track_upset_score` 特徴量を追加
2. **db_query_builder.py** に出走頭数（`num_runners`）を追加
3. 穴馬分類器を再訓練
4. Walk-Forward再実行で効果検証
5. **目標: 全競馬場でPrecision 10%以上達成**

---

## 🔥 Phase 1.7: 芝/ダート分離＋SQL特徴量強化（2026年1月22日）

**追加日**: 2026年1月22日  
**目的**: 芝/ダートで異なる傾向を持つ穴馬を別々にモデル化し、条件特化の特徴量を追加

### 背景

芝/ダート分離モデル実装後の検証結果（2024年データ）：

| 区分 | Precision | Phase 1 (8%) | 課題 |
|------|-----------|--------------|------|
| **芝** | **11.71%** | ✅達成 | Phase 3目標あと0.3% |
| **ダート** | **7.89%** | ❌未達成 | 特徴量改善が必要 |

**競馬場×芝ダの詳細**:
| 競馬場 | 芝 Precision | ダート Precision |
|--------|-------------|-----------------|
| 小倉 | **12.76%** ✅ | 10.15% ✅ |
| 東京 | **9.83%** ✅ | 6.83% ❌ |

### 実装する特徴量（SQL側で算出）

#### Phase 1.7.1: 馬場状態関連（最優先・芝に効果大）

| 特徴量 | 計算方法 | 期待効果 |
|--------|----------|----------|
| `is_turf_bad` | 芝×(重/不良) | **+2.0〜3.35%** |
| `is_turf_heavy` | 芝×重 | +1.73% |
| `is_turf_bad_condition` | 芝×不良 | +3.35% |
| `baba_upset_score` | 路面×馬場状態の正規化スコア | +1% |

#### Phase 1.7.2: 競馬場・クラス関連

| 特徴量 | 計算方法 | 期待効果 |
|--------|----------|----------|
| `is_local_track` | 札幌/函館/福島/小倉 | +1.47% |
| `is_open_class` | OPクラス | +2.38% |
| `is_3win_class` | 3勝クラス | +2.22% |
| `is_2win_class` | 2勝クラス | +1.72% |

#### Phase 1.7.3: 馬齢・前走関連

| 特徴量 | 計算方法 | 期待効果 |
|--------|----------|----------|
| `is_age_prime` | 4-5歳 | +1.50% |
| `is_age_old` | 8歳以上（負の影響） | -2.9% |
| `zenso_top6` | 前走6着以内 | +1.82% |
| `is_maiden` | 未勝利戦（負の影響） | -0.9% |

### 実装計画

1. **db_query_builder.py**: SQLで上記特徴量を算出（訓練＋速報両対応）
2. **feature_engineering.py**: 新特徴量の取り込み処理
3. **walk_forward_validation.py**: 芝/ダート分離モデル再訓練
4. **検証**: `calculate_precision_recall.py --by-surface`

### 成功基準

- **芝**: Precision 12%以上（Phase 3達成）
- **ダート**: Precision 8%以上（Phase 1達成）
- **全体**: Precision 10%以上（Phase 2達成）

---

### モデルの限界

- **複勝だけでは利益確保困難**: ROI 100%超えには非現実的な精度（Precision 29%）が必要
- **サンプル不足の条件**: 芝左長距離など母数が少ない条件では精度が不安定
- **オッズ変動**: 予測公開によるオッズ下落リスク（実運用時の課題）

### リスク管理

- **過学習の防止**: Walk Forward Validationで未来データへの汎化性能を確認
- **ドリフト監視**: 年度による傾向変化（ルール改正、馬場改修）を継続監視
- **条件別評価**: 全体精度だけでなく、条件別の偏りを常にチェック

---

## � Phase 1.8: 確率校正問題の発見と対策（2026年1月22日）

### 発見された深刻な問題

2024年東京・小倉データ（7996件）で穴馬検出モデルを分析した結果、**モデル出力が確率として全く校正されていない**ことが判明。

#### 問題1: 閾値を上げてもPrecisionが上がらない

| 閾値 | 候補数 | TP | Precision | Recall | 判定 |
|------|--------|-----|-----------|--------|------|
| 0.05 | 1607 | 169 | 10.52% | 56.71% | - |
| 0.10 | 1567 | 164 | 10.47% | 55.03% | ⚠️ Both DOWN |
| 0.20 | 1446 | 146 | 10.10% | 48.99% | ⚠️ Both DOWN |
| 0.50 | 876 | 75 | 8.56% | 25.17% | ⚠️ Both DOWN |
| 0.70 | 361 | 31 | 8.59% | 10.40% | ⚠️ Both DOWN |

**本来期待される挙動**: 閾値↑ → Precision↑、Recall↓  
**実際の挙動**: 閾値↑ → Precisionほぼ横ばい（むしろ悪化）、Recall↓

#### 問題2: 確率と実際の的中率が完全に乖離

| 確率区間 | 件数 | 実際の穴馬率 | 期待値 | 乖離 |
|----------|------|-------------|--------|------|
| 0.0-0.1 | 1567 | 8.55% | 5% | +3.55% |
| 0.1-0.2 | 121 | 14.88% | 15% | -0.12% |
| 0.2-0.3 | 166 | 12.05% | 25% | **-12.95%** |
| 0.3-0.4 | 185 | 14.59% | 35% | **-20.41%** |
| 0.4-0.5 | 219 | 10.96% | 45% | **-34.04%** |
| 0.5-0.6 | 237 | 9.28% | 55% | **-45.72%** |
| 0.6-0.7 | 278 | 7.91% | 65% | **-57.09%** |
| 0.7-0.8 | 256 | 8.98% | 75% | **-66.02%** |
| 0.8-0.9 | 101 | 7.92% | 85% | **-77.08%** |

**致命的な発見**: 「穴馬確率0.7」と予測された馬の実際の的中率は**8.98%**（70%ではない！）

#### 問題3: リフト値がほぼ1.0

- **ベースライン（ランダム）**: 9.51%
- **モデル（閾値0.10）**: 10.47%
- **リフト値**: 1.10x（ランダムより10%良いだけ）

### 根本原因

LightGBMの`predict_proba()`は**確率ではなくスコア**を出力している：

1. **AUC最適化の副作用**: 相対順位は正しいが、絶対値（確率）は校正されていない
2. **クラス不均衡**: 穴馬率9.5%のデータで学習 → 高確率予測が過剰に出力される
3. **閾値の意味なし**: 0.5の閾値 ≠ 50%の確率

### 以前の校正実装の失敗経験

**過去に実施したこと**:
- Platt Scaling / Isotonic Regressionによる確率校正を実装
- `upset_classifier_creator.py`に`calibrate_probabilities()`関数を追加

**発生した問題**:
- 校正後、ほとんどの馬の確率が0.1未満に収束
- 穴馬候補がほぼ検出されなくなった
- 結果としてRecallが激減（実用的でない）

**原因分析**:
- 校正は「確率を正確にする」ものであり、「識別能力を上げる」ものではない
- 元のモデルの識別能力が低い → 校正しても低いまま
- 穴馬率9.5%のデータで校正 → ほぼ全ての馬が0.1未満に

### 対策方針

#### 方針1: 確率ではなく「相対ランク」ベースで候補選定（推奨）

閾値（0.15など）ではなく、「上位N%」や「レース内順位」で候補を決定：

```python
# 例: 各レースで穴馬確率上位2頭を候補に
df['rank_in_race'] = df.groupby(['race_id'])['穴馬確率'].rank(ascending=False)
df['is_candidate'] = df['rank_in_race'] <= 2
```

**メリット**:
- 確率の絶対値に依存しない
- 各レースで一定数の候補が出る
- 校正不要

#### 方針2: 校正＋フォールバック戦略

校正を実施しつつ、候補が少なすぎる場合のフォールバックを用意：

```python
def get_upset_candidates(df, calibrated_prob, threshold=0.15, min_candidates_per_race=1):
    """
    校正済み確率で候補選定、最低候補数を保証
    """
    # まず校正確率で選定
    df['is_candidate'] = calibrated_prob >= threshold
    
    # 各レースで候補が0頭の場合、最高確率の馬を候補に
    for race_id in df['race_id'].unique():
        race_df = df[df['race_id'] == race_id]
        if race_df['is_candidate'].sum() == 0:
            top_idx = race_df['calibrated_prob'].idxmax()
            df.loc[top_idx, 'is_candidate'] = True
    
    return df
```

#### 方針3: モデル自体の改善（根本対策）

1. **Focal Lossの導入**: クラス不均衡に強い損失関数
2. **アンサンブル**: 複数モデルの予測を統合
3. **特徴量エンジニアリング**: オッズ以外の「過小評価」指標を追加

### 実装計画

| ステップ | 内容 | 所要時間 |
|----------|------|----------|
| 1 | 相対ランクベースの候補選定を実装 | 2時間 |
| 2 | 既存結果を相対ランクで再評価 | 1時間 |
| 3 | 校正＋フォールバック戦略を実装 | 3時間 |
| 4 | 両方式の比較検証 | 2時間 |

### 成功基準

- **候補選定の安定性**: 各レースで1-3頭の候補が出ること
- **Precision維持**: 相対ランク方式でも10%以上を維持
- **実用性**: 「候補なし」レースを10%未満に

### 確認スクリプト

```bash
# Precision/Recallトレードオフの確認
python check_precision_recall_tradeoff.py

# ROI分析
python analyze_roi_by_threshold.py check_results/predicted_results_all.tsv --by-track

# 相対ランク方式の評価
python evaluate_rank_based_selection.py check_results/predicted_results_all.tsv --by-track

# 校正戦略の評価
python evaluate_calibration_strategy.py check_results/predicted_results_all.tsv
```

### 実験結果（2026年1月22日）

#### 相対ランク方式 vs 閾値方式

| 方式 | 候補数 | TP | Precision | Recall | ROI |
|------|--------|-----|-----------|--------|-----|
| **閾値 >= 0.15** | 1529 | 160 | **10.46%** | 53.69% | **-23.8%** |
| 上位2頭/レース | 1113 | 89 | 8.00% | 29.87% | -29.8% |
| 上位3頭/レース | 1659 | 141 | 8.50% | 47.32% | -30.7% |

**結論**: 閾値方式の方がPrecision・ROI共に良い。モデルには識別能力がある。

#### 校正の効果

| 設定 | 候補数 | Precision | 問題 |
|------|--------|-----------|------|
| 校正なし + 閾値0.10 | 1567 | 10.47% | なし |
| 校正なし + 閾値0.15 | 1529 | 10.46% | なし |
| **校正あり + 閾値0.10** | 1739 | **10.81%** | なし |
| 校正あり + 閾値0.12 | 0 | - | **候補0!** |
| 校正あり + 閾値0.15 | 0 | - | **候補0!** |

**結論**: 
- 校正後は全ての馬が0.10-0.12に集中 → 閾値0.12以上で候補0
- これが「以前校正したら穴馬が検出されなくなった」原因
- **校正は不要**。現状の閾値方式で十分

#### 最終推奨

**現状維持**: 校正なし + 閾値0.15（ROI最適化済み）

理由:
1. モデルには識別能力がある（リフト値1.10x、高確率予測の方がマシ）
2. 確率の絶対値は校正されていないが、相対順位は正しい
3. 校正すると候補が激減し実用的でない

---

## 📊 Phase 1.9: FP（偽陽性）分析と特徴量改善

**追加日**: 2026年1月24日  
**実装優先度**: ⭐⭐⭐⭐⭐（最優先）

### 背景: 外部レビューからの指摘

> 「Recallを下げてもPrecisionが上がらない」
> = スコア空間で正例と負例が重なっている
> = **特徴量の情報量不足**の可能性が高い

### FP分析の実行

```bash
python analyze_fp_patterns.py check_results/predicted_results_all.tsv --threshold 0.15
```

### 分析結果（2026年1月24日）

#### 基本統計

| 区分 | 件数 | 割合 |
|------|------|------|
| 全候補 | 1,529 | 100% |
| TP（的中） | 160 | 10.5% |
| FP（外れ） | 1,369 | 89.5% |

#### 発見1: 確率が高いほど当たるわけではない

| 穴馬確率 | TP | FP | TP率 |
|----------|-----|-----|------|
| 0.15-0.20 | 14 | 69 | **16.9%** |
| 0.50-1.00 | 75 | 801 | **8.6%** ← 低い |

**結論**: モデルの確率出力は信頼できない

#### 発見2: 有望な条件の組み合わせ

| 条件 | 候補数 | TP率 | ベースとの差 |
|------|--------|------|-------------|
| **Ranker上位3 & 芝** | 34 | **26.5%** | **+16.0%** |
| Ranker上位5 & 芝 | 92 | 18.5% | +8.0% |
| 7-8番人気 & Ranker上位5 | 112 | 17.9% | +7.4% |
| ベースライン | 1,529 | 10.5% | - |

#### 発見3: オッズ帯による精度差

| オッズ帯 | TP率 |
|----------|------|
| **10-20倍** | **20.6%** |
| 20-30倍 | 16.6% |
| 100倍以上 | 2.6% ← 危険 |

#### 発見4: FPが多い条件（競馬場×芝ダート別）

| 競馬場 | 芝TP率 | ダートTP率 | 備考 |
|--------|--------|-----------|------|
| 小倉 | 12.7% | 11.3% | ほぼ同等 |
| 東京 | 11.9% | **8.4%** | **東京ダートのみ悪い** |

**結論**: 東京ダートのみ悪い傾向（ただし2場のみのテスト結果）

⚠️ **注意**: 現状テスト済みは東京・小倉の2場のみ。残り8場は未知数。

#### 発見5: TP vs FP の特徴量比較

| 特徴量 | TP平均 | FP平均 | 差 |
|--------|--------|--------|-----|
| 単勝オッズ | 39.74 | 66.23 | -26.49 |

**結論**: オッズが高すぎる馬（60倍以上）は外れやすい

### 診断結果

| 項目 | 判定 |
|------|------|
| モデル容量不足？ | NO（LightGBMで十分） |
| **特徴量情報不足？** | **YES**（条件絞りで精度2.5倍改善） |

### 対策方針

#### ⚠️ 重要: 「モデルで除外」ではなく「運用で購入判断」

**理由**:
- 現状テスト済みは2競馬場（東京・小倉）のみ
- 残り8競馬場のパフォーマンスは未知数
- 限定的なデータから「除外ルール」を決めるのは時期尚早

**推奨アプローチ**:
```
モデル学習・予測: 全条件対象（除外しない）
        ↓
全競馬場テスト: パフォーマンス計測
        ↓
実運用: 条件別に「購入/非購入」を判断
        （パフォーマンスが悪い条件では購入しない）
```

#### Phase 1.9.1: 購入判断フィルタ（運用時に適用）

モデルの予測は全条件で出し、**購入時に**以下のフィルタを適用:

1. Ranker予測上位5位以内に限定
2. オッズ60倍以上は購入見送り
3. 全競馬場テスト後、TP率が低い条件は購入見送り

#### Phase 1.9.2: 新特徴量

⚠️ **データリーク検証結果**

| 特徴量 | 状態 | 判定 |
|--------|------|------|
| `popularity_rank` | 既に使用中 | ✅ OK（実運用と同じタイミング） |
| `tansho_odds` | 既に使用中 | ✅ OK（実運用と同じタイミング） |
| `value_gap` | 既に使用中 | ✅ OK（上記から派生） |

**結論**: 
- 実運用で「締め切り直前のオッズ」を使うならリークではない
- `odds_band`は`tansho_odds`として既に使用中なので追加不要
- 追加すべき新特徴量は**なし**（既存特徴量で十分）

→ **Phase 1.9.1の条件フィルタのみ実装**

---

## 📊 Phase 1.10: 実際ROI分析（矛盾検証から得られた最終結論）

**追加日**: 2026年1月24日  
**実施内容**: 推定期待値と実際ROIの乖離を検証

### 背景: 矛盾する分析結果の発見

FP分析で以下の矛盾が発生:
- 「東京ダートはTP率8.4%で悪い」
- 「ダート高オッズは期待値が高い」

**原因調査の結果**: 推定期待値の計算方法に問題があった

### 重大な発見: 期待値推定の誤り

**推定方法の問題点**:
```
推定: 複勝オッズ ≈ 単勝オッズ × 0.25
実際: 複勝オッズ平均 = 7.28倍（推定値の約半分）
```

| オッズ帯 | 推定期待値 | 実際ROI | 乖離 |
|----------|-----------|---------|------|
| 50-100倍 | 1.39 (プラス) | **-10.9%** | ❌ 大きく乖離 |
| 100-500倍 | 1.02 (プラス) | **-60.1%** | ❌ 大きく乖離 |

**教訓**: 高オッズ馬の複勝オッズは単勝に比例しない！

### 実際ROIによる条件別分析結果

#### 全体統計（閾値0.15、7-12番人気）

| 指標 | 値 |
|------|-----|
| 全候補数 | 1,529件 |
| 的中数 | 160件 |
| TP率 | 10.5% |
| 投資額 | 152,900円 |
| 回収額 | 116,530円 |
| **全体ROI** | **-23.8%** ❌ |

#### 競馬場別ROI（全条件）

| 競馬場 | 芝/ダート | 候補数 | 的中 | TP率 | ROI |
|--------|----------|--------|------|------|-----|
| 東京 | 芝 | 285 | 34 | 11.9% | -12.8% ❌ |
| 東京 | ダート | 680 | 57 | 8.4% | **-33.3%** ❌ |
| 小倉 | 芝 | 370 | 47 | 12.7% | -18.1% ❌ |
| 小倉 | ダート | 194 | 22 | 11.3% | -17.4% ❌ |

**東京ダートのROI -33.3%が最悪** → 「東京ダートは悪い」は正しかった

#### 芝/ダート × Ranker × オッズ帯 の実際ROI

| 条件 | 候補数 | TP率 | ROI |
|------|--------|------|-----|
| ダート & Ranker上位5 & 60-100倍 | 11 | 18.2% | +134.5% ✅ |
| ダート & Ranker上位8 & 60-100倍 | 64 | 12.5% | +51.6% ✅ |
| 芝 & Ranker上位3 & 10-30倍 | 25 | 32.0% | +46.0% ✅ |
| 芝 & Ranker上位5 & 10-30倍 | 55 | 27.3% | +19.1% ✅ |
| 芝 & Ranker上位8 & 10-30倍 | 117 | 19.7% | -9.5% ❌ |

### 🎯 最終結論: 推奨購入条件

**実際の複勝オッズに基づくプラスROI条件**:

| 条件 | 候補数 | TP率 | ROI | 備考 |
|------|--------|------|-----|------|
| **小倉 ダート Ranker上位5 60-100倍** | 3件 | 66.7% | +760.0% | ⚠️ サンプル少 |
| **小倉 ダート Ranker上位8 60-100倍** | 11件 | 36.4% | +288.2% | ⚠️ サンプル少 |
| **東京 芝 Ranker上位5 10-30倍** | 16件 | 31.2% | +40.6% | ✅ 有望 |
| **小倉 芝 Ranker上位5 10-30倍** | 39件 | 25.6% | +10.3% | ✅ 有望 |
| **東京 ダート Ranker上位8 60-100倍** | 53件 | 7.5% | +2.5% | △ ギリギリ |

**合計**: 122件（全候補の8%）、的中25件、**ROI +プラス**

### 🔑 戦略的発見: 芝とダートで真逆のパターン

| 芝/ダート | 狙い目オッズ帯 | 必要なRanker条件 | 戦略 |
|-----------|---------------|-----------------|------|
| **芝** | 10-30倍（低め） | Ranker上位5以内 | 高TP率(25-32%)で手堅く |
| **ダート** | 60-100倍（高め） | Ranker上位8以内 | 高配当狙い（TP率低くてもペイ） |

### 購入判断フィルタ（更新版）

```python
def should_buy(row):
    """プラスROI条件に基づく購入判断"""
    surface = row['芝ダ区分']
    odds = row['単勝オッズ']
    ranker = row['予測順位']
    
    if surface == '芝':
        # 芝: 低オッズ×高Ranker
        return odds >= 10 and odds < 30 and ranker <= 5
    else:  # ダート
        # ダート: 高オッズ×Ranker上位8
        return odds >= 60 and odds < 100 and ranker <= 8
```

### 成功基準（更新）

| 指標 | 全候補 | フィルタ後 | 目標 |
|------|--------|-----------|------|
| 候補数 | 1,529件 | 122件 | - |
| TP率 | 10.5% | 20.5% | 20%以上 ✅ |
| ROI | -23.8% | **+プラス** | 0%以上 ✅ |

### ⚠️ 注意事項

1. **サンプル数の限界**: 東京・小倉の2競馬場のみの分析
2. **小倉ダート高オッズ**: サンプル数が少ない（3-11件）ため要追加検証
3. **全競馬場テスト必須**: この条件が他の競馬場でも有効か検証が必要

### 確認スクリプト

```bash
python analyze_fp_patterns.py check_results/predicted_results_all.tsv
python analyze_expected_value.py check_results/predicted_results_all.tsv --threshold 0.15
```

---

## 🔗 関連ドキュメント

- [特徴量一覧](FEATURE_LIST.md) - 既存特徴量の詳細
- [SHAP分析結果](shap_analysis_report.md) - 特徴量重要度の分析
- [モデル設定](model_configs.json) - 現在のモデル構成
- [ワークフローガイド](MODEL_WORKFLOW_GUIDE.md) - モデル作成の手順

---

## 🚀 Phase A: 確率校正（Calibration）実装

**追加日**: 2026年1月22日  
**実装優先度**: ⭐⭐⭐⭐⭐（最優先）

### 背景: モデルの根本的な問題

Walk-Forward検証結果（2016-2025年）で発見された重大な問題：

**🚨 閾値を上げてもPrecisionが改善しない**

| 競馬場 | 閾値0.10 | 閾値0.50 | 結果 |
|--------|---------|---------|------|
| 東京 | 8.90% | 8.15% | **悪化** |
| 中山 | 9.77% | 9.86% | 微増のみ |
| 京都 | 9.09% | 7.55% | **悪化** |

### 根本原因

LightGBMは`metric='auc'`で最適化されているため：
- **AUC**: 相対的な順位の正しさを評価（順序は正しい）
- **確率**: 絶対的な的中率として校正されていない

つまり：
```
モデル確率 0.1 → 実際の的中率 15%
モデル確率 0.5 → 実際の的中率 8%
```

こういう「逆転」が発生している可能性がある。

### 解決策: CalibratedClassifierCV

scikit-learnの`CalibratedClassifierCV`を使用して確率を校正：

```python
from sklearn.calibration import CalibratedClassifierCV

# upset_classifier_creator.py の train_with_class_weights() を修正
calibrated_model = CalibratedClassifierCV(
    lgb_model,
    method='isotonic',  # 非線形な校正（単調性のみ保証）
    cv=3
)
calibrated_model.fit(X_train, y_train)
```

### 期待効果

1. **閾値制御が意味を持つ**: 0.5 → 実際に50%前後で的中
2. **Precision向上**: 高確率予測の精度が向上
3. **実装コスト低**: 既存モデルをラップするだけ（1日で完了）

### 実装ステップ

1. `upset_classifier_creator.py`の修正（1-2時間）
2. Walk-Forward再実行（30分）
3. 校正カーブの確認（30分）
4. Precision改善効果の検証（1時間）

**所要時間**: 3-4時間

---

## 🏟️ 芝/ダート分離戦略（Step 1）

**追加日**: 2026年1月22日  
**更新日**: 2026年1月22日（データ分析に基づく計画変更）  
**実装優先度**: ⭐⭐⭐⭐（Phase A後に実施）

### 背景: データ分析結果

2013-2024年（訓練期間10年間）のデータを分析した結果：

#### 分離レベル別のデータ量と穴馬率差

| 分離レベル | 条件数 | データ不足 | 穴馬率の差 |
|-----------|--------|-----------|-----------|
| 競馬場別 | 10 | なし | 9.4%〜11.0%（1.6%差）|
| 競馬場×芝ダ | 20 | なし | 9.0%〜11.5%（2.5%差）|
| 競馬場×距離 | 20 | なし | 8.98%〜11.63%（2.6%差）|
| **競馬場×芝ダ×距離** | 40 | **4条件不足** | 8.4%〜12.0%（3.6%差）|

**不足条件（ダート中長距離）**: 札幌(185件)、小倉(131件)、函館(100件)、福島(115件)

#### 芝/ダート別データ量（全競馬場合計）

| モデル | データ量 | 穴馬数 | 穴馬率 |
|--------|---------|--------|--------|
| 芝モデル | 104,884 | 10,746 | 10.2% |
| ダートモデル | 112,401 | 11,285 | 10.0% |

### 採用戦略: 段階的分離

**重要な方針変更**: ローカル/主要場分離 → 芝/ダート分離に変更

理由:
1. 7-12番人気の穴馬率は全競馬場でほぼ同じ（9.4%〜11.0%）
2. 芝/ダートで傾向が異なる可能性（血統、脚質の影響）
3. 実装がシンプルで効果検証しやすい

#### Step 1: 芝/ダート分離（2モデル）⭐推奨・実施予定

```
現状: 統合モデル1つ（全競馬場・全条件）

Step 1後:
├── 芝モデル（全10競馬場の芝レース共通）
└── ダートモデル（全10競馬場のダートレース共通）
```

- **実装コスト**: 低（1日）
- **期待効果**: 中（芝/ダートで傾向が違う可能性）
- **リスク**: 低

#### Step 2: 地域×芝ダ分離（10モデル）⚠️保留

- **実装コスト**: 中（3日）
- **ステータス**: Step 1の効果次第で検討

#### Step 3: 競馬場×芝ダ分離（20モデル）

Step 1で効果があれば直接Step 3へ移行。

| 競馬場 | 芝 | ダート | 備考 |
|--------|-----|--------|------|
| 東京 | ✅ 十分 | ✅ 十分 | |
| 中山 | ✅ 十分 | ✅ 十分 | |
| 京都 | ✅ 十分 | ✅ 十分 | |
| 阪神 | ✅ 十分 | ✅ 十分 | |
| 中京 | ✅ 十分 | ✅ 十分 | |
| 新潟 | ✅ 十分 | ✅ 十分 | |
| 小倉 | ✅ 十分 | ✅ 十分 | |
| 福島 | ✅ 十分 | ✅ 十分 | |
| 札幌 | ✅ 十分 | ✅ 十分 | |
| 函館 | ✅ 十分 | ✅ 十分 | |

- **実装コスト**: 高（1週間）
- **期待効果**: 高（競馬場×芝ダの交互作用を学習）

### Step 1 実装詳細

#### 1. 定数定義（keiba_constants.py）

```python
# 芝のtrack_code（10-22）
TURF_TRACK_CODES = [str(i) for i in range(10, 23)]

# ダートのtrack_code（23-29）
DIRT_TRACK_CODES = [str(i) for i in range(23, 30)]

def get_surface_type(track_code: str) -> str:
    """track_codeから芝/ダートを判定"""
    if track_code in TURF_TRACK_CODES:
        return 'turf'
    elif track_code in DIRT_TRACK_CODES:
        return 'dirt'
    else:
        return 'unknown'
```

#### 2. 訓練データ分割（walk_forward_validation.py）

```python
def _create_upset_classifier(self, ...):
    # 芝データ
    df_turf = df_training[df_training['surface_type'] == 'turf']
    models_turf, _ = train_with_class_weights(X_turf, y_turf, ...)
    
    # ダートデータ
    df_dirt = df_training[df_training['surface_type'] == 'dirt']
    models_dirt, _ = train_with_class_weights(X_dirt, y_dirt, ...)
    
    # 両モデルを保存
    save_model(models_turf, f"upset_classifier_turf_{period}.sav")
    save_model(models_dirt, f"upset_classifier_dirt_{period}.sav")
```

#### 3. 予測ルーティング（universal_test.py）

```python
def predict_upset(df, model_turf, model_dirt):
    # 芝レースはturfモデルで予測
    df_turf = df[df['surface_type'] == 'turf']
    proba_turf = model_turf.predict(df_turf)
    
    # ダートレースはdirtモデルで予測
    df_dirt = df[df['surface_type'] == 'dirt']
    proba_dirt = model_dirt.predict(df_dirt)
    
    return pd.concat([proba_turf, proba_dirt])
```

#### 4. モデルファイル命名規則

```
models/
├── upset_classifier_turf_2019-2022.sav    # 2023年テスト用（芝）
├── upset_classifier_dirt_2019-2022.sav    # 2023年テスト用（ダート）
├── upset_classifier_turf_2020-2023.sav    # 2024年テスト用（芝）
├── upset_classifier_dirt_2020-2023.sav    # 2024年テスト用（ダート）
└── ...
```

### 効果検証基準

| 指標 | 現状（統合モデル） | Step 1目標 | Step 3目標 |
|------|-------------------|-----------|-----------|
| 全体Precision | 8.58% | 9.5%以上 | 10%以上 |
| 芝Precision | - | 9%以上 | 10%以上 |
| ダートPrecision | - | 9%以上 | 10%以上 |

### 移行判断基準

- **Step 1 → Step 3**: Precision 0.5%以上改善で移行
- **Step 1効果なし**: Focal Loss（Phase B）に方針転換

---

## 📅 改善ロードマップ（Phase A以降）

### フェーズ別実装計画

| Phase | 内容 | 所要時間 | 優先度 | 実装時期 |
|-------|------|---------|-------|---------|
| **Phase A** | **確率校正（Calibration）** | **3-4時間** | ⭐⭐⭐⭐⭐ | **即実施** |
| Phase B | Focal Loss導入 | 2-3日 | ⭐⭐⭐⭐ | Phase A後 |
| Phase C | ペース予測特徴量 | 1週間 | ⭐⭐⭐⭐ | Phase B後 |
| Phase D | 競馬場別モデル分離 | 2日 | ⭐⭐⭐ | Phase C後 |
| Phase E | アンサンブル強化 | 1週間 | ⭐⭐ | 余裕があれば |

### Phase別の依存関係

```
Phase A (Calibration) ← 他の全てに影響する基礎
    ↓
Phase B (Focal Loss) ← Calibration前提で調整
    ↓
Phase C (Pace Features) ← 特徴量追加は独立
    ↓
Phase D (Track Models) ← データ量確保のため特徴量追加後
    ↓
Phase E (Ensemble) ← 全モデル完成後
```

### 重要な判断基準

各Phaseの効果検証後、次のPhaseへ進むかを判断：
- **Precision 10%達成**: Phase D（競馬場別）へ進む
- **Precision 10%未達**: Phase B/C の追加改善を検討
- **収支プラス達成**: Phase E（アンサンブル）で安定化

---

**最終更新者**: GitHub Copilot AI Assistant  
**承認日**: 2026年1月19日  
**Phase A計画追加**: 2026年1月22日  
**芝/ダート分離戦略に更新**: 2026年1月22日（データ分析に基づく計画変更）
