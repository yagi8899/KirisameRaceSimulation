"""
ç©´é¦¬äºˆæ¸¬ã®æ­£ç¢ºãªPrecision/Recallã‚’è¨ˆç®—

ä½¿ç”¨æ–¹æ³•:
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼ˆcheck_results/predicted_results_all.tsv ã‚’åˆ†æï¼‰
    python calculate_precision_recall.py
    
    # ãƒ•ã‚¡ã‚¤ãƒ«æŒ‡å®š
    python calculate_precision_recall.py path/to/file.tsv
    
    # ç«¶é¦¬å ´åˆ¥ã«åˆ†æ
    python calculate_precision_recall.py --by-track
    
    # å¹´åº¦åˆ¥ã«åˆ†æ
    python calculate_precision_recall.py --by-year
    
    # ç‰¹å®šã®ç«¶é¦¬å ´ã®ã¿
    python calculate_precision_recall.py --track å‡½é¤¨
    
    # ç‰¹å®šã®å¹´åº¦ã®ã¿
    python calculate_precision_recall.py --year 2024
    
    # çµ„ã¿åˆã‚ã›
    python calculate_precision_recall.py path/to/file.tsv --by-track --by-year
"""
import pandas as pd
from pathlib import Path
import argparse
import json


# ç«¶é¦¬å ´åã‹ã‚‰ã‚³ãƒ¼ãƒ‰ã¸ã®ãƒãƒƒãƒ”ãƒ³ã‚°
TRACK_NAME_TO_CODE = {
    'æœ­å¹Œ': '01', 'å‡½é¤¨': '02', 'ç¦å³¶': '03', 'æ–°æ½Ÿ': '04', 'æ±äº¬': '05',
    'ä¸­å±±': '06', 'ä¸­äº¬': '07', 'äº¬éƒ½': '08', 'é˜ªç¥': '09', 'å°å€‰': '10'
}


def load_threshold_config() -> dict:
    """upset_threshold_config.json ã‹ã‚‰é–¾å€¤è¨­å®šã‚’èª­ã¿è¾¼ã‚€"""
    config_path = Path(__file__).parent / "upset_threshold_config.json"
    if config_path.exists():
        with open(config_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {"default_threshold": 0.20, "thresholds_by_condition": {}}


def get_threshold_for_track(config: dict, track_name: str) -> float:
    """ç«¶é¦¬å ´åã«å¯¾å¿œã™ã‚‹é–¾å€¤ã‚’å–å¾—"""
    default = config.get("default_threshold", 0.20)
    track_code = TRACK_NAME_TO_CODE.get(track_name)
    
    if track_code:
        by_track = config.get("thresholds_by_condition", {}).get("by_track", {})
        return by_track.get(track_code, default)
    
    return default


def apply_threshold_to_df(df: pd.DataFrame, config: dict) -> pd.DataFrame:
    """
    DataFrameã«é–¾å€¤ã‚’é©ç”¨ã—ã¦ç©´é¦¬å€™è£œã‚’å†è¨ˆç®—
    ç«¶é¦¬å ´ã”ã¨ã«ç•°ãªã‚‹é–¾å€¤ã‚’é©ç”¨
    """
    df = df.copy()
    
    if 'ç©´é¦¬ç¢ºç‡' not in df.columns:
        print("âš ï¸ 'ç©´é¦¬ç¢ºç‡'åˆ—ãŒãªã„ãŸã‚ã€æ—¢å­˜ã®'ç©´é¦¬å€™è£œ'ã‚’ä½¿ç”¨")
        return df
    
    if 'ç«¶é¦¬å ´' not in df.columns:
        # ç«¶é¦¬å ´åˆ—ãŒãªã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆé–¾å€¤ã‚’ä½¿ç”¨
        threshold = config.get("default_threshold", 0.20)
        df['ç©´é¦¬å€™è£œ'] = (df['ç©´é¦¬ç¢ºç‡'] >= threshold).astype(int)
        print(f"ğŸ“Š é–¾å€¤ {threshold} ã‚’å…¨ä½“ã«é©ç”¨")
        return df
    
    # ç«¶é¦¬å ´ã”ã¨ã«é–¾å€¤ã‚’é©ç”¨
    df['ç©´é¦¬å€™è£œ'] = 0
    applied_thresholds = {}
    
    for track_name in df['ç«¶é¦¬å ´'].unique():
        threshold = get_threshold_for_track(config, track_name)
        mask = df['ç«¶é¦¬å ´'] == track_name
        df.loc[mask, 'ç©´é¦¬å€™è£œ'] = (df.loc[mask, 'ç©´é¦¬ç¢ºç‡'] >= threshold).astype(int)
        applied_thresholds[track_name] = threshold
    
    print(f"ğŸ“Š é©ç”¨ã—ãŸé–¾å€¤: {applied_thresholds}")
    
    return df


def calculate_single_metrics(df: pd.DataFrame, label: str = "å…¨ä½“") -> dict:
    """
    å˜ä¸€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®Precision/Recallã‚’è¨ˆç®—
    
    Args:
        df: åˆ†æå¯¾è±¡ã®DataFrame
        label: å‡ºåŠ›ãƒ©ãƒ™ãƒ«ï¼ˆä¾‹: "å‡½é¤¨", "äº¬éƒ½"ï¼‰
    
    Returns:
        dict: è¨ˆç®—çµæœ
    """
    print(f"\n{'='*70}")
    print(f"ğŸ¯ {label} - ç©´é¦¬äºˆæ¸¬ã®è©•ä¾¡çµæœï¼ˆ7-12ç•ªäººæ°—ã§3ç€ä»¥å†…ï¼‰")
    print(f"{'='*70}")
    
    total_records = len(df)
    if total_records == 0:
        print(f"âš ï¸ ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return None
    
    # å®Ÿéš›ã®ç©´é¦¬ã‚’å®šç¾©ï¼ˆ7-12ç•ªäººæ°—ã§3ç€ä»¥å†…ï¼‰
    df = df.copy()
    df['å®Ÿéš›ã®ç©´é¦¬'] = (
        (df['äººæ°—é †'] >= 7) & 
        (df['äººæ°—é †'] <= 12) & 
        (df['ç¢ºå®šç€é †'] <= 3)
    ).astype(int)
    
    # True Positive: ç©´é¦¬å€™è£œã‹ã¤å®Ÿéš›ã®ç©´é¦¬
    TP = ((df['ç©´é¦¬å€™è£œ'] == 1) & (df['å®Ÿéš›ã®ç©´é¦¬'] == 1)).sum()
    
    # False Positive: ç©´é¦¬å€™è£œã ãŒå®Ÿéš›ã¯ç©´é¦¬ã§ã¯ãªã„
    FP = ((df['ç©´é¦¬å€™è£œ'] == 1) & (df['å®Ÿéš›ã®ç©´é¦¬'] == 0)).sum()
    
    # False Negative: ç©´é¦¬å€™è£œã§ã¯ãªã„ãŒå®Ÿéš›ã¯ç©´é¦¬
    FN = ((df['ç©´é¦¬å€™è£œ'] == 0) & (df['å®Ÿéš›ã®ç©´é¦¬'] == 1)).sum()
    
    # True Negative: ç©´é¦¬å€™è£œã§ãªãå®Ÿéš›ã‚‚ç©´é¦¬ã§ã¯ãªã„
    TN = ((df['ç©´é¦¬å€™è£œ'] == 0) & (df['å®Ÿéš›ã®ç©´é¦¬'] == 0)).sum()
    
    # é›†è¨ˆ
    ç©´é¦¬å€™è£œç·æ•° = TP + FP
    å®Ÿéš›ã®ç©´é¦¬ç·æ•° = TP + FN
    
    # Precisionï¼ˆé©åˆç‡ï¼‰
    Precision = (TP / ç©´é¦¬å€™è£œç·æ•° * 100) if ç©´é¦¬å€™è£œç·æ•° > 0 else 0
    
    # Recallï¼ˆå†ç¾ç‡ï¼‰
    Recall = (TP / å®Ÿéš›ã®ç©´é¦¬ç·æ•° * 100) if å®Ÿéš›ã®ç©´é¦¬ç·æ•° > 0 else 0
    
    # F1 Score
    F1 = (2 * Precision * Recall / (Precision + Recall)) if (Precision + Recall) > 0 else 0
    
    # çµæœè¡¨ç¤º
    print(f"\nğŸ“Š ãƒ‡ãƒ¼ã‚¿æ¦‚è¦:")
    print(f"  ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {total_records:,}é ­")
    print(f"  ç©´é¦¬å€™è£œç·æ•°: {ç©´é¦¬å€™è£œç·æ•°:,}é ­ (TP + FP)")
    print(f"  å®Ÿéš›ã®ç©´é¦¬æ•°: {å®Ÿéš›ã®ç©´é¦¬ç·æ•°:,}é ­ (TP + FN)")
    
    print(f"\nğŸ“Š æ··åŒè¡Œåˆ—:")
    print(f"  True Positive (TP):  {TP:,}é ­  â† ç©´é¦¬å€™è£œã‹ã¤å®Ÿéš›ã®ç©´é¦¬")
    print(f"  False Positive (FP): {FP:,}é ­  â† ç©´é¦¬å€™è£œã ãŒå¤–ã‚Œ")
    print(f"  False Negative (FN): {FN:,}é ­  â† è¦‹é€ƒã—ãŸç©´é¦¬")
    print(f"  True Negative (TN):  {TN:,}é ­  â† æ­£ã—ãé™¤å¤–")
    
    print(f"\nğŸ“ˆ è©•ä¾¡æŒ‡æ¨™:")
    print(f"  ğŸ¯ Precisionï¼ˆé©åˆç‡ï¼‰: {Precision:.2f}%")
    print(f"     â†’ ç©´é¦¬å€™è£œã®ã†ã¡{Precision:.2f}%ãŒå®Ÿéš›ã«å¥½èµ°")
    print(f"  ğŸ” Recallï¼ˆå†ç¾ç‡ï¼‰: {Recall:.2f}%")
    print(f"     â†’ å®Ÿéš›ã®ç©´é¦¬ã®{Recall:.2f}%ã‚’æ¤œå‡º")
    print(f"  âš–ï¸ F1 Score: {F1:.2f}")
    
    # Phaseè©•ä¾¡
    phase1 = Precision >= 8.0
    phase2 = Precision >= 10.0
    phase3 = Precision >= 12.0
    
    print(f"\nğŸ“‹ Phaseç›®æ¨™:")
    print(f"  Phase 1 (8%ä»¥ä¸Š):  {'âœ… é”æˆ' if phase1 else 'âŒ æœªé”æˆ'}")
    print(f"  Phase 2 (10%ä»¥ä¸Š): {'âœ… é”æˆ' if phase2 else 'âš ï¸ æœªé”æˆ'}")
    print(f"  Phase 3 (12%ä»¥ä¸Š): {'âœ… é”æˆ' if phase3 else 'âš ï¸ æœªé”æˆ'}")
    
    return {
        'label': label,
        'total': total_records,
        'candidates': ç©´é¦¬å€™è£œç·æ•°,
        'actual_upsets': å®Ÿéš›ã®ç©´é¦¬ç·æ•°,
        'TP': TP,
        'FP': FP,
        'FN': FN,
        'TN': TN,
        'precision': Precision,
        'recall': Recall,
        'f1': F1,
        'phase1': phase1,
        'phase2': phase2,
        'phase3': phase3
    }


def print_summary(results: list):
    """ç«¶é¦¬å ´åˆ¥ã®ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º"""
    print("\n" + "=" * 80)
    print("ğŸ“Š ç«¶é¦¬å ´åˆ¥ã‚µãƒãƒªãƒ¼")
    print("=" * 80)
    
    print(f"\n{'ç«¶é¦¬å ´':<10} {'ãƒ¬ã‚³ãƒ¼ãƒ‰':>10} {'å€™è£œæ•°':>8} {'ç©´é¦¬æ•°':>8} {'TP':>6} {'Precision':>12} {'Recall':>10} {'F1':>8} {'Phase1':>8}")
    print("-" * 100)
    
    for r in results:
        if r is None:
            continue
        phase1_mark = "âœ…" if r['phase1'] else "âŒ"
        print(f"{r['label']:<10} {r['total']:>10,} {r['candidates']:>8} {r['actual_upsets']:>8} {r['TP']:>6} {r['precision']:>11.2f}% {r['recall']:>9.2f}% {r['f1']:>8.2f} {phase1_mark:>8}")
    
    # Phaseé”æˆç‡
    phase1_count = sum(1 for r in results if r and r['phase1'])
    phase2_count = sum(1 for r in results if r and r['phase2'])
    phase3_count = sum(1 for r in results if r and r['phase3'])
    total_count = sum(1 for r in results if r)
    
    print(f"\nğŸ“‹ Phaseé”æˆçŠ¶æ³:")
    print(f"  Phase 1 (8%ä»¥ä¸Š):  {phase1_count}/{total_count} ã§é”æˆ")
    print(f"  Phase 2 (10%ä»¥ä¸Š): {phase2_count}/{total_count} ã§é”æˆ")
    print(f"  Phase 3 (12%ä»¥ä¸Š): {phase3_count}/{total_count} ã§é”æˆ")


def print_track_year_summary(track: str, results: list):
    """ç‰¹å®šç«¶é¦¬å ´ã®å¹´åº¦åˆ¥ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º"""
    print(f"\n  ğŸ“… {track} å¹´åº¦åˆ¥ã‚µãƒãƒªãƒ¼:")
    print(f"  {'å¹´åº¦':<12} {'ãƒ¬ã‚³ãƒ¼ãƒ‰':>8} {'å€™è£œæ•°':>6} {'TP':>5} {'Precision':>10} {'Recall':>8} {'Phase1':>7}")
    print("  " + "-" * 70)
    
    for r in results:
        if r is None:
            continue
        # ãƒ©ãƒ™ãƒ«ã‹ã‚‰å¹´åº¦éƒ¨åˆ†ã‚’æŠ½å‡ºï¼ˆ"  â”” ä¸­å±± 2022å¹´" â†’ "2022å¹´"ï¼‰
        label = r['label'].split()[-1] if r['label'] else ""
        phase1_mark = "âœ…" if r['phase1'] else "âŒ"
        print(f"  {label:<12} {r['total']:>8,} {r['candidates']:>6} {r['TP']:>5} {r['precision']:>9.2f}% {r['recall']:>7.2f}% {phase1_mark:>7}")


def calculate_metrics(file_path: str = None, by_track: bool = False, track_filter: str = None, by_year: bool = False, year_filter: int = None):
    """
    Precision/Recallã‚’æ­£ç¢ºã«è¨ˆç®—
    
    Args:
        file_path: åˆ†æå¯¾è±¡ã®TSVãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        by_track: ç«¶é¦¬å ´åˆ¥ã«åˆ†æã™ã‚‹ã‹
        track_filter: ç‰¹å®šã®ç«¶é¦¬å ´ã®ã¿åˆ†æï¼ˆä¾‹: "å‡½é¤¨"ï¼‰
        by_year: å¹´åº¦åˆ¥ã«åˆ†æã™ã‚‹ã‹
        year_filter: ç‰¹å®šã®å¹´åº¦ã®ã¿åˆ†æï¼ˆä¾‹: 2024ï¼‰
    """
    print("=" * 80)
    print("ğŸ¯ ç©´é¦¬äºˆæ¸¬ Precision/Recall è¨ˆç®—")
    print("=" * 80)
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®æ±ºå®š
    if file_path is None:
        results_file = Path("check_results/predicted_results_all.tsv")
    else:
        results_file = Path(file_path)
    
    print(f"\nğŸ“‚ å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«: {results_file}")
    
    if not results_file.exists():
        print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {results_file}")
        return None
    
    df = pd.read_csv(results_file, sep='\t', encoding='utf-8-sig')
    
    print(f"âœ… {len(df):,}ãƒ¬ã‚³ãƒ¼ãƒ‰èª­ã¿è¾¼ã¿å®Œäº†")
    print(f"ğŸ“‹ åˆ—ä¸€è¦§: {df.columns.tolist()}")
    
    # upset_threshold_config.json ã‹ã‚‰é–¾å€¤ã‚’èª­ã¿è¾¼ã‚“ã§é©ç”¨
    config = load_threshold_config()
    print(f"\nğŸ“‚ é–¾å€¤è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")
    print(f"   ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆé–¾å€¤: {config.get('default_threshold', 0.20)}")
    df = apply_threshold_to_df(df, config)
    
    # å¿…è¦ãªåˆ—ãŒã‚ã‚‹ã‹ç¢ºèª
    required_cols = ['ç©´é¦¬å€™è£œ', 'äººæ°—é †', 'ç¢ºå®šç€é †']
    missing = [col for col in required_cols if col not in df.columns]
    
    if missing:
        print(f"\nâŒ å¿…è¦ãªåˆ—ãŒã‚ã‚Šã¾ã›ã‚“: {missing}")
        return None
    
    # ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
    df = df.dropna(subset=['ç©´é¦¬å€™è£œ', 'äººæ°—é †', 'ç¢ºå®šç€é †'])
    print(f"ğŸ“Š NaNé™¤å¤–å¾Œ: {len(df):,}ãƒ¬ã‚³ãƒ¼ãƒ‰")
    
    # ç«¶é¦¬å ´ã®ä¸€è¦§ã‚’å–å¾—
    if 'ç«¶é¦¬å ´' in df.columns:
        tracks = df['ç«¶é¦¬å ´'].unique()
        print(f"ğŸ‡ å«ã¾ã‚Œã‚‹ç«¶é¦¬å ´: {', '.join(sorted(tracks))}")
    else:
        tracks = []
        by_track = False
        print(f"âš ï¸ 'ç«¶é¦¬å ´'åˆ—ãŒãªã„ãŸã‚ã€ç«¶é¦¬å ´åˆ¥åˆ†æã¯ã‚¹ã‚­ãƒƒãƒ—")
    
    # å¹´åº¦ã®ä¸€è¦§ã‚’å–å¾—
    if 'é–‹å‚¬å¹´' in df.columns:
        years = sorted(df['é–‹å‚¬å¹´'].unique())
        print(f"ğŸ“… å«ã¾ã‚Œã‚‹å¹´åº¦: {', '.join(map(str, years))}")
    else:
        years = []
        by_year = False
        print(f"âš ï¸ 'é–‹å‚¬å¹´'åˆ—ãŒãªã„ãŸã‚ã€å¹´åº¦åˆ¥åˆ†æã¯ã‚¹ã‚­ãƒƒãƒ—")
    
    results = []
    
    # ç‰¹å®šã®å¹´åº¦ã®ã¿
    if year_filter:
        if year_filter in years:
            df_year = df[df['é–‹å‚¬å¹´'] == year_filter]
            result = calculate_single_metrics(df_year, label=f"{year_filter}å¹´")
            results.append(result)
        else:
            print(f"âŒ å¹´åº¦ '{year_filter}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            print(f"ğŸ“‹ åˆ©ç”¨å¯èƒ½ãªå¹´åº¦: {', '.join(map(str, years))}")
            return None
    
    # ç‰¹å®šã®ç«¶é¦¬å ´ã®ã¿
    elif track_filter:
        if track_filter in tracks:
            df_track = df[df['ç«¶é¦¬å ´'] == track_filter]
            result = calculate_single_metrics(df_track, label=track_filter)
            results.append(result)
        else:
            print(f"âŒ ç«¶é¦¬å ´ '{track_filter}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            print(f"ğŸ“‹ åˆ©ç”¨å¯èƒ½ãªç«¶é¦¬å ´: {', '.join(sorted(tracks))}")
            return None
    
    # ç«¶é¦¬å ´åˆ¥ã¨å¹´åº¦åˆ¥ã®ä¸¡æ–¹
    elif by_track and by_year and len(tracks) > 0 and len(years) > 0:
        # ã¾ãšå…¨ä½“ã®åˆ†æ
        result = calculate_single_metrics(df, label="å…¨ä½“")
        results.append(result)
        
        # ç«¶é¦¬å ´åˆ¥ã®åˆ†æ + å„ç«¶é¦¬å ´ã®å¹´åº¦åˆ¥å†…è¨³
        print("\n" + "=" * 80)
        print("ğŸ“Š ç«¶é¦¬å ´åˆ¥åˆ†æï¼ˆå¹´åº¦åˆ¥å†…è¨³ä»˜ãï¼‰")
        print("=" * 80)
        track_results = [result]  # å…¨ä½“ã‚’å«ã‚€
        for track in sorted(tracks):
            df_track = df[df['ç«¶é¦¬å ´'] == track]
            if len(df_track) > 0:
                # ç«¶é¦¬å ´å…¨ä½“
                r = calculate_single_metrics(df_track, label=track)
                results.append(r)
                track_results.append(r)
                
                # ã“ã®ç«¶é¦¬å ´ã®å¹´åº¦åˆ¥å†…è¨³
                track_year_results = []
                for year in years:
                    df_track_year = df_track[df_track['é–‹å‚¬å¹´'] == year]
                    if len(df_track_year) > 0:
                        r_year = calculate_single_metrics(df_track_year, label=f"  â”” {track} {year}å¹´")
                        results.append(r_year)
                        track_year_results.append(r_year)
                
                # ç«¶é¦¬å ´å†…ã®å¹´åº¦ã‚µãƒãƒªãƒ¼
                if len(track_year_results) > 1:
                    print_track_year_summary(track, track_year_results)
        
        # ç«¶é¦¬å ´ã‚µãƒãƒªãƒ¼
        print_summary(track_results)
    
    # ç«¶é¦¬å ´åˆ¥ã®ã¿
    elif by_track and len(tracks) > 0:
        # ã¾ãšå…¨ä½“ã®åˆ†æ
        result = calculate_single_metrics(df, label="å…¨ä½“")
        results.append(result)
        
        # ç«¶é¦¬å ´åˆ¥ã®åˆ†æ
        for track in sorted(tracks):
            df_track = df[df['ç«¶é¦¬å ´'] == track]
            if len(df_track) > 0:
                result = calculate_single_metrics(df_track, label=track)
                results.append(result)
        
        # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
        print_summary(results)
    
    # å¹´åº¦åˆ¥ã®ã¿
    elif by_year and len(years) > 0:
        # ã¾ãšå…¨ä½“ã®åˆ†æ
        result = calculate_single_metrics(df, label="å…¨ä½“")
        results.append(result)
        
        # å¹´åº¦åˆ¥ã®åˆ†æ
        for year in years:
            df_year = df[df['é–‹å‚¬å¹´'] == year]
            if len(df_year) > 0:
                result = calculate_single_metrics(df_year, label=f"{year}å¹´")
                results.append(result)
        
        # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
        print_summary(results)
    
    # å…¨ä½“ã®ã¿åˆ†æ
    else:
        result = calculate_single_metrics(df, label="å…¨ä½“")
        results.append(result)
        
        # è©³ç´°ãªè©•ä¾¡ã‚’è¡¨ç¤ºï¼ˆå…¨ä½“ã®ã¿ã®å ´åˆï¼‰
        if result:
            print_detailed_evaluation(result)
    
    return results


def print_detailed_evaluation(result: dict):
    """è©³ç´°ãªè©•ä¾¡ã‚’è¡¨ç¤ºï¼ˆå…¨ä½“åˆ†ææ™‚ã®ã¿ï¼‰"""
    print(f"\n{'='*70}")
    print(f"ğŸ“‹ è©³ç´°è©•ä¾¡")
    print(f"{'='*70}")
    
    # å€™è£œæ•°è©•ä¾¡
    candidates = result['candidates']
    print(f"\nã€å€™è£œæ•°ã®è©•ä¾¡ã€‘")
    if candidates <= 500:
        print(f"  âœ… å°‘ãªã‚ ({candidates:,}é ­) - çµã‚Šè¾¼ã¿åŠ¹ã„ã¦ã„ã‚‹")
    elif candidates <= 1500:
        print(f"  âœ… é©æ­£ ({candidates:,}é ­)")
    elif candidates <= 3000:
        print(f"  âš ï¸ ã‚„ã‚„å¤šã‚ ({candidates:,}é ­)")
    else:
        print(f"  âŒ å¤šã™ã ({candidates:,}é ­) - é–¾å€¤ã‚’ä¸Šã’ã‚‹ã“ã¨ã‚’æ¨å¥¨")
    
    # Recallè©•ä¾¡
    recall = result['recall']
    print(f"\nã€Recallï¼ˆå†ç¾ç‡ï¼‰ã®è©•ä¾¡ã€‘")
    if recall >= 90:
        print(f"  âš ï¸ é«˜ã™ã ({recall:.2f}%) - é–¾å€¤ãŒä½ã™ãã‚‹å¯èƒ½æ€§")
    elif recall >= 60:
        print(f"  âœ… é©æ­£ ({recall:.2f}%)")
    elif recall >= 40:
        print(f"  âš ï¸ ã‚„ã‚„ä½ã‚ ({recall:.2f}%) - è¦‹é€ƒã—ãŒå¤šã„")
    else:
        print(f"  âŒ ä½ã™ã ({recall:.2f}%) - é–¾å€¤ã‚’ä¸‹ã’ã‚‹ã“ã¨ã‚’æ¨å¥¨")
    
    # ãƒãƒ©ãƒ³ã‚¹è©•ä¾¡
    precision = result['precision']
    print(f"\nã€ãƒãƒ©ãƒ³ã‚¹è©•ä¾¡ã€‘")
    if precision >= 12 and 50 <= recall <= 80:
        print(f"  âœ… ç†æƒ³çš„ãªãƒãƒ©ãƒ³ã‚¹")
    elif precision >= 8 and recall >= 50:
        print(f"  âœ… è‰¯å¥½ãªãƒãƒ©ãƒ³ã‚¹")
    elif precision >= 8:
        print(f"  âš ï¸ Precisionã¯é”æˆã€RecallãŒä½ã‚")
    elif recall >= 80:
        print(f"  âš ï¸ Recallã¯é«˜ã„ãŒã€PrecisionãŒä½ã„ â†’ é–¾å€¤ã‚’ä¸Šã’ã‚‹")
    else:
        print(f"  âŒ æ”¹å–„ãŒå¿…è¦")


def main():
    parser = argparse.ArgumentParser(
        description='ç©´é¦¬äºˆæ¸¬ã®Precision/Recallè¨ˆç®—',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä¾‹:
  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼ˆcheck_results/predicted_results_all.tsv ã‚’åˆ†æï¼‰
  python calculate_precision_recall.py
  
  # ãƒ•ã‚¡ã‚¤ãƒ«æŒ‡å®š
  python calculate_precision_recall.py path/to/file.tsv
  
  # ç«¶é¦¬å ´åˆ¥ã«åˆ†æ
  python calculate_precision_recall.py --by-track
  
  # ç‰¹å®šã®ç«¶é¦¬å ´ã®ã¿
  python calculate_precision_recall.py --track å‡½é¤¨
  
  # çµ„ã¿åˆã‚ã›
  # å¹´åº¦åˆ¥ã«åˆ†æ
  python calculate_precision_recall.py --by-year
  
  # ç‰¹å®šã®å¹´åº¦ã®ã¿
  python calculate_precision_recall.py --year 2024
  
  # çµ„ã¿åˆã‚ã›
  python calculate_precision_recall.py path/to/file.tsv --by-track
        """
    )
    
    parser.add_argument('file', nargs='?', default=None,
                        help='åˆ†æå¯¾è±¡ã®TSVãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆçœç•¥æ™‚: check_results/predicted_results_all.tsvï¼‰')
    parser.add_argument('--by-track', '-b', action='store_true',
                        help='ç«¶é¦¬å ´åˆ¥ã«åˆ†æã™ã‚‹')
    parser.add_argument('--by-year', '-y', action='store_true',
                        help='å¹´åº¦åˆ¥ã«åˆ†æã™ã‚‹')
    parser.add_argument('--track', '-t', type=str, default=None,
                        help='ç‰¹å®šã®ç«¶é¦¬å ´ã®ã¿åˆ†æï¼ˆä¾‹: å‡½é¤¨ï¼‰')
    parser.add_argument('--year', type=int, default=None,
                        help='ç‰¹å®šã®å¹´åº¦ã®ã¿åˆ†æï¼ˆä¾‹: 2024ï¼‰')
    
    args = parser.parse_args()
    
    results = calculate_metrics(
        file_path=args.file,
        by_track=args.by_track,
        track_filter=args.track,
        by_year=args.by_year,
        year_filter=args.year
    )
    
    if results is not None:
        print("\n" + "=" * 80)
        print("âœ… è¨ˆç®—å®Œäº†ï¼")
        print("=" * 80)


if __name__ == '__main__':
    main()
