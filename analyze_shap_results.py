"""
SHAPåˆ†æçµæœã®è©³ç´°çµ±è¨ˆåˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆ

å®Ÿè¡Œ:
    python analyze_shap_results.py --input shap_analysis/tokyo_turf_3ageup_long/2023/tokyo_turf_3ageup_long_importance.csv --model-name tokyo_turf_3ageup_long
    python analyze_shap_results.py --input shap_analysis/hanshin_turf_3ageup_long/2023/hanshin_turf_3ageup_long_importance.csv --model-name hanshin_turf_3ageup_long
"""
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime
import argparse
from pathlib import Path

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
plt.rcParams['font.sans-serif'] = ['MS Gothic', 'Yu Gothic', 'Meiryo']
plt.rcParams['axes.unicode_minus'] = False

def analyze_feature_importance(input_csv, model_name, output_dir):
    """ç‰¹å¾´é‡é‡è¦åº¦ã®è©³ç´°åˆ†æ
    
    Args:
        input_csv (str): SHAPé‡è¦åº¦CSVãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        model_name (str): ãƒ¢ãƒ‡ãƒ«åï¼ˆå‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã«ä½¿ç”¨ï¼‰
        output_dir (str): å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: shap_analysisï¼‰
    """
    print("="*80)
    print(f"[TEST] SHAPç‰¹å¾´é‡é‡è¦åº¦ã®è©³ç´°åˆ†æ: {model_name}")
    print("="*80)
    
    # CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
    if not Path(input_csv).exists():
        print(f"[ERROR] ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_csv}")
        return
    
    df = pd.read_csv(input_csv)
    
    print(f"\n[+] å…¨ç‰¹å¾´é‡æ•°: {len(df)}å€‹\n")
    
    # åŸºæœ¬çµ±è¨ˆ
    print("=" * 80)
    print("ã€åŸºæœ¬çµ±è¨ˆé‡ã€‘")
    print("=" * 80)
    print(f"SHAPå€¤ã®åˆè¨ˆ: {df['mean_abs_shap'].sum():.4f}")
    print(f"SHAPå€¤ã®å¹³å‡: {df['mean_abs_shap'].mean():.4f}")
    print(f"SHAPå€¤ã®ä¸­å¤®å€¤: {df['mean_abs_shap'].median():.4f}")
    print(f"SHAPå€¤ã®æ¨™æº–åå·®: {df['mean_abs_shap'].std():.4f}")
    print(f"SHAPå€¤ã®æœ€å¤§å€¤: {df['mean_abs_shap'].max():.4f}")
    print(f"SHAPå€¤ã®æœ€å°å€¤: {df['mean_abs_shap'].min():.4f}")
    
    # ç´¯ç©å¯„ä¸ç‡
    df['cumsum_ratio'] = df['mean_abs_shap'].cumsum() / df['mean_abs_shap'].sum()
    
    print("\n" + "=" * 80)
    print("ã€ç´¯ç©å¯„ä¸ç‡åˆ†æã€‘")
    print("=" * 80)
    
    for threshold in [0.5, 0.7, 0.8, 0.9]:
        n_features = (df['cumsum_ratio'] <= threshold).sum() + 1
        print(f"ç´¯ç©å¯„ä¸ç‡ {threshold*100:.0f}% ã«å¿…è¦ãªç‰¹å¾´é‡æ•°: {n_features}å€‹")
        print(f"  â†’ Top{n_features}: {', '.join(df.head(n_features)['feature'].tolist())}")
    
    # ã‚«ãƒ†ã‚´ãƒªåˆ¥åˆ†æ
    print("\n" + "=" * 80)
    print("ã€ç‰¹å¾´é‡ã‚«ãƒ†ã‚´ãƒªåˆ¥åˆ†æã€‘")
    print("=" * 80)
    
    categories = {
        'éå»æˆç¸¾ç³»': ['past_avg_sotai_chakujun', 'past_score', 'time_index'],
        'æ–¤é‡ç³»': ['futan_per_barei', 'futan_zscore', 'futan_percentile', 'futan_deviation', 'futan_juryo', 'futan_per_barei_log'],
        'é¨æ‰‹ç³»': ['kishu_surface_score', 'kishu_skill_score', 'kishu_popularity_score'],
        'èª¿æ•™å¸«ç³»': ['chokyoshi_recent_score'],
        'é¦¬ç•ªãƒ»æ ç•ªç³»': ['umaban_kyori_interaction', 'umaban_percentile', 'wakuban_ratio', 'wakuban_bias_score'],
        'è·é›¢é©æ€§ç³»': ['similar_distance_score', 'distance_category_score', 'distance_change_adaptability'],
        'é¦¬å ´é©æ€§ç³»': ['surface_aptitude_score', 'baba_condition_score', 'baba_change_adaptability', 'kohan_3f_index'],
        'å¹´é½¢ç³»': ['barei_peak_distance', 'barei_peak_short']
    }
    
    category_stats = []
    for category, features in categories.items():
        category_df = df[df['feature'].isin(features)]
        total_shap = category_df['mean_abs_shap'].sum()
        avg_shap = category_df['mean_abs_shap'].mean()
        n_features = len(category_df)
        category_stats.append({
            'ã‚«ãƒ†ã‚´ãƒª': category,
            'ç‰¹å¾´é‡æ•°': n_features,
            'SHAPåˆè¨ˆ': total_shap,
            'SHAPå¹³å‡': avg_shap,
            'å¯„ä¸ç‡(%)': total_shap / df['mean_abs_shap'].sum() * 100
        })
    
    category_df = pd.DataFrame(category_stats).sort_values('SHAPåˆè¨ˆ', ascending=False)
    print(category_df.to_string(index=False))
    
    # å‰Šé™¤æ¨å¥¨ç‰¹å¾´é‡
    print("\n" + "=" * 80)
    print("ã€å‰Šé™¤æ¨å¥¨ç‰¹å¾´é‡(SHAP < 0.005)ã€‘")
    print("=" * 80)
    
    low_impact = df[df['mean_abs_shap'] < 0.005].sort_values('mean_abs_shap', ascending=False)
    if len(low_impact) > 0:
        print(f"å‰Šé™¤å€™è£œ: {len(low_impact)}å€‹\n")
        for idx, row in low_impact.iterrows():
            print(f"  [ERROR] {row['feature']:30s} SHAP={row['mean_abs_shap']:.6f}")
        
        print(f"\nå‰Šé™¤ã™ã‚‹ã“ã¨ã§:")
        print(f"  - ç‰¹å¾´é‡æ•°: {len(df)}å€‹ â†’ {len(df) - len(low_impact)}å€‹")
        print(f"  - å‰Šæ¸›ç‡: {len(low_impact)/len(df)*100:.1f}%")
        print(f"  - å¤±ã‚ã‚Œã‚‹æƒ…å ±é‡: {low_impact['mean_abs_shap'].sum()/df['mean_abs_shap'].sum()*100:.2f}%")
    else:
        print("å‰Šé™¤æ¨å¥¨ã®ç‰¹å¾´é‡ã¯ã‚ã‚Šã¾ã›ã‚“")
    
    # LightGBM Gainã¨SHAPã®ç›¸é–¢
    print("\n" + "=" * 80)
    print("ã€LightGBM Gain vs SHAPå€¤ã®ç›¸é–¢ã€‘")
    print("=" * 80)
    
    correlation = df['mean_abs_shap'].corr(df['lgb_gain'])
    print(f"ãƒ”ã‚¢ã‚½ãƒ³ç›¸é–¢ä¿‚æ•°: {correlation:.4f}")
    
    # ä¹–é›¢ãŒå¤§ãã„ç‰¹å¾´é‡
    df['gain_shap_ratio'] = df['lgb_gain'] / (df['mean_abs_shap'] * 1000)
    df_sorted = df.sort_values('gain_shap_ratio', ascending=False)
    
    print("\nGainãŒé«˜ã„ã®ã«SHAPãŒä½ã„ç‰¹å¾´é‡(ãƒ¢ãƒ‡ãƒ«ãŒéå‰°ã«ä½¿ç”¨):")
    for idx, row in df_sorted.head(5).iterrows():
        print(f"  {row['feature']:30s} Gain={row['lgb_gain']:8.2f} SHAP={row['mean_abs_shap']:.4f} æ¯”ç‡={row['gain_shap_ratio']:.2f}")
    
    print("\nSHAPãŒé«˜ã„ã®ã«GainãŒä½ã„ç‰¹å¾´é‡(åŠ¹ç‡çš„ãªç‰¹å¾´é‡):")
    for idx, row in df_sorted.tail(5).iterrows():
        print(f"  {row['feature']:30s} Gain={row['lgb_gain']:8.2f} SHAP={row['mean_abs_shap']:.4f} æ¯”ç‡={row['gain_shap_ratio']:.2f}")
    
    # å¯è¦–åŒ–
    create_visualizations(df, category_df)
    
    return df, category_df


def create_visualizations(df, category_df):
    """SHAPåˆ†æçµæœã®è¿½åŠ å¯è¦–åŒ–"""
    print("\n" + "=" * 80)
    print("[+] è¿½åŠ ã‚°ãƒ©ãƒ•ã‚’ä½œæˆä¸­...")
    print("=" * 80)
    
    # 1. ç´¯ç©å¯„ä¸ç‡ã‚°ãƒ©ãƒ•
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    
    # 1-1. ç´¯ç©å¯„ä¸ç‡
    ax1 = axes[0, 0]
    ax1.plot(range(1, len(df)+1), df['cumsum_ratio'], 'b-', linewidth=2)
    ax1.axhline(y=0.8, color='r', linestyle='--', label='80%ãƒ©ã‚¤ãƒ³')
    ax1.axhline(y=0.9, color='orange', linestyle='--', label='90%ãƒ©ã‚¤ãƒ³')
    ax1.set_xlabel('ç‰¹å¾´é‡æ•°', fontsize=12)
    ax1.set_ylabel('ç´¯ç©å¯„ä¸ç‡', fontsize=12)
    ax1.set_title('ç‰¹å¾´é‡ã®ç´¯ç©å¯„ä¸ç‡', fontsize=14, fontweight='bold')
    ax1.grid(True, alpha=0.3)
    ax1.legend()
    
    # 1-2. ã‚«ãƒ†ã‚´ãƒªåˆ¥å¯„ä¸ç‡
    ax2 = axes[0, 1]
    colors = plt.cm.Set3(range(len(category_df)))
    ax2.bar(range(len(category_df)), category_df['å¯„ä¸ç‡(%)'], color=colors)
    ax2.set_xticks(range(len(category_df)))
    ax2.set_xticklabels(category_df['ã‚«ãƒ†ã‚´ãƒª'], rotation=45, ha='right')
    ax2.set_ylabel('å¯„ä¸ç‡ (%)', fontsize=12)
    ax2.set_title('ç‰¹å¾´é‡ã‚«ãƒ†ã‚´ãƒªåˆ¥å¯„ä¸ç‡', fontsize=14, fontweight='bold')
    ax2.grid(True, alpha=0.3, axis='y')
    
    # 1-3. SHAPå€¤ã®åˆ†å¸ƒ
    ax3 = axes[1, 0]
    ax3.hist(df['mean_abs_shap'], bins=20, edgecolor='black', alpha=0.7)
    ax3.axvline(df['mean_abs_shap'].median(), color='r', linestyle='--', label=f'ä¸­å¤®å€¤={df["mean_abs_shap"].median():.4f}')
    ax3.axvline(df['mean_abs_shap'].mean(), color='g', linestyle='--', label=f'å¹³å‡å€¤={df["mean_abs_shap"].mean():.4f}')
    ax3.set_xlabel('SHAPå€¤', fontsize=12)
    ax3.set_ylabel('ç‰¹å¾´é‡æ•°', fontsize=12)
    ax3.set_title('SHAPå€¤ã®åˆ†å¸ƒ', fontsize=14, fontweight='bold')
    ax3.legend()
    ax3.grid(True, alpha=0.3, axis='y')
    
    # 1-4. LightGBM Gain vs SHAPæ•£å¸ƒå›³
    ax4 = axes[1, 1]
    scatter = ax4.scatter(df['lgb_gain'], df['mean_abs_shap'], alpha=0.6, s=100)
    ax4.set_xlabel('LightGBM Gain', fontsize=12)
    ax4.set_ylabel('SHAPå€¤', fontsize=12)
    ax4.set_title('LightGBM Gain vs SHAPå€¤', fontsize=14, fontweight='bold')
    ax4.grid(True, alpha=0.3)
    
    # ãƒˆãƒƒãƒ—3ã«ãƒ©ãƒ™ãƒ«ä»˜ã‘
    for idx, row in df.head(3).iterrows():
        ax4.annotate(row['feature'], 
                    (row['lgb_gain'], row['mean_abs_shap']),
                    xytext=(5, 5), textcoords='offset points',
                    fontsize=9, alpha=0.8)
    
    plt.tight_layout()
    output_path = Path(output_dir) / 'detailed_analysis.png'
    output_path.parent.mkdir(parents=True, exist_ok=True)
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"  [OK] {output_path}")
    
    # 2. ãƒ‘ãƒ¬ãƒ¼ãƒˆå›³
    fig, ax1 = plt.subplots(figsize=(14, 8))
    
    x = range(len(df))
    ax1.bar(x, df['mean_abs_shap'], color='steelblue', alpha=0.7)
    ax1.set_xlabel('ç‰¹å¾´é‡', fontsize=12)
    ax1.set_ylabel('SHAPå€¤', fontsize=12, color='steelblue')
    ax1.tick_params(axis='y', labelcolor='steelblue')
    ax1.set_xticks(x)
    ax1.set_xticklabels(df['feature'], rotation=90, fontsize=9)
    
    ax2 = ax1.twinx()
    ax2.plot(x, df['cumsum_ratio'] * 100, 'r-', marker='o', linewidth=2, markersize=4)
    ax2.axhline(y=80, color='orange', linestyle='--', alpha=0.5)
    ax2.set_ylabel('ç´¯ç©å¯„ä¸ç‡ (%)', fontsize=12, color='red')
    ax2.tick_params(axis='y', labelcolor='red')
    ax2.set_ylim([0, 105])
    
    plt.title('ç‰¹å¾´é‡é‡è¦åº¦ã®ãƒ‘ãƒ¬ãƒ¼ãƒˆå›³', fontsize=16, fontweight='bold', pad=20)
    plt.tight_layout()
    output_path = Path(output_dir) / 'pareto_chart.png'
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"  [OK] {output_path}")
    
    plt.close('all')


def suggest_improvements(df):
    """æ”¹å–„ææ¡ˆã‚’ç”Ÿæˆ"""
    print("\n" + "=" * 80)
    print("[TIP] å…·ä½“çš„ãªæ”¹å–„ææ¡ˆ")
    print("=" * 80)
    
    # Top3ç‰¹å¾´é‡ã®å¼·åŒ–æ¡ˆ
    print("\nã€1. Top3ç‰¹å¾´é‡ã®å¼·åŒ–ã€‘")
    top3 = df.head(3)
    for idx, row in top3.iterrows():
        print(f"\n {row['feature']} (SHAP={row['mean_abs_shap']:.4f})")
        
        if 'past_avg_sotai_chakujun' in row['feature']:
            print("  æ”¹å–„æ¡ˆ:")
            print("    - ç¾åœ¨: å˜ç´”å¹³å‡(ç›´è¿‘3èµ°)")
            print("    - ææ¡ˆ: æŒ‡æ•°åŠ é‡å¹³å‡(æœ€æ–°ãƒ¬ãƒ¼ã‚¹ã‚’é‡è¦–)")
            print("    - ã‚³ãƒ¼ãƒ‰ä¾‹:")
            print("      weights = [0.5, 0.3, 0.2]  # æœ€æ–°ã€2èµ°å‰ã€3èµ°å‰")
            print("      past_avg_sotai_chakujun = np.average(past_3_races, weights=weights)")
            
        elif 'umaban_kyori_interaction' in row['feature']:
            print("  æ”¹å–„æ¡ˆ:")
            print("    - ç¾åœ¨: umaban * kyori / 1000")
            print("    - ææ¡ˆ: éç·šå½¢å¤‰æ›ã§é•·è·é›¢Ã—å¤–æ ã®ãƒšãƒŠãƒ«ãƒ†ã‚£å¼·åŒ–")
            print("    - ã‚³ãƒ¼ãƒ‰ä¾‹:")
            print("      if kyori >= 2400 and umaban >= 13:")
            print("          penalty = 1.5")
            print("      elif kyori <= 1800 and umaban <= 3:")
            print("          bonus = 0.7")
            
        elif 'past_score' in row['feature']:
            print("  æ”¹å–„æ¡ˆ:")
            print("    - ç¾åœ¨: ã‚°ãƒ¬ãƒ¼ãƒ‰åˆ¥å›ºå®šå€ç‡")
            print("    - ææ¡ˆ: è³é‡‘é¡ãƒ™ãƒ¼ã‚¹ã®å‹•çš„é‡ã¿ä»˜ã‘")
            print("    - ã‚³ãƒ¼ãƒ‰ä¾‹:")
            print("      weight = prize_money / 10000000  # è³é‡‘1å„„å††ã§10.0")
    
    # å‰Šé™¤æ¨å¥¨
    print("\nã€2. ä¸è¦ç‰¹å¾´é‡ã®å‰Šé™¤ã€‘")
    low_features = df[df['mean_abs_shap'] < 0.005]['feature'].tolist()
    if low_features:
        print(f"å‰Šé™¤æ¨å¥¨: {len(low_features)}å€‹")
        for feat in low_features:
            print(f"  [ERROR] {feat}")
        print("\nå‰Šé™¤ã«ã‚ˆã‚‹æœŸå¾…åŠ¹æœ:")
        print("  - éå­¦ç¿’ãƒªã‚¹ã‚¯æ¸›å°‘")
        print("  - å­¦ç¿’æ™‚é–“çŸ­ç¸®")
        print("  - ãƒ¢ãƒ‡ãƒ«è§£é‡ˆæ€§å‘ä¸Š")
    
    # ä¸­ä½ç‰¹å¾´é‡ã®æ”¹å–„
    print("\nã€3. ä¸­ä½ç‰¹å¾´é‡ã®æ”¹å–„å¯èƒ½æ€§ã€‘")
    mid_features = df[(df['mean_abs_shap'] >= 0.01) & (df['mean_abs_shap'] < 0.05)]
    print(f"æ”¹å–„å€™è£œ: {len(mid_features)}å€‹")
    for idx, row in mid_features.iterrows():
        print(f"  [TOOL] {row['feature']:30s} SHAP={row['mean_abs_shap']:.4f}")
    
    print("\næ”¹å–„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ:")
    print("  - éç·šå½¢å¤‰æ›ã®è¿½åŠ ")
    print("  - ä»–ã®ç‰¹å¾´é‡ã¨ã®ç›¸äº’ä½œç”¨")
    print("  - æ™‚é–“çª“ã®èª¿æ•´(3ãƒ¶æœˆâ†’6ãƒ¶æœˆãªã©)")


def generate_markdown_report(df, category_df, model_name, output_dir):
    """Markdownãƒ¬ãƒãƒ¼ãƒˆè‡ªå‹•ç”Ÿæˆ
    
    Args:
        df: ç‰¹å¾´é‡é‡è¦åº¦DataFrame
        category_df: ã‚«ãƒ†ã‚´ãƒªåˆ¥é›†è¨ˆDataFrame
        model_name: ãƒ¢ãƒ‡ãƒ«å
        output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    """
    print("\n" + "=" * 80)
    print(f"[+] Markdownãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­: {model_name}")
    print("=" * 80)
    
    # ç¾åœ¨æ—¥æ™‚
    current_date = datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')
    
    # å‰Šé™¤æ¨å¥¨ç‰¹å¾´é‡
    low_impact = df[df['mean_abs_shap'] < 0.005].sort_values('mean_abs_shap', ascending=False)
    
    # Top3ã®å¯„ä¸ç‡
    total_shap = df['mean_abs_shap'].sum()
    top3_ratio = df.head(3)['mean_abs_shap'].sum() / total_shap * 100
    
    # ãƒ¬ãƒãƒ¼ãƒˆæœ¬æ–‡ç”Ÿæˆ
    report = f"""# SHAPåˆ†æãƒ¬ãƒãƒ¼ãƒˆ - {model_name}

## ğŸ“Š å®Ÿè¡Œæ—¥: {current_date}

---

## ğŸ¯ é‡è¦ãªç™ºè¦‹

### 1ï¸âƒ£ **éå»æˆç¸¾ç³»ã®ç‰¹å¾´é‡ãŒåœ§å€’çš„ã«é‡è¦**

**Top 3ã®ç‰¹å¾´é‡:**
"""
    
    # Top3è©³ç´°
    for i, (idx, row) in enumerate(df.head(3).iterrows(), 1):
        feature_ratio = row['mean_abs_shap'] / total_shap * 100
        report += f"{i}. **{row['feature']}** ({row['mean_abs_shap']:.3f}) - "
        
        if 'past_avg_sotai_chakujun' in row['feature']:
            report += "éå»ã®ç›¸å¯¾ç€é †\n"
            report += f"   - SHAPå€¤: {row['mean_abs_shap']:.3f} (ã¶ã£ã¡ãã‚Š1ä½)\n"
            report += f"   - LightGBM Gain: {row['lgb_gain']:.1f}\n"
            report += "   - æ„å‘³: ç›´è¿‘3èµ°ã®ç›¸å¯¾ç€é †(1-(ç€é †/å‡ºèµ°é ­æ•°))ã®å¹³å‡\n"
            report += "   - **çµè«–**: é¦¬ã®ç›´è¿‘ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒæœ€ã‚‚é‡è¦!\n\n"
        elif 'umaban_kyori_interaction' in row['feature']:
            report += "é¦¬ç•ªÃ—è·é›¢ã®ç›¸äº’ä½œç”¨\n"
            report += f"   - SHAPå€¤: {row['mean_abs_shap']:.3f}\n"
            report += f"   - LightGBM Gain: {row['lgb_gain']:.1f}\n"
            report += "   - æ„å‘³: é¦¬ç•ªã¨è·é›¢ã®çµ„ã¿åˆã‚ã›åŠ¹æœ\n"
            report += "   - **çµè«–**: å†…æ /å¤–æ ã¨é•·è·é›¢ã®çµ„ã¿åˆã‚ã›ãŒé‡è¦\n\n"
        elif 'past_score' in row['feature']:
            report += "ã‚°ãƒ¬ãƒ¼ãƒ‰åˆ¥éå»æˆç¸¾ã‚¹ã‚³ã‚¢\n"
            report += f"   - SHAPå€¤: {row['mean_abs_shap']:.3f}\n"
            report += f"   - LightGBM Gain: {row['lgb_gain']:.1f}\n"
            report += "   - æ„å‘³: ãƒ¬ãƒ¼ã‚¹ã‚°ãƒ¬ãƒ¼ãƒ‰ã‚’è€ƒæ…®ã—ãŸéå»3èµ°ã®é‡ã¿ä»˜ã‘ã‚¹ã‚³ã‚¢\n"
            report += "   - **çµè«–**: G1ã§1ç€ã¯é‡ãè©•ä¾¡ã•ã‚Œã‚‹\n\n"
        else:
            report += f"{row['feature']}\n"
            report += f"   - SHAPå€¤: {row['mean_abs_shap']:.3f}\n"
            report += f"   - LightGBM Gain: {row['lgb_gain']:.1f}\n\n"
    
    report += f"**Top3ã ã‘ã§å…¨ä½“å½±éŸ¿ã®{top3_ratio:.1f}%ã‚’å ã‚ã‚‹!**\n"
    for i, (idx, row) in enumerate(df.head(3).iterrows(), 1):
        feature_ratio = row['mean_abs_shap'] / total_shap * 100
        report += f"- {row['feature']}: {row['mean_abs_shap']:.3f} / {total_shap:.3f} = {feature_ratio:.1f}%\n"
    
    report += "\n---\n\n"
    
    # ã‚«ãƒ†ã‚´ãƒªåˆ¥åˆ†æ
    report += "### 2ï¸âƒ£ **ã‚«ãƒ†ã‚´ãƒªåˆ¥ç‰¹å¾´é‡ã®é‡è¦åº¦**\n\n"
    report += "**ç‰¹å¾´é‡ã‚«ãƒ†ã‚´ãƒªåˆ¥å¯„ä¸ç‡:**\n"
    for idx, row in category_df.head(5).iterrows():
        report += f"- **{row['ã‚«ãƒ†ã‚´ãƒª']}** ({row['å¯„ä¸ç‡(%)']:.1f}%) - {row['ç‰¹å¾´é‡æ•°']}å€‹ã®ç‰¹å¾´é‡\n"
    
    report += "\n**åˆ†æ:**\n"
    top_category = category_df.iloc[0]
    report += f"- {top_category['ã‚«ãƒ†ã‚´ãƒª']}ãŒ{top_category['å¯„ä¸ç‡(%)']:.1f}%ã§ãƒˆãƒƒãƒ—\n"
    report += f"- ãƒ¢ãƒ‡ãƒ«ã¯é¦¬ã®åŸºæœ¬èƒ½åŠ›ã‚’æœ€ã‚‚é‡è¦–ã—ã¦ã„ã‚‹\n"
    
    report += "\n---\n\n"
    
    # å‰Šé™¤æ¨å¥¨ç‰¹å¾´é‡
    report += "### 3ï¸âƒ£ **å‰Šé™¤æ¨å¥¨ç‰¹å¾´é‡ã®åˆ†æ**\n\n"
    
    if len(low_impact) > 0:
        report += f"**å‰Šé™¤å€™è£œ(SHAP < 0.005): {len(low_impact)}å€‹**\n\n"
        for idx, row in low_impact.iterrows():
            report += f"- `{row['feature']}` (SHAP={row['mean_abs_shap']:.6f}) âŒ\n"
        
        info_loss = low_impact['mean_abs_shap'].sum() / total_shap * 100
        report += f"\n**å‰Šé™¤ã«ã‚ˆã‚‹å½±éŸ¿:**\n"
        report += f"- ç‰¹å¾´é‡æ•°: {len(df)}å€‹ â†’ {len(df) - len(low_impact)}å€‹\n"
        report += f"- å‰Šæ¸›ç‡: {len(low_impact)/len(df)*100:.1f}%\n"
        report += f"- å¤±ã‚ã‚Œã‚‹æƒ…å ±é‡: {info_loss:.2f}%\n\n"
        report += "**æœŸå¾…åŠ¹æœ:**\n"
        report += "- éå­¦ç¿’ãƒªã‚¹ã‚¯æ¸›å°‘\n"
        report += "- å­¦ç¿’é€Ÿåº¦å‘ä¸Š\n"
        report += "- ãƒ¢ãƒ‡ãƒ«ã®è§£é‡ˆæ€§å‘ä¸Š\n"
    else:
        report += "**å‰Šé™¤æ¨å¥¨ã®ç‰¹å¾´é‡ã¯ã‚ã‚Šã¾ã›ã‚“ âœ…**\n\n"
        bottom3 = df.tail(3)
        report += "æœ€ä¸‹ä½3ã¤ã®ç‰¹å¾´é‡ã§ã‚‚ä¸€å®šã®è²¢çŒ®åº¦ãŒã‚ã‚Šã¾ã™:\n"
        for idx, row in bottom3.iterrows():
            report += f"- `{row['feature']}` (SHAP={row['mean_abs_shap']:.4f})\n"
        report += "\nã™ã¹ã¦ã®ç‰¹å¾´é‡ãŒæ„å‘³ã®ã‚ã‚‹è²¢çŒ®ã‚’ã—ã¦ã„ã¾ã™ï¼\n"
    
    report += "\n---\n\n"
    
    # ç´¯ç©å¯„ä¸ç‡
    report += "### 4ï¸âƒ£ **ç´¯ç©å¯„ä¸ç‡åˆ†æ**\n\n"
    for threshold in [0.5, 0.7, 0.8, 0.9]:
        n_features = (df['cumsum_ratio'] <= threshold).sum() + 1
        report += f"- **ç´¯ç©å¯„ä¸ç‡ {threshold*100:.0f}%**: Top{n_features}å€‹ã®ç‰¹å¾´é‡\n"
    
    report += "\n**ãƒ‘ãƒ¬ãƒ¼ãƒˆã®æ³•å‰‡:**\n"
    n_50 = (df['cumsum_ratio'] <= 0.5).sum() + 1
    report += f"- ä¸Šä½{n_50}å€‹ï¼ˆå…¨ä½“ã®{n_50/len(df)*100:.1f}%ï¼‰ã§å…¨ä½“ã®50%ã‚’èª¬æ˜\n"
    report += "- ç†æƒ³çš„ãªé‡è¦åº¦åˆ†å¸ƒã‚’å®Ÿç¾ï¼\n"
    
    report += "\n---\n\n"
    
    # æ”¹å–„ææ¡ˆ
    report += "## ğŸ”¥ æ”¹å–„ææ¡ˆ\n\n"
    report += "### âœ… ã™ãã§ãã‚‹æ”¹å–„\n\n"
    
    # å‰Šé™¤ææ¡ˆ
    if len(low_impact) > 0:
        report += "#### 1. **ä¸è¦ãªç‰¹å¾´é‡ã‚’å‰Šé™¤(æ¬¡å…ƒå‰Šæ¸›)**\n"
        report += "å‰Šé™¤å€™è£œ(SHAP < 0.005):\n"
        for idx, row in low_impact.iterrows():
            report += f"- `{row['feature']}` ({row['mean_abs_shap']:.6f}) âŒ\n"
        report += "\n"
    
    # Top3å¼·åŒ–
    report += "#### 2. **Top3ç‰¹å¾´é‡ã®å¼·åŒ–**\n\n"
    
    if 'past_avg_sotai_chakujun' in df.head(3)['feature'].values:
        report += "**past_avg_sotai_chakujunå¼·åŒ–æ¡ˆ:**\n"
        report += "- ç¾åœ¨: ç›´è¿‘3èµ°ã®å¹³å‡\n"
        report += "- æ”¹å–„: **æŒ‡æ•°åŠ é‡å¹³å‡**(æœ€æ–°ãƒ¬ãƒ¼ã‚¹ã‚’é‡è¦–)\n"
        report += "  - 3èµ°å‰: é‡ã¿0.2\n"
        report += "  - 2èµ°å‰: é‡ã¿0.3\n"
        report += "  - 1èµ°å‰: é‡ã¿0.5\n\n"
    
    if 'umaban_kyori_interaction' in df.head(3)['feature'].values:
        report += "**umaban_kyori_interactionå¼·åŒ–æ¡ˆ:**\n"
        report += "- ç¾åœ¨: umaban Ã— kyori / 1000\n"
        report += "- æ”¹å–„: **éç·šå½¢å¤‰æ›**\n"
        report += "  - é•·è·é›¢(2400m+) Ã— å¤–æ (13ç•ª+) â†’ ãƒšãƒŠãƒ«ãƒ†ã‚£å¤§\n"
        report += "  - çŸ­è·é›¢(1800m-) Ã— å†…æ (1-3ç•ª) â†’ ãƒœãƒ¼ãƒŠã‚¹\n\n"
    
    if 'past_score' in df.head(3)['feature'].values:
        report += "**past_scoreå¼·åŒ–æ¡ˆ:**\n"
        report += "- ç¾åœ¨: G1=1.0, G2=0.8, G3=0.6...\n"
        report += "- æ”¹å–„: **è³é‡‘ãƒ™ãƒ¼ã‚¹**ã®é‡ã¿ä»˜ã‘\n"
        report += "  - 1ç€è³é‡‘ãŒé«˜ã„ãƒ¬ãƒ¼ã‚¹ = ã‚ˆã‚Šé«˜è©•ä¾¡\n\n"
    
    report += "---\n\n"
    
    # çµ±è¨ˆã‚µãƒãƒªãƒ¼
    report += "## ğŸ“ˆ çµ±è¨ˆã‚µãƒãƒªãƒ¼\n\n"
    report += f"- **å…¨ç‰¹å¾´é‡æ•°**: {len(df)}å€‹\n"
    report += f"- **SHAPå€¤åˆè¨ˆ**: {total_shap:.4f}\n"
    report += f"- **SHAPå€¤å¹³å‡**: {df['mean_abs_shap'].mean():.4f}\n"
    report += f"- **SHAPå€¤ä¸­å¤®å€¤**: {df['mean_abs_shap'].median():.4f}\n"
    report += f"- **SHAPå€¤æ¨™æº–åå·®**: {df['mean_abs_shap'].std():.4f}\n"
    report += f"- **LightGBM Gainç›¸é–¢**: {df['mean_abs_shap'].corr(df['lgb_gain']):.4f}\n"
    
    report += "\n---\n\n"
    
    # æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
    report += "## ğŸ² æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³\n\n"
    
    if len(low_impact) > 0:
        report += "### å„ªå…ˆåº¦é«˜(ã™ãã‚„ã‚‹)\n"
        report += f"1. âœ… **{len(low_impact)}å€‹ã®ä¸è¦ç‰¹å¾´é‡ã‚’å‰Šé™¤**\n"
        report += "2. âœ… **Top3ç‰¹å¾´é‡ã‚’å¼·åŒ–**\n"
        report += "3. âœ… **ãƒ¢ãƒ‡ãƒ«å†å­¦ç¿’**\n\n"
    else:
        report += "### å„ªå…ˆåº¦é«˜(ã™ãã‚„ã‚‹)\n"
        report += "1. âœ… **Top3ç‰¹å¾´é‡ã‚’å¼·åŒ–**ï¼ˆæŒ‡æ•°åŠ é‡å¹³å‡ã€éç·šå½¢å¤‰æ›ï¼‰\n"
        report += "2. âœ… **ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã§åŠ¹æœæ¤œè¨¼**\n"
        report += "3. â³ **é–¾å€¤ã®å†èª¿æ•´**\n\n"
    
    report += "### å„ªå…ˆåº¦ä¸­(æ¤œè¨¼å¾Œã«å®Ÿæ–½)\n"
    report += "4. â³ **ä¸­ä½ç‰¹å¾´é‡ã®æ”¹å–„**ï¼ˆéç·šå½¢å¤‰æ›ã€ç›¸äº’ä½œç”¨è¿½åŠ ï¼‰\n"
    report += "5. â³ **éå»æˆç¸¾å‚ç…§æœŸé–“ã®èª¿æ•´**ï¼ˆ3èµ°â†’5èµ°ãªã©ï¼‰\n"
    report += "6. â³ **é¨æ‰‹ç‰¹å¾´é‡ã®ç²¾ç·»åŒ–**ï¼ˆç«¶é¦¬å ´åˆ¥ã«åˆ†å‰²ï¼‰\n\n"
    
    report += "### å„ªå…ˆåº¦ä½(ä½™è£•ãŒã‚ã‚Œã°)\n"
    report += "7. ğŸ”® **é¨æ‰‹Ã—é¦¬ã®ç›¸æ€§ç‰¹å¾´é‡ã‚’è¿½åŠ **\n"
    report += "8. ğŸ”® **è³é‡‘é¡ãƒ™ãƒ¼ã‚¹ã®ç‰¹å¾´é‡ã‚’è¿½åŠ **\n"
    
    report += "\n---\n\n"
    
    # çµè«–
    report += "## ğŸ’¡ çµè«–\n\n"
    report += "**SHAPåˆ†æã‹ã‚‰å¾—ã‚‰ã‚ŒãŸæœ€å¤§ã®çŸ¥è¦‹:**\n\n"
    
    top1 = df.iloc[0]
    top1_ratio = top1['mean_abs_shap'] / total_shap * 100
    report += f"> **ã€Œ{top1['feature']}ãŒå…¨ä½“ã®{top1_ratio:.1f}%ã‚’å ã‚ã€ä»–ã®ã™ã¹ã¦ã‚’åœ§å€’ã—ã¦ã„ã‚‹ã€**\n\n"
    
    report += "ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«ã¯:\n"
    report += "- âœ… é¦¬ã®éå»æˆç¸¾ã‚’æ­£ã—ãè©•ä¾¡ã§ãã¦ã„ã‚‹\n"
    
    kishu_count = len([f for f in df['feature'].values if 'kishu' in f])
    if kishu_count > 0:
        report += "- âœ… é¨æ‰‹ã®èƒ½åŠ›ã‚‚é©åˆ‡ã«è€ƒæ…®ã—ã¦ã„ã‚‹\n"
    
    futan_count = len([f for f in df['feature'].values if 'futan' in f])
    if futan_count > 0:
        report += "- âœ… æ–¤é‡ã®å½±éŸ¿ã‚‚æ‰ãˆã¦ã„ã‚‹\n"
    
    if len(low_impact) > 0:
        report += f"- âŒ ãƒã‚¤ã‚ºç‰¹å¾´é‡ãŒå¤šã™ãã‚‹({len(df)}å€‹ä¸­{len(low_impact)}å€‹ã¯ä¸è¦)\n"
    else:
        report += "- âœ… ã™ã¹ã¦ã®ç‰¹å¾´é‡ãŒæ„å‘³ã®ã‚ã‚‹è²¢çŒ®ã‚’ã—ã¦ã„ã‚‹\n"
    
    report += "- âŒ Topç‰¹å¾´é‡ã®ä½œã‚Šæ–¹ã«æ”¹å–„ä½™åœ°ã‚ã‚Š\n\n"
    
    if len(low_impact) > 0:
        report += "**æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:**\n"
        report += f"1. ä¸è¦ç‰¹å¾´é‡ã‚’å‰Šé™¤ã—ã¦{len(df) - len(low_impact)}å€‹ã«æ¸›ã‚‰ã™\n"
        report += "2. Top3ç‰¹å¾´é‡ã‚’å¼·åŒ–ï¼ˆæŒ‡æ•°åŠ é‡å¹³å‡ãªã©ï¼‰\n"
        report += "3. ãƒ¢ãƒ‡ãƒ«ã‚’å†å­¦ç¿’ã—ã¦çš„ä¸­ç‡ã‚’ç¢ºèª\n"
    else:
        report += "**æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:**\n"
        report += "1. Top3ç‰¹å¾´é‡ã‚’å¼·åŒ–ï¼ˆæŒ‡æ•°åŠ é‡å¹³å‡ã€éç·šå½¢å¤‰æ›ï¼‰\n"
        report += "2. ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã§å®Ÿéš›ã®çš„ä¸­ç‡æ”¹å–„ã‚’ç¢ºèª\n"
        report += "3. ã•ã‚‰ãªã‚‹ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°\n"
    
    # ãƒ•ã‚¡ã‚¤ãƒ«æ›¸ãå‡ºã—
    output_path = Path(output_dir) / f'{model_name}_analysis_report.md'
    output_path.parent.mkdir(parents=True, exist_ok=True)
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"  [OK] {output_path}")
    
    return report


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='SHAPåˆ†æçµæœã®è©³ç´°çµ±è¨ˆåˆ†æ')
    parser.add_argument('--input', type=str, required=True,
                        help='SHAPé‡è¦åº¦CSVãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ (ä¾‹: shap_analysis/tokyo_turf_3ageup_long/2023/tokyo_turf_3ageup_long_importance.csv)')
    parser.add_argument('--model-name', type=str, required=True,
                        help='ãƒ¢ãƒ‡ãƒ«å (ä¾‹: tokyo_turf_3ageup_long)')
    parser.add_argument('--output-dir', type=str, default=None,
                        help='å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã¨åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª)')
    
    args = parser.parse_args()
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è¨­å®š
    if args.output_dir:
        output_dir = args.output_dir
    else:
        # å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã¨åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        output_dir = str(Path(args.input).parent)
    
    df, category_df = analyze_feature_importance(args.input, args.model_name, output_dir)
    if df is not None:
        suggest_improvements(df)
        generate_markdown_report(df, category_df, args.model_name, output_dir)
        
        print("\n" + "=" * 80)
        print("[OK] åˆ†æå®Œäº†!")
        print("=" * 80)
        print("\nç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«:")
        print(f"  - {Path(output_dir) / 'detailed_analysis.png'}")
        print(f"  - {Path(output_dir) / 'pareto_chart.png'}")
        print(f"  - {Path(output_dir) / f'{args.model_name}_analysis_report.md'}")
        print("\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
        print("  1. ãƒ¬ãƒãƒ¼ãƒˆã‚’èª­ã‚“ã§æ”¹å–„å†…å®¹ã‚’ç¢ºèª")
        print("  2. ä¸è¦ç‰¹å¾´é‡ã‚’å‰Šé™¤")
        print("  3. Top3ç‰¹å¾´é‡ã‚’å¼·åŒ–")
        print("  4. ãƒ¢ãƒ‡ãƒ«å†å­¦ç¿’")
        print("  5. çš„ä¸­ç‡ã®å¤‰åŒ–ã‚’ç¢ºèª")
