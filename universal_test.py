#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ê±éÁî®Á´∂È¶¨‰∫àÊ∏¨„ÉÜ„Çπ„Éà„Çπ„ÇØ„É™„Éó„Éà

„Åì„ÅÆ„Çπ„ÇØ„É™„Éó„Éà„ÅØ„ÄÅË§áÊï∞„ÅÆ„É¢„Éá„É´„Éï„Ç°„Ç§„É´„Å´ÂØæÂøú„Åó„ÅüÁ´∂È¶¨‰∫àÊ∏¨„ÉÜ„Çπ„Éà„ÇíÂÆüË°å„Åó„Åæ„Åô„ÄÇ
model_creator.py„Åß‰ΩúÊàê„Åó„Åü„É¢„Éá„É´„Çí‰ΩøÁî®„Åó„Å¶‰∫àÊ∏¨„ÇíË°å„ÅÑ„ÄÅÁµêÊûú„Çí‰øùÂ≠ò„Åó„Åæ„Åô„ÄÇ
"""

import psycopg2
import pandas as pd
import pickle
import lightgbm as lgb
import numpy as np
import os
from pathlib import Path
from datetime import datetime
from keiba_constants import get_track_name, format_model_description
from model_config_loader import get_all_models, get_legacy_model


def save_results_with_append(df, filename, append_mode=True, output_dir='results'):
    """
    ÁµêÊûú„ÇíTSV„Éï„Ç°„Ç§„É´„Å´‰øùÂ≠òÔºàËøΩË®ò„É¢„Éº„ÉâÂØæÂøúÔºâ
    
    Args:
        df (DataFrame): ‰øùÂ≠ò„Åô„Çã„Éá„Éº„Çø„Éï„É¨„Éº„É†
        filename (str): ‰øùÂ≠òÂÖà„Éï„Ç°„Ç§„É´Âêç
        append_mode (bool): True=ËøΩË®ò„É¢„Éº„Éâ„ÄÅFalse=‰∏äÊõ∏„Åç„É¢„Éº„Éâ
        output_dir (str): Âá∫ÂäõÂÖà„Éá„Ç£„É¨„ÇØ„Éà„É™Ôºà„Éá„Éï„Ç©„É´„Éà: 'results'Ôºâ
    """
    # Âá∫Âäõ„Éá„Ç£„É¨„ÇØ„Éà„É™„Çí‰ΩúÊàêÔºàÂ≠òÂú®„Åó„Å™„ÅÑÂ†¥ÂêàÔºâ
    output_path = Path(output_dir)
    output_path.mkdir(exist_ok=True)
    
    # „Éï„Ç°„Ç§„É´„Éë„Çπ„Çí‰ΩúÊàê
    filepath = output_path / filename
    
    if append_mode and filepath.exists():
        # „Éï„Ç°„Ç§„É´„ÅåÊó¢„Å´Â≠òÂú®„Åô„ÇãÂ†¥Âêà„ÅØËøΩË®òÔºà„Éò„ÉÉ„ÉÄ„Éº„Å™„ÅóÔºâ
        print(f"üìù Êó¢Â≠ò„Éï„Ç°„Ç§„É´„Å´ËøΩË®ò: {filepath}")
        df.to_csv(filepath, mode='a', header=False, index=False, sep='\t', encoding='utf-8-sig')
    else:
        # „Éï„Ç°„Ç§„É´„ÅåÂ≠òÂú®„Åó„Å™„ÅÑÂ†¥Âêà„ÅØÊñ∞Ë¶è‰ΩúÊàêÔºà„Éò„ÉÉ„ÉÄ„Éº„ÅÇ„ÇäÔºâ
        print(f"üìã Êñ∞Ë¶è„Éï„Ç°„Ç§„É´‰ΩúÊàê: {filepath}")
        df.to_csv(filepath, index=False, sep='\t', encoding='utf-8-sig')


def predict_with_model(model_filename, track_code, kyoso_shubetsu_code, surface_type, 
                      min_distance, max_distance, test_year_start=2023, test_year_end=2023):
    """
    ÊåáÂÆö„Åó„Åü„É¢„Éá„É´„Åß‰∫àÊ∏¨„ÇíÂÆüË°å„Åô„ÇãÊ±éÁî®Èñ¢Êï∞
    
    Args:
        model_filename (str): ‰ΩøÁî®„Åô„Çã„É¢„Éá„É´„Éï„Ç°„Ç§„É´Âêç
        track_code (str): Á´∂È¶¨Â†¥„Ç≥„Éº„Éâ
        kyoso_shubetsu_code (str): Á´∂‰∫âÁ®ÆÂà•„Ç≥„Éº„Éâ
        surface_type (str): 'turf' or 'dirt'
        min_distance (int): ÊúÄÂ∞èË∑ùÈõ¢
        max_distance (int): ÊúÄÂ§ßË∑ùÈõ¢
        test_year_start (int): „ÉÜ„Çπ„ÉàÂØæË±°ÈñãÂßãÂπ¥ („Éá„Éï„Ç©„É´„Éà: 2023)
        test_year_end (int): „ÉÜ„Çπ„ÉàÂØæË±°ÁµÇ‰∫ÜÂπ¥ („Éá„Éï„Ç©„É´„Éà: 2023)
        
    Returns:
        tuple: (‰∫àÊ∏¨ÁµêÊûúDataFrame, „Çµ„Éû„É™„ÉºDataFrame, „É¨„Éº„ÇπÊï∞)
    """
    
    # PostgreSQL „Ç≥„Éç„ÇØ„Ç∑„Éß„É≥„ÅÆ‰ΩúÊàê
    conn = psycopg2.connect(
        host='localhost',
        port='5432',
        user='postgres',
        password='ahtaht88',
        dbname='keiba'
    )

    # „Éà„É©„ÉÉ„ÇØÊù°‰ª∂„ÇíÂãïÁöÑ„Å´Ë®≠ÂÆö
    if surface_type.lower() == 'turf':
        # Ëäù„ÅÆÂ†¥Âêà
        track_condition = "cast(rase.track_code as integer) between 10 and 22"
        baba_condition = "ra.babajotai_code_shiba"
    else:
        # „ÉÄ„Éº„Éà„ÅÆÂ†¥Âêà
        track_condition = "cast(rase.track_code as integer) between 23 and 29"
        baba_condition = "ra.babajotai_code_dirt"

    # Ë∑ùÈõ¢Êù°‰ª∂„ÇíË®≠ÂÆö
    if max_distance == 9999:
        distance_condition = f"cast(rase.kyori as integer) >= {min_distance}"
    else:
        distance_condition = f"cast(rase.kyori as integer) between {min_distance} and {max_distance}"

    # Á´∂‰∫âÁ®ÆÂà•„ÇíË®≠ÂÆö
    if kyoso_shubetsu_code == '12':
        # 3Ê≠≥Êà¶
        kyoso_shubetsu_condition = "cast(rase.kyoso_shubetsu_code as integer) = 12"
    elif kyoso_shubetsu_code == '13':
        kyoso_shubetsu_condition = "cast(rase.kyoso_shubetsu_code as integer) >= 13"

    # SQL„ÇØ„Ç®„É™„ÇíÂãïÁöÑ„Å´ÁîüÊàê
    sql = f"""
    select * from (
        select
        ra.kaisai_nen,
        ra.kaisai_tsukihi,
        ra.race_bango,
        seum.umaban,
        seum.bamei,
        ra.keibajo_code,
        CASE 
            WHEN ra.keibajo_code = '01' THEN 'Êú≠Âπå' 
            WHEN ra.keibajo_code = '02' THEN 'ÂáΩÈ§®' 
            WHEN ra.keibajo_code = '03' THEN 'Á¶èÂ≥∂' 
            WHEN ra.keibajo_code = '04' THEN 'Êñ∞ÊΩü' 
            WHEN ra.keibajo_code = '05' THEN 'Êù±‰∫¨' 
            WHEN ra.keibajo_code = '06' THEN '‰∏≠Â±±' 
            WHEN ra.keibajo_code = '07' THEN '‰∏≠‰∫¨' 
            WHEN ra.keibajo_code = '08' THEN '‰∫¨ÈÉΩ' 
            WHEN ra.keibajo_code = '09' THEN 'Èò™Á•û' 
            WHEN ra.keibajo_code = '10' THEN 'Â∞èÂÄâ' 
            ELSE '' 
        END keibajo_name,
        ra.kyori,
        ra.tenko_code,
        {baba_condition} as babajotai_code,
        ra.grade_code,
        ra.kyoso_joken_code,
        ra.kyoso_shubetsu_code,
        ra.track_code,
        seum.ketto_toroku_bango,
        seum.wakuban,
        cast(seum.umaban as integer) as umaban_numeric,
        seum.barei,
        seum.kishu_code,
        seum.chokyoshi_code,
        seum.futan_juryo,
        seum.seibetsu_code,
        CASE WHEN seum.seibetsu_code = '1' THEN '1' ELSE '0' END AS mare_horse,
        CASE WHEN seum.seibetsu_code = '2' THEN '1' ELSE '0' END AS femare_horse,
        CASE WHEN seum.seibetsu_code = '3' THEN '1' ELSE '0' END AS sen_horse,
        CASE WHEN {baba_condition} = '1' THEN '1' ELSE '0' END AS baba_good,
        CASE WHEN {baba_condition} = '2' THEN '1' ELSE '0' END AS baba_slightly_heavy,
        CASE WHEN {baba_condition} = '3' THEN '1' ELSE '0' END AS baba_heavy,
        CASE WHEN {baba_condition} = '4' THEN '1' ELSE '0' END AS baba_defective,
        CASE WHEN ra.tenko_code = '1' THEN '1' ELSE '0' END AS tenko_fine,
        CASE WHEN ra.tenko_code = '2' THEN '1' ELSE '0' END AS tenko_cloudy,
        CASE WHEN ra.tenko_code = '3' THEN '1' ELSE '0' END AS tenko_rainy,
        CASE WHEN ra.tenko_code = '4' THEN '1' ELSE '0' END AS tenko_drizzle,
        CASE WHEN ra.tenko_code = '5' THEN '1' ELSE '0' END AS tenko_snow,
        CASE WHEN ra.tenko_code = '6' THEN '1' ELSE '0' END AS tenko_light_snow,
        nullif(cast(seum.tansho_odds as float), 0) / 10 as tansho_odds,
        nullif(cast(seum.tansho_ninkijun as integer), 0) as tansho_ninkijun_numeric,
        nullif(cast(seum.kakutei_chakujun as integer), 0) as kakutei_chakujun_numeric,
        1.0 / nullif(cast(seum.kakutei_chakujun as integer), 0) as chakujun_score,
        AVG(
            1 - (cast(seum.kakutei_chakujun as float) / cast(ra.shusso_tosu as float))
        ) OVER (
            PARTITION BY seum.ketto_toroku_bango
            ORDER BY cast(ra.kaisai_nen as integer), cast(ra.kaisai_tsukihi as integer)
            ROWS BETWEEN 3 PRECEDING AND 1 PRECEDING
        ) AS past_avg_sotai_chakujun,
        AVG(
            cast(ra.kyori as integer) /
            NULLIF(
                FLOOR(cast(seum.soha_time as integer) / 1000) * 60 +
                FLOOR((cast(seum.soha_time as integer) % 1000) / 10) +
                (cast(seum.soha_time as integer) % 10) * 0.1,
                0
            )
        ) OVER (
            PARTITION BY seum.ketto_toroku_bango
            ORDER BY cast(ra.kaisai_nen as integer), cast(ra.kaisai_tsukihi as integer)
            ROWS BETWEEN 3 PRECEDING AND 1 PRECEDING
        ) AS time_index,
        SUM(
            CASE 
                WHEN seum.kakutei_chakujun = '01' THEN 100
                WHEN seum.kakutei_chakujun = '02' THEN 80
                WHEN seum.kakutei_chakujun = '03' THEN 60
                WHEN seum.kakutei_chakujun = '04' THEN 40
                WHEN seum.kakutei_chakujun = '05' THEN 30
                WHEN seum.kakutei_chakujun = '06' THEN 20
                WHEN seum.kakutei_chakujun = '07' THEN 10
                ELSE 5 
            END
            * CASE 
                WHEN ra.grade_code = 'A' THEN 1.00
                WHEN ra.grade_code = 'B' THEN 0.80
                WHEN ra.grade_code = 'C' THEN 0.60
                WHEN ra.grade_code <> 'A' AND ra.grade_code <> 'B' AND ra.grade_code <> 'C' AND ra.kyoso_joken_code = '999' THEN 0.50
                WHEN ra.grade_code <> 'A' AND ra.grade_code <> 'B' AND ra.grade_code <> 'C' AND ra.kyoso_joken_code = '016' THEN 0.40
                WHEN ra.grade_code <> 'A' AND ra.grade_code <> 'B' AND ra.grade_code <> 'C' AND ra.kyoso_joken_code = '010' THEN 0.30
                WHEN ra.grade_code <> 'A' AND ra.grade_code <> 'B' AND ra.grade_code <> 'C' AND ra.kyoso_joken_code = '005' THEN 0.20
                ELSE 0.10
            END
        ) OVER (
            PARTITION BY seum.ketto_toroku_bango
            ORDER BY cast(ra.kaisai_nen as integer), cast(ra.kaisai_tsukihi as integer)
            ROWS BETWEEN 3 PRECEDING AND 1 PRECEDING  
        ) AS past_score,
        CASE 
            WHEN AVG(
                CASE 
                    WHEN cast(seum.kohan_3f as integer) > 0 AND cast(seum.kohan_3f as integer) < 999 THEN
                    CAST(seum.kohan_3f AS FLOAT) / 10
                    ELSE NULL
                END
            ) OVER (
                PARTITION BY seum.ketto_toroku_bango
                ORDER BY cast(ra.kaisai_nen as integer), cast(ra.kaisai_tsukihi as integer)
                ROWS BETWEEN 3 PRECEDING AND 1 PRECEDING
            ) IS NOT NULL THEN
            AVG(
                CASE 
                    WHEN cast(seum.kohan_3f as integer) > 0 AND cast(seum.kohan_3f as integer) < 999 THEN
                    CAST(seum.kohan_3f AS FLOAT) / 10
                    ELSE NULL
                END
            ) OVER (
                PARTITION BY seum.ketto_toroku_bango
                ORDER BY cast(ra.kaisai_nen as integer), cast(ra.kaisai_tsukihi as integer)
                ROWS BETWEEN 3 PRECEDING AND 1 PRECEDING
            ) - 
            CASE
                WHEN cast(ra.kyori as integer) <= 1600 THEN 33.5
                WHEN cast(ra.kyori as integer) <= 2000 THEN 35.0
                WHEN cast(ra.kyori as integer) <= 2400 THEN 36.0
                ELSE 37.0
            END
            ELSE 0
        END AS kohan_3f_index
        ,nullif(cast(nullif(trim(hr.haraimodoshi_fukusho_1a), '') as integer), 0) as Ë§áÂãù1ÁùÄÈ¶¨Áï™
        ,nullif(cast(nullif(trim(hr.haraimodoshi_fukusho_1b), '') as float), 0) / 100 as Ë§áÂãù1ÁùÄ„Ç™„ÉÉ„Ç∫
        ,nullif(cast(nullif(trim(hr.haraimodoshi_fukusho_1c), '') as integer), 0) as Ë§áÂãù1ÁùÄ‰∫∫Ê∞ó
        ,nullif(cast(nullif(trim(hr.haraimodoshi_fukusho_2a), '') as integer), 0) as Ë§áÂãù2ÁùÄÈ¶¨Áï™
        ,nullif(cast(nullif(trim(hr.haraimodoshi_fukusho_2b), '') as float), 0) / 100 as Ë§áÂãù2ÁùÄ„Ç™„ÉÉ„Ç∫
        ,nullif(cast(nullif(trim(hr.haraimodoshi_fukusho_2c), '') as integer), 0) as Ë§áÂãù2ÁùÄ‰∫∫Ê∞ó
        ,nullif(cast(nullif(trim(hr.haraimodoshi_fukusho_3a), '') as integer), 0) as Ë§áÂãù3ÁùÄÈ¶¨Áï™
        ,nullif(cast(nullif(trim(hr.haraimodoshi_fukusho_3b), '') as float), 0) / 100 as Ë§áÂãù3ÁùÄ„Ç™„ÉÉ„Ç∫
        ,nullif(cast(nullif(trim(hr.haraimodoshi_fukusho_3c), '') as integer), 0) as Ë§áÂãù3ÁùÄ‰∫∫Ê∞ó
        ,cast(substring(trim(hr.haraimodoshi_umaren_1a), 1, 2) as integer) as È¶¨ÈÄ£È¶¨Áï™1
        ,cast(substring(trim(hr.haraimodoshi_umaren_1a), 3, 2) as integer) as È¶¨ÈÄ£È¶¨Áï™2
        ,nullif(cast(nullif(trim(hr.haraimodoshi_umaren_1b), '') as float), 0) / 100 as È¶¨ÈÄ£„Ç™„ÉÉ„Ç∫
        ,cast(substring(trim(hr.haraimodoshi_wide_1a), 1, 2) as integer) as „ÉØ„Ç§„Éâ1_2È¶¨Áï™1
        ,cast(substring(trim(hr.haraimodoshi_wide_1a), 3, 2) as integer) as „ÉØ„Ç§„Éâ1_2È¶¨Áï™2
        ,cast(substring(trim(hr.haraimodoshi_wide_2a), 1, 2) as integer) as „ÉØ„Ç§„Éâ2_3ÁùÄÈ¶¨Áï™1
        ,cast(substring(trim(hr.haraimodoshi_wide_2a), 3, 2) as integer) as „ÉØ„Ç§„Éâ2_3ÁùÄÈ¶¨Áï™2
        ,cast(substring(trim(hr.haraimodoshi_wide_3a), 1, 2) as integer) as „ÉØ„Ç§„Éâ1_3ÁùÄÈ¶¨Áï™1
        ,cast(substring(trim(hr.haraimodoshi_wide_3a), 3, 2) as integer) as „ÉØ„Ç§„Éâ1_3ÁùÄÈ¶¨Áï™2
        ,nullif(cast(nullif(trim(hr.haraimodoshi_wide_1b), '') as float), 0) / 100 as „ÉØ„Ç§„Éâ1_2„Ç™„ÉÉ„Ç∫
        ,nullif(cast(nullif(trim(hr.haraimodoshi_wide_2b), '') as float), 0) / 100 as „ÉØ„Ç§„Éâ2_3„Ç™„ÉÉ„Ç∫
        ,nullif(cast(nullif(trim(hr.haraimodoshi_wide_3b), '') as float), 0) / 100 as „ÉØ„Ç§„Éâ1_3„Ç™„ÉÉ„Ç∫
        ,cast(substring(trim(hr.haraimodoshi_umatan_1a), 1, 2) as integer) as È¶¨ÂçòÈ¶¨Áï™1
        ,cast(substring(trim(hr.haraimodoshi_umatan_1a), 3, 2) as integer) as È¶¨ÂçòÈ¶¨Áï™2
        ,nullif(cast(nullif(trim(hr.haraimodoshi_umatan_1b), '') as float), 0) / 100 as È¶¨Âçò„Ç™„ÉÉ„Ç∫
        ,nullif(cast(nullif(trim(hr.haraimodoshi_sanrenpuku_1b), '') as float), 0) / 100 as ÔºìÈÄ£Ë§á„Ç™„ÉÉ„Ç∫
    from
        jvd_ra ra 
        inner join ( 
            select
                se.kaisai_nen
                , se.kaisai_tsukihi
                , se.keibajo_code
                , se.race_bango
                , se.kakutei_chakujun
                , se.ketto_toroku_bango
                , se.bamei
                , se.wakuban
                , se.umaban
                , se.barei
                , se.seibetsu_code
                , se.futan_juryo
                , se.kishu_code
                , se.chokyoshi_code
                , se.tansho_odds
                , se.tansho_ninkijun
                , se.kohan_3f
                , se.soha_time
            from
                jvd_se se 
            where
                se.kohan_3f <> '000' 
                and se.kohan_3f <> '999'
        ) seum 
            on ra.kaisai_nen = seum.kaisai_nen 
            and ra.kaisai_tsukihi = seum.kaisai_tsukihi 
            and ra.keibajo_code = seum.keibajo_code 
            and ra.race_bango = seum.race_bango
        inner join jvd_hr hr
            on ra.kaisai_nen = hr.kaisai_nen 
            and ra.kaisai_tsukihi = hr.kaisai_tsukihi 
            and ra.keibajo_code = hr.keibajo_code 
            and ra.race_bango = hr.race_bango
    where
        cast(ra.kaisai_nen as integer) between {test_year_start} and {test_year_end}  --„ÉÜ„Çπ„ÉàÂπ¥ÁØÑÂõ≤
    ) rase 
    where 
    rase.keibajo_code = '{track_code}'
    and {kyoso_shubetsu_condition}
    and {track_condition}
    and {distance_condition}
    """

    # „Éá„Éº„Çø„ÇíÂèñÂæó
    df = pd.read_sql_query(sql=sql, con=conn)
    conn.close()
    
    if len(df) == 0:
        print(f"‚ùå {model_filename} „Å´ÂØæÂøú„Åô„Çã„ÉÜ„Çπ„Éà„Éá„Éº„Çø„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„Åß„Åó„Åü„ÄÇ")
        return None, None, 0

    print(f"üìä „ÉÜ„Çπ„Éà„Éá„Éº„Çø‰ª∂Êï∞: {len(df)}‰ª∂")

    # È¶¨Âêç„Å†„Åë„ÅØ‰øùÂ≠ò„Åó„Å¶„Åä„Åè
    horse_names = df['bamei'].copy()
    
    # Êï∞ÂÄ§„Éá„Éº„Çø„Å†„Åë„ÇíÂâçÂá¶ÁêÜ
    numeric_columns = df.columns.drop(['bamei', 'keibajo_name'])  # È¶¨Âêç‰ª•Â§ñ„ÅÆÂàó„ÇíÂèñÂæó
    df[numeric_columns] = df[numeric_columns].apply(pd.to_numeric, errors='coerce')
    df[numeric_columns] = df[numeric_columns].replace('0', np.nan)
    df[numeric_columns] = df[numeric_columns].fillna(0)
    
    # ‰øùÂ≠ò„Åó„Å¶„Åä„ÅÑ„ÅüÈ¶¨Âêç„ÇíÊàª„Åô
    df['bamei'] = horse_names

    # ÁâπÂæ¥Èáè„ÇíÈÅ∏ÊäûÔºàmodel_creator.py„Å®Âêå„ÅòÁâπÂæ¥ÈáèÔºâ
    X = df.loc[:, [
        "kyori",
        "tenko_code",  
        "babajotai_code", 
        "seibetsu_code",
        "futan_juryo",
        "past_score",
        "kohan_3f_index",
        "past_avg_sotai_chakujun",
        "time_index",
        # "mare_horse",
        # "femare_horse",
        # "sen_horse",
        # "baba_good",
        # "baba_slightly_heavy",
        # "baba_heavy",
        # "baba_defective",
        # "tenko_fine",
        # "tenko_cloudy",
        # "tenko_rainy",
        # "tenko_drizzle",
        # "tenko_snow",
        # "tenko_light_snow",
    ]].astype(float)
    
    # È´òÊÄßËÉΩ„Å™Ê¥æÁîüÁâπÂæ¥Èáè„ÇíËøΩÂä†ÔºÅÔºàmodel_creator.py„Å®Âêå„ÅòÔºâ
    # Êû†Áï™„Å®È†≠Êï∞„ÅÆÊØîÁéáÔºàÂÜÖÊû†ÊúâÂà©Â∫¶Ôºâ
    max_wakuban = df.groupby(['kaisai_nen', 'kaisai_tsukihi', 'race_bango'])['wakuban'].transform('max')
    df['wakuban_ratio'] = df['wakuban'] / max_wakuban
    X['wakuban_ratio'] = df['wakuban_ratio']
    
    # Êñ§Èáè„Å®È¶¨ÈΩ¢„ÅÆÊØîÁéáÔºàËã•È¶¨„ÅÆË≤†ÊãÖËÉΩÂäõÔºâ
    df['futan_per_barei'] = df['futan_juryo'] / df['barei'].replace(0, 1)
    X['futan_per_barei'] = df['futan_per_barei']
    
    # üî•ÊîπÂñÑ„Åï„Çå„ÅüÁâπÂæ¥Èáèüî•
    # 2. futan_per_barei„ÅÆÈùûÁ∑öÂΩ¢Â§âÊèõ
    df['futan_per_barei_log'] = np.log(df['futan_per_barei'].clip(lower=0.1))
    X['futan_per_barei_log'] = df['futan_per_barei_log']
    
    # ÊúüÂæÖÊñ§Èáè„Åã„Çâ„ÅÆÂ∑ÆÂàÜÔºàÂπ¥ÈΩ¢Âà•ÊúüÂæÖÊñ§Èáè„Å®„ÅÆÂ∑ÆÔºâ
    expected_weight_by_age = {2: 48, 3: 52, 4: 55, 5: 57, 6: 57, 7: 56, 8: 55}
    df['futan_deviation'] = df.apply(
        lambda row: row['futan_juryo'] - expected_weight_by_age.get(row['barei'], 55), 
        axis=1
    )
    X['futan_deviation'] = df['futan_deviation']

    # È¶¨Áï™√óË∑ùÈõ¢„ÅÆÁõ∏‰∫í‰ΩúÁî®ÔºàÂÜÖÂ§ñÊû†„ÅÆË∑ùÈõ¢ÈÅ©ÊÄßÔºâ
    df['umaban_kyori_interaction'] = df['umaban_numeric'] * df['kyori'] / 1000  # „Çπ„Ç±„Éº„É´Ë™øÊï¥
    X['umaban_kyori_interaction'] = df['umaban_kyori_interaction']
    
    # 4. Ë§áÊï∞„ÅÆ„Éî„Éº„ÇØÂπ¥ÈΩ¢„Éë„Çø„Éº„É≥
    df['barei_peak_distance'] = abs(df['barei'] - 4)  # 4Ê≠≥„Çí„Éî„Éº„ÇØ„Å®‰ªÆÂÆöÔºàÊó¢Â≠òÔºâ
    X['barei_peak_distance'] = df['barei_peak_distance']
    
    # 3Ê≠≥Áü≠Ë∑ùÈõ¢„Éî„Éº„ÇØÔºàÊó©ÁÜüÂûãÔºâ
    df['barei_peak_short'] = abs(df['barei'] - 3)
    X['barei_peak_short'] = df['barei_peak_short']
    
    # # 5Ê≠≥Èï∑Ë∑ùÈõ¢„Éî„Éº„ÇØÔºàÊô©ÊàêÂûãÔºâ
    # df['barei_peak_long'] = abs(df['barei'] - 5)
    # X['barei_peak_long'] = df['barei_peak_long']

    # 5. Êû†Áï™„Éê„Ç§„Ç¢„Çπ„Çπ„Ç≥„Ç¢ÔºàÊû†Áï™„ÅÆÊ≠¥Âè≤ÁöÑÂÑ™‰ΩçÊÄß„ÇíÊï∞ÂÄ§ÂåñÔºâ
    # Êû†Áï™Âà•„ÅÆÊ≠¥Âè≤ÁöÑÁùÄÈ†ÜÂàÜÂ∏É„ÇíË®àÁÆó
    wakuban_stats = df.groupby('wakuban').agg({
        'kakutei_chakujun_numeric': ['mean', 'std', 'count']
    }).round(4)
    wakuban_stats.columns = ['waku_avg_rank', 'waku_std_rank', 'waku_count']
    wakuban_stats = wakuban_stats.reset_index()
    
    # ÂÖ®‰ΩìÂπ≥Âùá„Åã„Çâ„ÅÆÂÅèÂ∑Æ„Åß„Éê„Ç§„Ç¢„Çπ„Çπ„Ç≥„Ç¢„ÇíË®àÁÆó
    overall_avg_rank = df['kakutei_chakujun_numeric'].mean()
    wakuban_stats['wakuban_bias_score'] = (overall_avg_rank - wakuban_stats['waku_avg_rank']) / wakuban_stats['waku_std_rank']
    wakuban_stats['wakuban_bias_score'] = wakuban_stats['wakuban_bias_score'].fillna(0)  # NaN„Çí0„ÅßÂüã„ÇÅ„Çã
    
    # DataFrame„Å´„Éû„Éº„Ç∏
    df = df.merge(wakuban_stats[['wakuban', 'wakuban_bias_score']], on='wakuban', how='left')
    X['wakuban_bias_score'] = df['wakuban_bias_score']

    # „É¨„Éº„ÇπÂÜÖ„Åß„ÅÆÈ¶¨Áï™Áõ∏ÂØæ‰ΩçÁΩÆÔºàÈ†≠Êï∞„Å´„Çà„ÇãÊ≠£Ë¶èÂåñÔºâ
    df['umaban_percentile'] = df.groupby(['kaisai_nen', 'kaisai_tsukihi', 'race_bango'])['umaban_numeric'].transform(
        lambda x: x.rank(pct=True)
    )
    X['umaban_percentile'] = df['umaban_percentile']
    
    # 2025/10/15 ËøΩÂä†

    # # 2025/10/15 ËøΩÂä†

    # „Ç´„ÉÜ„Ç¥„É™Â§âÊï∞„Çí‰ΩúÊàê
    # X['kyori'] = X['kyori'].astype('category')
    # X['tenko_code'] = X['tenko_code'].astype('category')
    # X['babajotai_code'] = X['babajotai_code'].astype('category')
    # X['seibetsu_code'] = X['seibetsu_code'].astype('category')

    # „É¢„Éá„É´„Çí„É≠„Éº„Éâ
    try:
        with open(model_filename, 'rb') as model_file:
            model = pickle.load(model_file)
    except FileNotFoundError:
        print(f"‚ùå „É¢„Éá„É´„Éï„Ç°„Ç§„É´ {model_filename} „ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„ÄÇ")
        return None, None, 0

    # „Ç∑„Ç∞„É¢„Ç§„ÉâÈñ¢Êï∞„ÇíÂÆöÁæ©
    def sigmoid(x):
        """ÂÄ§„Çí0-1„ÅÆÁØÑÂõ≤„Å´Âèé„ÇÅ„Çã„ÇàÔΩû"""
        return 1 / (1 + np.exp(-x))

    # ‰∫àÊ∏¨„ÇíÂÆüË°å„Åó„Å¶„ÄÅ„Ç∑„Ç∞„É¢„Ç§„ÉâÈñ¢Êï∞„ÅßÂ§âÊèõ
    raw_scores = model.predict(X)
    df['predicted_chakujun_score'] = sigmoid(raw_scores)

    # „Éá„Éº„Çø„Çí„ÇΩ„Éº„Éà
    df = df.sort_values(by=['kaisai_nen', 'kaisai_tsukihi', 'race_bango', 'umaban'], ascending=True)

    # „Ç∞„É´„Éº„ÉóÂÜÖ„Åß„ÅÆ„Çπ„Ç≥„Ç¢È†Ü‰Ωç„ÇíË®àÁÆó
    df['score_rank'] = df.groupby(['kaisai_nen', 'kaisai_tsukihi', 'race_bango'])['predicted_chakujun_score'].rank(method='min', ascending=False)

    # kakutei_chakujun_numeric „Å® score_rank „ÇíÊï¥Êï∞„Å´Â§âÊèõ
    df['kakutei_chakujun_numeric'] = df['kakutei_chakujun_numeric'].fillna(0).astype(int)
    df['tansho_ninkijun_numeric'] = df['tansho_ninkijun_numeric'].fillna(0).astype(int)
    df['score_rank'] = df['score_rank'].fillna(0).astype(int)
    
    # surface_typeÂàó„ÇíËøΩÂä†ÔºàËäù„Éª„ÉÄ„Éº„ÉàÂå∫ÂàÜÔºâ
    from keiba_constants import get_surface_name
    df['surface_type_name'] = get_surface_name(surface_type)

    # ÂøÖË¶Å„Å™Âàó„ÇíÈÅ∏Êäû
    output_columns = ['keibajo_name',
                      'kaisai_nen', 
                      'kaisai_tsukihi', 
                      'race_bango',
                      'surface_type_name',
                      'kyori',
                      'umaban', 
                      'bamei', 
                      'tansho_odds', 
                      'tansho_ninkijun_numeric', 
                      'kakutei_chakujun_numeric', 
                      'score_rank', 
                      'predicted_chakujun_score',
                      'Ë§áÂãù1ÁùÄÈ¶¨Áï™',
                      'Ë§áÂãù1ÁùÄ„Ç™„ÉÉ„Ç∫',
                      'Ë§áÂãù1ÁùÄ‰∫∫Ê∞ó',
                      'Ë§áÂãù2ÁùÄÈ¶¨Áï™',
                      'Ë§áÂãù2ÁùÄ„Ç™„ÉÉ„Ç∫',
                      'Ë§áÂãù2ÁùÄ‰∫∫Ê∞ó',
                      'Ë§áÂãù3ÁùÄÈ¶¨Áï™',
                      'Ë§áÂãù3ÁùÄ„Ç™„ÉÉ„Ç∫',
                      'Ë§áÂãù3ÁùÄ‰∫∫Ê∞ó',
                      'È¶¨ÈÄ£È¶¨Áï™1',
                      'È¶¨ÈÄ£È¶¨Áï™2',
                      'È¶¨ÈÄ£„Ç™„ÉÉ„Ç∫',
                      '„ÉØ„Ç§„Éâ1_2È¶¨Áï™1',
                      '„ÉØ„Ç§„Éâ1_2È¶¨Áï™2',
                      '„ÉØ„Ç§„Éâ2_3ÁùÄÈ¶¨Áï™1',
                      '„ÉØ„Ç§„Éâ2_3ÁùÄÈ¶¨Áï™2',
                      '„ÉØ„Ç§„Éâ1_3ÁùÄÈ¶¨Áï™1',
                      '„ÉØ„Ç§„Éâ1_3ÁùÄÈ¶¨Áï™2',
                      '„ÉØ„Ç§„Éâ1_2„Ç™„ÉÉ„Ç∫',
                      '„ÉØ„Ç§„Éâ2_3„Ç™„ÉÉ„Ç∫',
                      '„ÉØ„Ç§„Éâ1_3„Ç™„ÉÉ„Ç∫',
                      'È¶¨ÂçòÈ¶¨Áï™1',
                      'È¶¨ÂçòÈ¶¨Áï™2',
                      'È¶¨Âçò„Ç™„ÉÉ„Ç∫',
                      'ÔºìÈÄ£Ë§á„Ç™„ÉÉ„Ç∫',]
    output_df = df[output_columns]

    # ÂàóÂêç„ÇíÂ§âÊõ¥
    output_df = output_df.rename(columns={
        'keibajo_name': 'Á´∂È¶¨Â†¥',
        'kaisai_nen': 'ÈñãÂÇ¨Âπ¥',
        'kaisai_tsukihi': 'ÈñãÂÇ¨Êó•',
        'race_bango': '„É¨„Éº„ÇπÁï™Âè∑',
        'surface_type_name': 'Ëäù„ÉÄÂå∫ÂàÜ',
        'kyori': 'Ë∑ùÈõ¢',
        'umaban': 'È¶¨Áï™',
        'bamei': 'È¶¨Âêç',
        'tansho_odds': 'ÂçòÂãù„Ç™„ÉÉ„Ç∫',
        'tansho_ninkijun_numeric': '‰∫∫Ê∞óÈ†Ü',
        'kakutei_chakujun_numeric': 'Á¢∫ÂÆöÁùÄÈ†Ü',
        'score_rank': '‰∫àÊ∏¨È†Ü‰Ωç',
        'predicted_chakujun_score': '‰∫àÊ∏¨„Çπ„Ç≥„Ç¢'
    })

    # Ê≠£„Åó„ÅÑ„É¨„Éº„ÇπÊï∞„ÅÆË®àÁÆóÊñπÊ≥ï„ÅØ„Åì„ÇåÔΩûÔºÅ
    race_count = len(output_df.groupby(['ÈñãÂÇ¨Âπ¥', 'ÈñãÂÇ¨Êó•', '„É¨„Éº„ÇπÁï™Âè∑']))

    # ÁöÑ‰∏≠Áéá„ÉªÂõûÂèéÁéáË®àÁÆóÔºàÂÖÉ„ÅÆtest.py„Åã„ÇâÁßªÊ§çÔºâ
    # ÂçòÂãù„ÅÆÁöÑ‰∏≠Áéá„Å®ÂõûÂèéÁéá
    tansho_hit = (output_df['Á¢∫ÂÆöÁùÄÈ†Ü'] == 1) & (output_df['‰∫àÊ∏¨È†Ü‰Ωç'] == 1)
    tansho_hitrate = 100 * tansho_hit.sum() / race_count
    tansho_recoveryrate = 100 * (tansho_hit * output_df['ÂçòÂãù„Ç™„ÉÉ„Ç∫']).sum() / race_count

    # Ë§áÂãù„ÅÆÁöÑ‰∏≠Áéá„Å®ÂõûÂèéÁéá
    fukusho_hit = (output_df['Á¢∫ÂÆöÁùÄÈ†Ü'].isin([1, 2, 3])) & (output_df['‰∫àÊ∏¨È†Ü‰Ωç'].isin([1, 2, 3]))
    fukusho_hitrate = fukusho_hit.sum() / (race_count * 3) * 100

    # ÁöÑ‰∏≠È¶¨„Å†„ÅëÂèñ„ÇäÂá∫„Åô
    hit_rows = output_df[fukusho_hit].copy()

    def extract_odds(row):
        if row['Á¢∫ÂÆöÁùÄÈ†Ü'] == 1:
            return row['Ë§áÂãù1ÁùÄ„Ç™„ÉÉ„Ç∫']
        elif row['Á¢∫ÂÆöÁùÄÈ†Ü'] == 2:
            return row['Ë§áÂãù2ÁùÄ„Ç™„ÉÉ„Ç∫']
        elif row['Á¢∫ÂÆöÁùÄÈ†Ü'] == 3:
            return row['Ë§áÂãù3ÁùÄ„Ç™„ÉÉ„Ç∫']
        else:
            return 0

    # ÁöÑ‰∏≠È¶¨„Å´ÂØæÂøú„Åô„ÇãÊâïÊàª„ÇíË®àÁÆóÔºà100ÂÜÜË≥≠„Åë„Åü„Å®„Åó„Å¶Ôºâ
    hit_rows['ÁöÑ‰∏≠„Ç™„ÉÉ„Ç∫'] = hit_rows.apply(extract_odds, axis=1)
    total_payout = (hit_rows['ÁöÑ‰∏≠„Ç™„ÉÉ„Ç∫'] * 100).sum()

    # Á∑èË≥ºÂÖ•È°çÔºàÊØé„É¨„Éº„Çπ„Åß3È†≠„Å´100ÂÜÜ„Åö„Å§Ôºâ
    total_bet = race_count * 3 * 100
    fukusho_recoveryrate = total_payout / total_bet * 100

    # È¶¨ÈÄ£„ÅÆÁöÑ‰∏≠Áéá„Å®ÂõûÂèéÁéá
    umaren_hit = output_df.groupby(['ÈñãÂÇ¨Âπ¥', 'ÈñãÂÇ¨Êó•', '„É¨„Éº„ÇπÁï™Âè∑']).apply(
        lambda x: set([1, 2]).issubset(set(x.sort_values('‰∫àÊ∏¨„Çπ„Ç≥„Ç¢', ascending=False).head(2)['Á¢∫ÂÆöÁùÄÈ†Ü'].values))
    )
    umaren_hitrate = 100 * umaren_hit.sum() / race_count
    umaren_recoveryrate = 100 * (umaren_hit * output_df.groupby(['ÈñãÂÇ¨Âπ¥', 'ÈñãÂÇ¨Êó•', '„É¨„Éº„ÇπÁï™Âè∑'])['È¶¨ÈÄ£„Ç™„ÉÉ„Ç∫'].first()).sum() / race_count

    # „ÉØ„Ç§„ÉâÁöÑ‰∏≠Áéá„ÉªÂõûÂèéÁéá„ÇÇË®àÁÆóÔºàÁúÅÁï•„Åó„Å¶Á∞°Áï•ÂåñÔºâ
    wide_hitrate = 0  # Ë®àÁÆó„ÅåË§áÈõë„Å™„ÅÆ„ÅßÁúÅÁï•
    wide_recoveryrate = 0

    # È¶¨Âçò„ÅÆÁöÑ‰∏≠Áéá„Å®ÂõûÂèéÁéá
    umatan_hit = output_df.groupby(['ÈñãÂÇ¨Âπ¥', 'ÈñãÂÇ¨Êó•', '„É¨„Éº„ÇπÁï™Âè∑']).apply(
        lambda x: list(x.sort_values('‰∫àÊ∏¨„Çπ„Ç≥„Ç¢', ascending=False).head(2)['Á¢∫ÂÆöÁùÄÈ†Ü'].values) == [1, 2]
    )
    umatan_hitrate = 100 * umatan_hit.sum() / race_count
    
    umatan_odds_sum = 0
    for name, race_group in output_df.groupby(['ÈñãÂÇ¨Âπ¥', 'ÈñãÂÇ¨Êó•', '„É¨„Éº„ÇπÁï™Âè∑']):
        top_horses = race_group.sort_values('‰∫àÊ∏¨„Çπ„Ç≥„Ç¢', ascending=False).head(2)
        if list(top_horses['Á¢∫ÂÆöÁùÄÈ†Ü'].values) == [1, 2]:
            umatan_odds_sum += race_group['È¶¨Âçò„Ç™„ÉÉ„Ç∫'].iloc[0]

    umatan_recoveryrate = 100 * umatan_odds_sum / race_count

    # ‰∏âÈÄ£Ë§á„ÅÆÁöÑ‰∏≠Áéá„Å®ÂõûÂèéÁéá
    sanrenpuku_hit = output_df.groupby(['ÈñãÂÇ¨Âπ¥', 'ÈñãÂÇ¨Êó•', '„É¨„Éº„ÇπÁï™Âè∑']).apply(
        lambda x: set([1, 2, 3]).issubset(set(x.sort_values('‰∫àÊ∏¨„Çπ„Ç≥„Ç¢', ascending=False).head(3)['Á¢∫ÂÆöÁùÄÈ†Ü'].values))
    )
    sanrenpuku_hitrate = 100 * sanrenpuku_hit.sum() / len(sanrenpuku_hit)
    sanrenpuku_recoveryrate = 100 * (sanrenpuku_hit * output_df.groupby(['ÈñãÂÇ¨Âπ¥', 'ÈñãÂÇ¨Êó•', '„É¨„Éº„ÇπÁï™Âè∑'])['ÔºìÈÄ£Ë§á„Ç™„ÉÉ„Ç∫'].first()).sum() / len(sanrenpuku_hit)

    # ÁµêÊûú„Çí„Éá„Éº„Çø„Éï„É¨„Éº„É†„Å´„Åæ„Å®„ÇÅ„Çã
    summary_df = pd.DataFrame({
        'ÁöÑ‰∏≠Êï∞': [tansho_hit.sum(), fukusho_hit.sum(), umaren_hit.sum(), 0, umatan_hit.sum(), sanrenpuku_hit.sum()],
        'ÁöÑ‰∏≠Áéá(%)': [tansho_hitrate, fukusho_hitrate, umaren_hitrate, wide_hitrate, umatan_hitrate, sanrenpuku_hitrate],
        'ÂõûÂèéÁéá(%)': [tansho_recoveryrate, fukusho_recoveryrate, umaren_recoveryrate, wide_recoveryrate, umatan_recoveryrate, sanrenpuku_recoveryrate]
    }, index=['ÂçòÂãù', 'Ë§áÂãù', 'È¶¨ÈÄ£', '„ÉØ„Ç§„Éâ', 'È¶¨Âçò', 'ÔºìÈÄ£Ë§á'])

    return output_df, summary_df, race_count


def test_multiple_models(test_year_start=2023, test_year_end=2023):
    """
    Ë§áÊï∞„ÅÆ„É¢„Éá„É´„Çí„ÉÜ„Çπ„Éà„Åó„Å¶ÁµêÊûú„ÇíÊØîËºÉ„Åô„ÇãÈñ¢Êï∞(Ë®≠ÂÆö„ÅØJSON„Éï„Ç°„Ç§„É´„Åã„ÇâË™≠„ÅøËæº„Åø)
    
    Args:
        test_year_start (int): „ÉÜ„Çπ„ÉàÂØæË±°ÈñãÂßãÂπ¥ („Éá„Éï„Ç©„É´„Éà: 2023)
        test_year_end (int): „ÉÜ„Çπ„ÉàÂØæË±°ÁµÇ‰∫ÜÂπ¥ („Éá„Éï„Ç©„É´„Éà: 2023)
    """
    
    # JSON„Éï„Ç°„Ç§„É´„Åã„ÇâÂÖ®„É¢„Éá„É´Ë®≠ÂÆö„ÇíË™≠„ÅøËæº„Åø
    try:
        model_configs = get_all_models()
    except Exception as e:
        print(f"‚ùå Ë®≠ÂÆö„Éï„Ç°„Ç§„É´„ÅÆË™≠„ÅøËæº„Åø„Å´Â§±Êïó„Åó„Åæ„Åó„Åü: {e}")
        return
    
    if not model_configs:
        print("‚ö†Ô∏è  „ÉÜ„Çπ„ÉàÂØæË±°„ÅÆ„É¢„Éá„É´Ë®≠ÂÆö„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„Åß„Åó„Åü„ÄÇ")
        return
    
    print("üèá Ë§áÊï∞„É¢„Éá„É´„ÉÜ„Çπ„Éà„ÇíÈñãÂßã„Åó„Åæ„ÅôÔºÅ")
    print("=" * 60)
    
    all_results = {}
    # Áµ±Âêà„Éï„Ç°„Ç§„É´„ÅÆÂàùÂõûÊõ∏„ÅçËæº„Åø„Éï„É©„Ç∞
    first_unified_write = True
    
    for i, config in enumerate(model_configs, 1):
        model_filename = config['model_filename']
        description = config.get('description', f"„É¢„Éá„É´{i}")
        
        print(f"\n„Äê{i}/{len(model_configs)}„Äë {description} „É¢„Éá„É´„Çí„ÉÜ„Çπ„Éà‰∏≠...")
        print(f"üìÅ „É¢„Éá„É´„Éï„Ç°„Ç§„É´: {model_filename}")
        
        # „É¢„Éá„É´„Éï„Ç°„Ç§„É´„ÅÆÂ≠òÂú®Á¢∫Ë™çÔºàmodels„Éï„Ç©„É´„ÉÄ„ÇÇÁ¢∫Ë™çÔºâ
        model_path = model_filename
        if not os.path.exists(model_path):
            models_path = f"models/{model_filename}"
            if os.path.exists(models_path):
                model_path = models_path
                print(f"üìÇ models„Éï„Ç©„É´„ÉÄÂÜÖ„ÅÆ„Éï„Ç°„Ç§„É´„Çí‰ΩøÁî®: {models_path}")
            else:
                print(f"‚ö†Ô∏è  „É¢„Éá„É´„Éï„Ç°„Ç§„É´ {model_filename} „ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„ÄÇ„Çπ„Ç≠„ÉÉ„Éó„Åó„Åæ„Åô„ÄÇ")
                print(f"    Á¢∫Ë™çÂ†¥ÊâÄ: ./{model_filename}, ./models/{model_filename}")
                continue
        
        try:
            output_df, summary_df, race_count = predict_with_model(
                model_filename=model_path,  # Â≠òÂú®Á¢∫Ë™çÊ∏à„Åø„ÅÆ„Éë„Çπ„Çí‰ΩøÁî®
                track_code=config['track_code'],
                kyoso_shubetsu_code=config['kyoso_shubetsu_code'],
                surface_type=config['surface_type'],
                min_distance=config['min_distance'],
                max_distance=config['max_distance'],
                test_year_start=test_year_start,
                test_year_end=test_year_end
            )
            
            if output_df is not None:
                # ÁµêÊûú„Çí‰øùÂ≠òÔºàËøΩË®ò„É¢„Éº„ÉâÔºâ
                base_filename = model_filename.replace('.sav', '').replace('models/', '')
                individual_output_file = f"predicted_results_{base_filename}.tsv"
                summary_file = f"betting_summary_{base_filename}.tsv"
                
                # ÂÄãÂà•„É¢„Éá„É´ÁµêÊûú„ÇíËøΩË®ò‰øùÂ≠ò
                save_results_with_append(output_df, individual_output_file, append_mode=True)
                
                # ÂÖ®„É¢„Éá„É´Áµ±Âêà„Éï„Ç°„Ç§„É´„Å´‰øùÂ≠òÔºàÂàùÂõû„ÅØ‰∏äÊõ∏„Åç„ÄÅ‰ª•Èôç„ÅØËøΩË®òÔºâ
                unified_output_file = "predicted_results.tsv"
                save_results_with_append(output_df, unified_output_file, append_mode=not first_unified_write)
                first_unified_write = False  # ÂàùÂõûÊõ∏„ÅçËæº„ÅøÂÆå‰∫Ü
                
                # „Çµ„Éû„É™„Éº„ÅØÂÄãÂà•„Éï„Ç°„Ç§„É´„Å´‰øùÂ≠ò
                results_dir = Path('results')
                results_dir.mkdir(exist_ok=True)
                summary_filepath = results_dir / summary_file
                summary_df.to_csv(summary_filepath, index=True, sep='\t', encoding='utf-8-sig')
                
                print(f"‚úÖ ÂÆå‰∫ÜÔºÅ„É¨„Éº„ÇπÊï∞: {race_count}")
                print(f"  - ÂÄãÂà•ÁµêÊûú: {individual_output_file}")
                print(f"  - Áµ±ÂêàÁµêÊûú: {unified_output_file}")
                print(f"  - „Çµ„Éû„É™„Éº: {summary_file}")
                
                # ÁµêÊûú„Çí‰øùÂ≠òÔºàÂæå„ÅßÊØîËºÉÁî®Ôºâ
                all_results[description] = {
                    'summary': summary_df,
                    'race_count': race_count,
                    'model_filename': model_filename
                }
                
                # ‰∏ªË¶Å„Å™ÁµêÊûú„ÇíË°®Á§∫
                print(f"  - ÂçòÂãùÁöÑ‰∏≠Áéá: {summary_df.loc['ÂçòÂãù', 'ÁöÑ‰∏≠Áéá(%)']:.2f}%")
                print(f"  - ÂçòÂãùÂõûÂèéÁéá: {summary_df.loc['ÂçòÂãù', 'ÂõûÂèéÁéá(%)']:.2f}%")
                print(f"  - Ë§áÂãùÁöÑ‰∏≠Áéá: {summary_df.loc['Ë§áÂãù', 'ÁöÑ‰∏≠Áéá(%)']:.2f}%")
                print(f"  - Ë§áÂãùÂõûÂèéÁéá: {summary_df.loc['Ë§áÂãù', 'ÂõûÂèéÁéá(%)']:.2f}%")
                
            else:
                print(f"‚ùå „ÉÜ„Çπ„Éà„Éá„Éº„Çø„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„Åß„Åó„Åü„ÄÇ")
                
        except Exception as e:
            print(f"‚ùå „Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü: {str(e)}")
            import traceback
            traceback.print_exc()
        
        print("-" * 60)
    
    # Ë§áÊï∞„É¢„Éá„É´„ÅÆÊØîËºÉÁµêÊûú„Çí‰ΩúÊàê
    if len(all_results) > 1:
        print("\nüìä „É¢„Éá„É´ÊØîËºÉÁµêÊûú")
        print("=" * 60)
        
        comparison_data = []
        for description, result in all_results.items():
            summary = result['summary']
            comparison_data.append({
                '„É¢„Éá„É´': description,
                '„É¨„Éº„ÇπÊï∞': result['race_count'],
                'ÂçòÂãùÁöÑ‰∏≠Áéá': f"{summary.loc['ÂçòÂãù', 'ÁöÑ‰∏≠Áéá(%)']:.2f}%",
                'ÂçòÂãùÂõûÂèéÁéá': f"{summary.loc['ÂçòÂãù', 'ÂõûÂèéÁéá(%)']:.2f}%",
                'Ë§áÂãùÁöÑ‰∏≠Áéá': f"{summary.loc['Ë§áÂãù', 'ÁöÑ‰∏≠Áéá(%)']:.2f}%",
                'Ë§áÂãùÂõûÂèéÁéá': f"{summary.loc['Ë§áÂãù', 'ÂõûÂèéÁéá(%)']:.2f}%",
                '‰∏âÈÄ£Ë§áÁöÑ‰∏≠Áéá': f"{summary.loc['ÔºìÈÄ£Ë§á', 'ÁöÑ‰∏≠Áéá(%)']:.2f}%",
                '‰∏âÈÄ£Ë§áÂõûÂèéÁéá': f"{summary.loc['ÔºìÈÄ£Ë§á', 'ÂõûÂèéÁéá(%)']:.2f}%"
            })
        
        comparison_df = pd.DataFrame(comparison_data)
        
        # ÊØîËºÉÁµêÊûú„Çí‰øùÂ≠ò
        comparison_file = 'model_comparison.tsv'
        results_dir = Path('results')
        results_dir.mkdir(exist_ok=True)
        comparison_filepath = results_dir / comparison_file
        
        comparison_df.to_csv(comparison_filepath, index=False, sep='\t', encoding='utf-8-sig')
        
        print(comparison_df.to_string(index=False))
        print(f"\nüìã ÊØîËºÉÁµêÊûú„Çí {comparison_filepath} „Å´‰øùÂ≠ò„Åó„Åæ„Åó„ÅüÔºÅ")
    
    print("\nüèÅ „Åô„Åπ„Å¶„ÅÆ„ÉÜ„Çπ„Éà„ÅåÂÆå‰∫Ü„Åó„Åæ„Åó„ÅüÔºÅ")


def predict_and_save_results():
    """
    Êóß„Éê„Éº„Ç∏„Éß„É≥‰∫íÊèõÊÄß„ÅÆ„Åü„ÇÅ„ÅÆÈñ¢Êï∞
    Èò™Á•ûÁ´∂È¶¨Â†¥„ÅÆÔºìÊ≠≥‰ª•‰∏äËäù‰∏≠Èï∑Ë∑ùÈõ¢„É¢„Éá„É´„Åß„ÉÜ„Çπ„Éà
    """
    output_df, summary_df, race_count = predict_with_model(
        model_filename='hanshin_shiba_3ageup_model.sav',
        track_code='09',  # Èò™Á•û
        kyoso_shubetsu_code='13',  # 3Ê≠≥‰ª•‰∏ä
        surface_type='turf',  # Ëäù
        min_distance=1700,  # ‰∏≠Èï∑Ë∑ùÈõ¢
        max_distance=9999  # ‰∏äÈôê„Å™„Åó
    )
    
    if output_df is not None:
        # results„Éá„Ç£„É¨„ÇØ„Éà„É™„Çí‰ΩúÊàê
        results_dir = Path('results')
        results_dir.mkdir(exist_ok=True)
        
        # ÁµêÊûú„ÇíTSV„Å´‰øùÂ≠òÔºàËøΩË®ò„É¢„Éº„ÉâÔºâ
        output_file = 'predicted_results.tsv'
        save_results_with_append(output_df, output_file, append_mode=True)
        print(f"‰∫àÊ∏¨ÁµêÊûú„Çí results/{output_file} „Å´‰øùÂ≠ò„Åó„Åæ„Åó„ÅüÔºÅ")

        # ÁöÑ‰∏≠Áéá„Å®ÂõûÂèéÁéá„ÇíÂà•„Éï„Ç°„Ç§„É´„Å´‰øùÂ≠ò
        summary_file = 'betting_summary.tsv'
        summary_filepath = results_dir / summary_file
        summary_df.to_csv(summary_filepath, index=True, sep='\t', encoding='utf-8-sig')
        print(f"ÁöÑ‰∏≠Áéá„ÉªÂõûÂèéÁéá„ÉªÁöÑ‰∏≠Êï∞„Çí results/{summary_file} „Å´‰øùÂ≠ò„Åó„Åæ„Åó„ÅüÔºÅ")


if __name__ == '__main__':
    # ÂÆüË°åÊñπÊ≥ï„ÇíÈÅ∏Êäû„Åß„Åç„Çã„Çà„ÅÜ„Å´
    import sys
    
    # „Éá„Éï„Ç©„É´„Éà„ÅÆ„ÉÜ„Çπ„ÉàÂπ¥ÁØÑÂõ≤
    test_year_start = 2023
    test_year_end = 2023
    
    # „Ç≥„Éû„É≥„Éâ„É©„Ç§„É≥ÂºïÊï∞„ÇíËß£Êûê
    mode = 'single'  # „Éá„Éï„Ç©„É´„Éà„ÅØÂçò‰∏Ä„É¢„Éá„É´„ÉÜ„Çπ„Éà
    
    for arg in sys.argv[1:]:
        if arg == 'multi':
            mode = 'multi'
        elif '-' in arg and arg[0].isdigit():
            # "2020-2023" ÂΩ¢Âºè„ÅÆÂπ¥ÁØÑÂõ≤ÊåáÂÆö
            try:
                years = arg.split('-')
                if len(years) == 2:
                    test_year_start = int(years[0])
                    test_year_end = int(years[1])
                    print(f"üìÖ „ÉÜ„Çπ„ÉàÂπ¥ÁØÑÂõ≤ÊåáÂÆö: {test_year_start}Âπ¥~{test_year_end}Âπ¥")
            except ValueError:
                print(f"‚ö†Ô∏è  ÁÑ°Âäπ„Å™Âπ¥ÁØÑÂõ≤„Éï„Ç©„Éº„Éû„ÉÉ„Éà: {arg} (‰æã: 2020-2023)")
        elif arg.isdigit() and len(arg) == 4:
            # "2023" ÂΩ¢Âºè„ÅÆÂçò‰∏ÄÂπ¥ÊåáÂÆö
            test_year_start = test_year_end = int(arg)
            print(f"üìÖ „ÉÜ„Çπ„ÉàÂπ¥ÊåáÂÆö: {test_year_start}Âπ¥")
    
    if mode == 'multi':
        # python universal_test.py multi [Âπ¥ÁØÑÂõ≤]
        test_multiple_models(test_year_start=test_year_start, test_year_end=test_year_end)
    else:
        # python universal_test.py [Âπ¥ÁØÑÂõ≤] („Éá„Éï„Ç©„É´„Éà)
        # Âçò‰∏Ä„É¢„Éá„É´„ÉÜ„Çπ„Éà„ÅßÂπ¥ÁØÑÂõ≤„Çí‰ΩøÁî®
        output_df, summary_df, race_count = predict_with_model(
            model_filename='hanshin_shiba_3ageup_model.sav',
            track_code='09',  # Èò™Á•û
            kyoso_shubetsu_code='13',  # 3Ê≠≥‰ª•‰∏ä
            surface_type='turf',  # Ëäù
            min_distance=1700,  # ‰∏≠Èï∑Ë∑ùÈõ¢
            max_distance=9999,  # ‰∏äÈôê„Å™„Åó
            test_year_start=test_year_start,
            test_year_end=test_year_end
        )
        
        if output_df is not None:
            # results„Éá„Ç£„É¨„ÇØ„Éà„É™„Çí‰ΩúÊàê
            results_dir = Path('results')
            results_dir.mkdir(exist_ok=True)
            
            # ÁµêÊûú„ÇíTSV„Å´‰øùÂ≠òÔºàËøΩË®ò„É¢„Éº„ÉâÔºâ
            output_file = 'predicted_results.tsv'
            save_results_with_append(output_df, output_file, append_mode=True)
            print(f"‰∫àÊ∏¨ÁµêÊûú„Çí results/{output_file} „Å´‰øùÂ≠ò„Åó„Åæ„Åó„Åü!")

            # ÁöÑ‰∏≠Áéá„Å®ÂõûÂèéÁéá„ÇíÂà•„Éï„Ç°„Ç§„É´„Å´‰øùÂ≠ò
            summary_file = 'betting_summary.tsv'
            summary_filepath = results_dir / summary_file
            summary_df.to_csv(summary_filepath, index=True, sep='\t', encoding='utf-8-sig')
            print(f"ÁöÑ‰∏≠Áéá„ÉªÂõûÂèéÁéá„ÉªÁöÑ‰∏≠Êï∞„Çí results/{summary_file} „Å´‰øùÂ≠ò„Åó„Åæ„Åó„Åü!")