#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ±ç”¨ç«¶é¦¬äºˆæ¸¬ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€è¤‡æ•°ã®ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã«å¯¾å¿œã—ãŸç«¶é¦¬äºˆæ¸¬ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã—ã¾ã™ã€‚
model_creator.pyã§ä½œæˆã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦äºˆæ¸¬ã‚’è¡Œã„ã€çµæœã‚’ä¿å­˜ã—ã¾ã™ã€‚
"""

import psycopg2
import pandas as pd
import pickle
import lightgbm as lgb
import numpy as np
import os
from pathlib import Path
from datetime import datetime
from keiba_constants import get_track_name, format_model_description
from model_config_loader import get_all_models, get_legacy_model


def save_results_with_append(df, filename, append_mode=True, output_dir='results'):
    """
    çµæœã‚’TSVãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ï¼ˆè¿½è¨˜ãƒ¢ãƒ¼ãƒ‰å¯¾å¿œï¼‰
    
    Args:
        df (DataFrame): ä¿å­˜ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
        filename (str): ä¿å­˜å…ˆãƒ•ã‚¡ã‚¤ãƒ«å
        append_mode (bool): True=è¿½è¨˜ãƒ¢ãƒ¼ãƒ‰ã€False=ä¸Šæ›¸ããƒ¢ãƒ¼ãƒ‰
        output_dir (str): å‡ºåŠ›å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 'results'ï¼‰
    """
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆï¼ˆå­˜åœ¨ã—ãªã„å ´åˆï¼‰
    output_path = Path(output_dir)
    output_path.mkdir(exist_ok=True)
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’ä½œæˆ
    filepath = output_path / filename
    
    if append_mode and filepath.exists():
        # ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ—¢ã«å­˜åœ¨ã™ã‚‹å ´åˆã¯è¿½è¨˜ï¼ˆãƒ˜ãƒƒãƒ€ãƒ¼ãªã—ï¼‰
        print(f"ğŸ“ æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã«è¿½è¨˜: {filepath}")
        df.to_csv(filepath, mode='a', header=False, index=False, sep='\t', encoding='utf-8-sig')
    else:
        # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯æ–°è¦ä½œæˆï¼ˆãƒ˜ãƒƒãƒ€ãƒ¼ã‚ã‚Šï¼‰
        print(f"ğŸ“‹ æ–°è¦ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ: {filepath}")
        df.to_csv(filepath, index=False, sep='\t', encoding='utf-8-sig')


def predict_with_model(model_filename, track_code, kyoso_shubetsu_code, surface_type, 
                      min_distance, max_distance, test_year_start=2023, test_year_end=2023):
    """
    æŒ‡å®šã—ãŸãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬ã‚’å®Ÿè¡Œã™ã‚‹æ±ç”¨é–¢æ•°
    
    Args:
        model_filename (str): ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«å
        track_code (str): ç«¶é¦¬å ´ã‚³ãƒ¼ãƒ‰
        kyoso_shubetsu_code (str): ç«¶äº‰ç¨®åˆ¥ã‚³ãƒ¼ãƒ‰
        surface_type (str): 'turf' or 'dirt'
        min_distance (int): æœ€å°è·é›¢
        max_distance (int): æœ€å¤§è·é›¢
        test_year_start (int): ãƒ†ã‚¹ãƒˆå¯¾è±¡é–‹å§‹å¹´ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 2023)
        test_year_end (int): ãƒ†ã‚¹ãƒˆå¯¾è±¡çµ‚äº†å¹´ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 2023)
        
    Returns:
        tuple: (äºˆæ¸¬çµæœDataFrame, ã‚µãƒãƒªãƒ¼DataFrame, ãƒ¬ãƒ¼ã‚¹æ•°)
    """
    
    # PostgreSQL ã‚³ãƒã‚¯ã‚·ãƒ§ãƒ³ã®ä½œæˆ
    conn = psycopg2.connect(
        host='localhost',
        port='5432',
        user='postgres',
        password='ahtaht88',
        dbname='keiba'
    )

    # ãƒˆãƒ©ãƒƒã‚¯æ¡ä»¶ã‚’å‹•çš„ã«è¨­å®š
    if surface_type.lower() == 'turf':
        # èŠã®å ´åˆ
        track_condition = "cast(rase.track_code as integer) between 10 and 22"
        baba_condition = "ra.babajotai_code_shiba"
    else:
        # ãƒ€ãƒ¼ãƒˆã®å ´åˆ
        track_condition = "cast(rase.track_code as integer) between 23 and 29"
        baba_condition = "ra.babajotai_code_dirt"

    # è·é›¢æ¡ä»¶ã‚’è¨­å®š
    if max_distance == 9999:
        distance_condition = f"cast(rase.kyori as integer) >= {min_distance}"
    else:
        distance_condition = f"cast(rase.kyori as integer) between {min_distance} and {max_distance}"

    # ç«¶äº‰ç¨®åˆ¥ã‚’è¨­å®š
    if kyoso_shubetsu_code == '12':
        # 3æ­³æˆ¦
        kyoso_shubetsu_condition = "cast(rase.kyoso_shubetsu_code as integer) = 12"
    elif kyoso_shubetsu_code == '13':
        kyoso_shubetsu_condition = "cast(rase.kyoso_shubetsu_code as integer) >= 13"

    # SQLã‚¯ã‚¨ãƒªã‚’å‹•çš„ã«ç”Ÿæˆ
    sql = f"""
    select * from (
        select
        ra.kaisai_nen,
        ra.kaisai_tsukihi,
        ra.race_bango,
        seum.umaban,
        seum.bamei,
        ra.keibajo_code,
        CASE 
            WHEN ra.keibajo_code = '01' THEN 'æœ­å¹Œ' 
            WHEN ra.keibajo_code = '02' THEN 'å‡½é¤¨' 
            WHEN ra.keibajo_code = '03' THEN 'ç¦å³¶' 
            WHEN ra.keibajo_code = '04' THEN 'æ–°æ½Ÿ' 
            WHEN ra.keibajo_code = '05' THEN 'æ±äº¬' 
            WHEN ra.keibajo_code = '06' THEN 'ä¸­å±±' 
            WHEN ra.keibajo_code = '07' THEN 'ä¸­äº¬' 
            WHEN ra.keibajo_code = '08' THEN 'äº¬éƒ½' 
            WHEN ra.keibajo_code = '09' THEN 'é˜ªç¥' 
            WHEN ra.keibajo_code = '10' THEN 'å°å€‰' 
            ELSE '' 
        END keibajo_name,
        ra.kyori,
        ra.shusso_tosu,
        ra.tenko_code,
        {baba_condition} as babajotai_code,
        ra.grade_code,
        ra.kyoso_joken_code,
        ra.kyoso_shubetsu_code,
        ra.track_code,
        seum.ketto_toroku_bango,
        seum.wakuban,
        cast(seum.umaban as integer) as umaban_numeric,
        seum.barei,
        seum.kishu_code,
        seum.chokyoshi_code,
        seum.kishu_name,
        seum.chokyoshi_name,
        seum.futan_juryo,
        seum.seibetsu_code,
        nullif(cast(seum.tansho_odds as float), 0) / 10 as tansho_odds,
        nullif(cast(seum.tansho_ninkijun as integer), 0) as tansho_ninkijun_numeric,
        nullif(cast(seum.kakutei_chakujun as integer), 0) as kakutei_chakujun_numeric,
        1.0 / nullif(cast(seum.kakutei_chakujun as integer), 0) as chakujun_score,
        AVG(
            (1 - (cast(seum.kakutei_chakujun as float) / cast(ra.shusso_tosu as float)))
            * CASE
                WHEN seum.time_sa LIKE '-%' THEN 1.00  -- 1ç€(ãƒã‚¤ãƒŠã‚¹å€¤) â†’ ä¿‚æ•°1.00(æº€ç‚¹)
                WHEN CAST(REPLACE(seum.time_sa, '+', '') AS INTEGER) <= 5 THEN 0.85   -- 0.5ç§’å·®ä»¥å†… â†’ 0.85å€(15%æ¸›)
                WHEN CAST(REPLACE(seum.time_sa, '+', '') AS INTEGER) <= 10 THEN 0.70  -- 1.0ç§’å·®ä»¥å†… â†’ 0.70å€(30%æ¸›)
                WHEN CAST(REPLACE(seum.time_sa, '+', '') AS INTEGER) <= 20 THEN 0.50  -- 2.0ç§’å·®ä»¥å†… â†’ 0.50å€(50%æ¸›)
                WHEN CAST(REPLACE(seum.time_sa, '+', '') AS INTEGER) <= 30 THEN 0.30  -- 3.0ç§’å·®ä»¥å†… â†’ 0.30å€(70%æ¸›)
                ELSE 0.20  -- 3.0ç§’è¶… â†’ 0.20å€(å¤§æ•—ã¯ã»ã¼ç„¡è¦–)
            END
        ) OVER (
            PARTITION BY seum.ketto_toroku_bango
            ORDER BY cast(ra.kaisai_nen as integer), cast(ra.kaisai_tsukihi as integer)
            ROWS BETWEEN 3 PRECEDING AND 1 PRECEDING
        ) AS past_avg_sotai_chakujun,
        AVG(
            cast(ra.kyori as integer) /
            NULLIF(
                FLOOR(cast(seum.soha_time as integer) / 1000) * 60 +
                FLOOR((cast(seum.soha_time as integer) % 1000) / 10) +
                (cast(seum.soha_time as integer) % 10) * 0.1,
                0
            )
        ) OVER (
            PARTITION BY seum.ketto_toroku_bango
            ORDER BY cast(ra.kaisai_nen as integer), cast(ra.kaisai_tsukihi as integer)
            ROWS BETWEEN 3 PRECEDING AND 1 PRECEDING
        ) AS time_index,
        SUM(
            CASE 
                WHEN seum.kakutei_chakujun = '01' THEN 100
                WHEN seum.kakutei_chakujun = '02' THEN 80
                WHEN seum.kakutei_chakujun = '03' THEN 60
                WHEN seum.kakutei_chakujun = '04' THEN 40
                WHEN seum.kakutei_chakujun = '05' THEN 30
                WHEN seum.kakutei_chakujun = '06' THEN 20
                WHEN seum.kakutei_chakujun = '07' THEN 10
                ELSE 5 
            END
            * CASE 
                WHEN ra.grade_code = 'A' THEN 3.00
                WHEN ra.grade_code = 'B' THEN 2.00
                WHEN ra.grade_code = 'C' THEN 1.50
                WHEN ra.grade_code <> 'A' AND ra.grade_code <> 'B' AND ra.grade_code <> 'C' AND ra.kyoso_joken_code = '999' THEN 1.00
                WHEN ra.grade_code <> 'A' AND ra.grade_code <> 'B' AND ra.grade_code <> 'C' AND ra.kyoso_joken_code = '016' THEN 0.80
                WHEN ra.grade_code <> 'A' AND ra.grade_code <> 'B' AND ra.grade_code <> 'C' AND ra.kyoso_joken_code = '010' THEN 0.60
                WHEN ra.grade_code <> 'A' AND ra.grade_code <> 'B' AND ra.grade_code <> 'C' AND ra.kyoso_joken_code = '005' THEN 0.40
                ELSE 0.20
            END
        ) OVER (
            PARTITION BY seum.ketto_toroku_bango
            ORDER BY cast(ra.kaisai_nen as integer), cast(ra.kaisai_tsukihi as integer)
            ROWS BETWEEN 3 PRECEDING AND 1 PRECEDING  
        ) AS past_score,
        CASE 
            WHEN AVG(
                CASE 
                    WHEN cast(seum.kohan_3f as integer) > 0 AND cast(seum.kohan_3f as integer) < 999 THEN
                    CAST(seum.kohan_3f AS FLOAT) / 10
                    ELSE NULL
                END
            ) OVER (
                PARTITION BY seum.ketto_toroku_bango
                ORDER BY cast(ra.kaisai_nen as integer), cast(ra.kaisai_tsukihi as integer)
                ROWS BETWEEN 3 PRECEDING AND 1 PRECEDING
            ) IS NOT NULL THEN
            AVG(
                CASE 
                    WHEN cast(seum.kohan_3f as integer) > 0 AND cast(seum.kohan_3f as integer) < 999 THEN
                    CAST(seum.kohan_3f AS FLOAT) / 10
                    ELSE NULL
                END
            ) OVER (
                PARTITION BY seum.ketto_toroku_bango
                ORDER BY cast(ra.kaisai_nen as integer), cast(ra.kaisai_tsukihi as integer)
                ROWS BETWEEN 3 PRECEDING AND 1 PRECEDING
            ) - 
            CASE
                WHEN cast(ra.kyori as integer) <= 1600 THEN 33.5
                WHEN cast(ra.kyori as integer) <= 2000 THEN 35.0
                WHEN cast(ra.kyori as integer) <= 2400 THEN 36.0
                ELSE 37.0
            END
            ELSE 0
        END AS kohan_3f_index
        ,nullif(cast(nullif(trim(hr.haraimodoshi_fukusho_1a), '') as integer), 0) as è¤‡å‹1ç€é¦¬ç•ª
        ,nullif(cast(nullif(trim(hr.haraimodoshi_fukusho_1b), '') as float), 0) / 100 as è¤‡å‹1ç€ã‚ªãƒƒã‚º
        ,nullif(cast(nullif(trim(hr.haraimodoshi_fukusho_1c), '') as integer), 0) as è¤‡å‹1ç€äººæ°—
        ,nullif(cast(nullif(trim(hr.haraimodoshi_fukusho_2a), '') as integer), 0) as è¤‡å‹2ç€é¦¬ç•ª
        ,nullif(cast(nullif(trim(hr.haraimodoshi_fukusho_2b), '') as float), 0) / 100 as è¤‡å‹2ç€ã‚ªãƒƒã‚º
        ,nullif(cast(nullif(trim(hr.haraimodoshi_fukusho_2c), '') as integer), 0) as è¤‡å‹2ç€äººæ°—
        ,nullif(cast(nullif(trim(hr.haraimodoshi_fukusho_3a), '') as integer), 0) as è¤‡å‹3ç€é¦¬ç•ª
        ,nullif(cast(nullif(trim(hr.haraimodoshi_fukusho_3b), '') as float), 0) / 100 as è¤‡å‹3ç€ã‚ªãƒƒã‚º
        ,nullif(cast(nullif(trim(hr.haraimodoshi_fukusho_3c), '') as integer), 0) as è¤‡å‹3ç€äººæ°—
        ,cast(substring(trim(hr.haraimodoshi_umaren_1a), 1, 2) as integer) as é¦¬é€£é¦¬ç•ª1
        ,cast(substring(trim(hr.haraimodoshi_umaren_1a), 3, 2) as integer) as é¦¬é€£é¦¬ç•ª2
        ,nullif(cast(nullif(trim(hr.haraimodoshi_umaren_1b), '') as float), 0) / 100 as é¦¬é€£ã‚ªãƒƒã‚º
        ,cast(substring(trim(hr.haraimodoshi_wide_1a), 1, 2) as integer) as ãƒ¯ã‚¤ãƒ‰1_2é¦¬ç•ª1
        ,cast(substring(trim(hr.haraimodoshi_wide_1a), 3, 2) as integer) as ãƒ¯ã‚¤ãƒ‰1_2é¦¬ç•ª2
        ,cast(substring(trim(hr.haraimodoshi_wide_2a), 1, 2) as integer) as ãƒ¯ã‚¤ãƒ‰2_3ç€é¦¬ç•ª1
        ,cast(substring(trim(hr.haraimodoshi_wide_2a), 3, 2) as integer) as ãƒ¯ã‚¤ãƒ‰2_3ç€é¦¬ç•ª2
        ,cast(substring(trim(hr.haraimodoshi_wide_3a), 1, 2) as integer) as ãƒ¯ã‚¤ãƒ‰1_3ç€é¦¬ç•ª1
        ,cast(substring(trim(hr.haraimodoshi_wide_3a), 3, 2) as integer) as ãƒ¯ã‚¤ãƒ‰1_3ç€é¦¬ç•ª2
        ,nullif(cast(nullif(trim(hr.haraimodoshi_wide_1b), '') as float), 0) / 100 as ãƒ¯ã‚¤ãƒ‰1_2ã‚ªãƒƒã‚º
        ,nullif(cast(nullif(trim(hr.haraimodoshi_wide_2b), '') as float), 0) / 100 as ãƒ¯ã‚¤ãƒ‰2_3ã‚ªãƒƒã‚º
        ,nullif(cast(nullif(trim(hr.haraimodoshi_wide_3b), '') as float), 0) / 100 as ãƒ¯ã‚¤ãƒ‰1_3ã‚ªãƒƒã‚º
        ,cast(substring(trim(hr.haraimodoshi_umatan_1a), 1, 2) as integer) as é¦¬å˜é¦¬ç•ª1
        ,cast(substring(trim(hr.haraimodoshi_umatan_1a), 3, 2) as integer) as é¦¬å˜é¦¬ç•ª2
        ,nullif(cast(nullif(trim(hr.haraimodoshi_umatan_1b), '') as float), 0) / 100 as é¦¬å˜ã‚ªãƒƒã‚º
        ,nullif(cast(nullif(trim(hr.haraimodoshi_sanrenpuku_1b), '') as float), 0) / 100 as ï¼“é€£è¤‡ã‚ªãƒƒã‚º
    from
        jvd_ra ra 
        inner join ( 
            select
                se.kaisai_nen
                , se.kaisai_tsukihi
                , se.keibajo_code
                , se.race_bango
                , se.kakutei_chakujun
                , se.ketto_toroku_bango
                , se.bamei
                , se.wakuban
                , se.umaban
                , se.barei
                , se.seibetsu_code
                , se.futan_juryo
                , se.kishu_code
                , se.chokyoshi_code
                , trim(se.kishumei_ryakusho) as kishu_name
                , trim(se.chokyoshimei_ryakusho) as chokyoshi_name
                , se.tansho_odds
                , se.tansho_ninkijun
                , se.kohan_3f
                , se.soha_time
                , se.time_sa
            from
                jvd_se se 
            where
                se.kohan_3f <> '000' 
                and se.kohan_3f <> '999'
        ) seum 
            on ra.kaisai_nen = seum.kaisai_nen 
            and ra.kaisai_tsukihi = seum.kaisai_tsukihi 
            and ra.keibajo_code = seum.keibajo_code 
            and ra.race_bango = seum.race_bango
        inner join jvd_hr hr
            on ra.kaisai_nen = hr.kaisai_nen 
            and ra.kaisai_tsukihi = hr.kaisai_tsukihi 
            and ra.keibajo_code = hr.keibajo_code 
            and ra.race_bango = hr.race_bango
    where
        cast(ra.kaisai_nen as integer) between {test_year_start - 3} and {test_year_end}  --ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ã®å¯¾è±¡å¹´ç¯„å›²
    ) rase 
    where 
    rase.keibajo_code = '{track_code}'
    and cast(rase.kaisai_nen as integer) between {test_year_start} and {test_year_end}  --ãƒ†ã‚¹ãƒˆå¹´ç¯„å›²
    and {kyoso_shubetsu_condition}
    and {track_condition}
    and {distance_condition}
    """
    
    # ãƒ†ã‚¹ãƒˆç”¨ã®SQLã‚’ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã«å‡ºåŠ›ï¼ˆå¸¸ã«ä¸Šæ›¸ãï¼‰
    log_filepath = Path('sql_log_test.txt')
    with open(log_filepath, 'w', encoding='utf-8') as f:
        f.write(f"=== ãƒ†ã‚¹ãƒˆç”¨SQL ===\n")
        f.write(f"ãƒ¢ãƒ‡ãƒ«: {model_filename}\n")
        f.write(f"ãƒ†ã‚¹ãƒˆæœŸé–“: {test_year_start}å¹´ã€œ{test_year_end}å¹´\n")
        f.write(f"å®Ÿè¡Œæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"\n{sql}\n")
    print(f"ğŸ“ ãƒ†ã‚¹ãƒˆç”¨SQLã‚’ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã«å‡ºåŠ›: {log_filepath}")

    # ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    df = pd.read_sql_query(sql=sql, con=conn)
    conn.close()
    
    if len(df) == 0:
        print(f"âŒ {model_filename} ã«å¯¾å¿œã™ã‚‹ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        return None, None, 0

    print(f"ğŸ“Š ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {len(df)}ä»¶")

    # ğŸ”¥ä¿®æ­£: ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã‚’é©åˆ‡ã«å®Ÿæ–½ï¼ˆmodel_creator.pyã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
    # é¨æ‰‹ã‚³ãƒ¼ãƒ‰ãƒ»èª¿æ•™å¸«ã‚³ãƒ¼ãƒ‰ãƒ»é¦¬åãªã©ã®æ–‡å­—åˆ—åˆ—ã‚’ä¿æŒã—ãŸã¾ã¾ã€æ•°å€¤åˆ—ã®ã¿ã‚’å‡¦ç†
    print("ğŸ” ãƒ‡ãƒ¼ã‚¿å‹ç¢ºèª...")
    print(f"  kishu_codeå‹ï¼ˆä¿®æ­£å‰ï¼‰: {df['kishu_code'].dtype}")
    print(f"  kishu_codeã‚µãƒ³ãƒ—ãƒ«: {df['kishu_code'].head(5).tolist()}")
    print(f"  kishu_codeãƒ¦ãƒ‹ãƒ¼ã‚¯æ•°: {df['kishu_code'].nunique()}")
    
    # æ•°å€¤åŒ–ã™ã‚‹åˆ—ã‚’æ˜ç¤ºçš„ã«æŒ‡å®šï¼ˆæ–‡å­—åˆ—åˆ—ã¯é™¤å¤–ï¼‰
    numeric_columns = [
        'wakuban', 'umaban_numeric', 'barei', 'futan_juryo', 'tansho_odds',
        'kaisai_nen', 'kaisai_tsukihi', 'race_bango', 'kyori', 'shusso_tosu',
        'tenko_code', 'babajotai_code', 'grade_code', 'kyoso_joken_code',
        'kyoso_shubetsu_code', 'track_code', 'seibetsu_code',
        'kakutei_chakujun_numeric', 'chakujun_score', 'past_avg_sotai_chakujun',
        'time_index', 'past_score', 'kohan_3f_index'
    ]
    
    # æ•°å€¤åŒ–ã™ã‚‹åˆ—ã®ã¿å‡¦ç†ï¼ˆæ–‡å­—åˆ—åˆ—ã¯ä¿æŒï¼‰
    for col in numeric_columns:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce')
    
    # æ¬ æå€¤ã‚’0ã§åŸ‹ã‚ã‚‹ï¼ˆæ•°å€¤åˆ—ã®ã¿ï¼‰
    df[numeric_columns] = df[numeric_columns].fillna(0)
    
    # æ–‡å­—åˆ—å‹ã®åˆ—ã¯ãã®ã¾ã¾ä¿æŒï¼ˆkishu_code, chokyoshi_code, bamei ãªã©ï¼‰
    print(f"  kishu_codeå‹ï¼ˆä¿®æ­£å¾Œï¼‰: {df['kishu_code'].dtype}")
    print(f"  kishu_codeã‚µãƒ³ãƒ—ãƒ«: {df['kishu_code'].head(5).tolist()}")
    print("âœ… ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†å®Œäº†ï¼ˆæ–‡å­—åˆ—åˆ—ã‚’ä¿æŒï¼‰")

    # past_avg_sotai_chakujunã¯SQLã§è¨ˆç®—æ¸ˆã¿ã®å˜ç´”ç§»å‹•å¹³å‡ã‚’ä½¿ç”¨
    # (EWMå®Ÿé¨“ã®çµæœã€å˜ç´”å¹³å‡ã®æ–¹ãŒè¤‡å‹ãƒ»ä¸‰é€£è¤‡ã§å®‰å®šã—ãŸæ€§èƒ½ã‚’ç¤ºã—ãŸ)

    # ç‰¹å¾´é‡ã‚’é¸æŠï¼ˆmodel_creator.pyã¨åŒã˜ç‰¹å¾´é‡ï¼‰
    X = df.loc[:, [
        # "futan_juryo",
        "past_score",
        "kohan_3f_index",
        "past_avg_sotai_chakujun",
        "time_index",
    ]].astype(float)
    
    # é«˜æ€§èƒ½ãªæ´¾ç”Ÿç‰¹å¾´é‡ã‚’è¿½åŠ ï¼ï¼ˆmodel_creator.pyã¨åŒã˜ï¼‰
    # æ ç•ªã¨é ­æ•°ã®æ¯”ç‡ï¼ˆå†…æ æœ‰åˆ©åº¦ï¼‰
    max_wakuban = df.groupby(['kaisai_nen', 'kaisai_tsukihi', 'race_bango'])['wakuban'].transform('max')
    df['wakuban_ratio'] = df['wakuban'] / max_wakuban
    X['wakuban_ratio'] = df['wakuban_ratio']
    
    # æ–¤é‡ã¨é¦¬é½¢ã®æ¯”ç‡ï¼ˆè‹¥é¦¬ã®è² æ‹…èƒ½åŠ›ï¼‰
    df['futan_per_barei'] = df['futan_juryo'] / df['barei'].replace(0, 1)
    X['futan_per_barei'] = df['futan_per_barei']
    
    # ğŸ”¥æ”¹å–„ã•ã‚ŒãŸç‰¹å¾´é‡ğŸ”¥
    # 2. futan_per_bareiã®éç·šå½¢å¤‰æ›
    df['futan_per_barei_log'] = np.log(df['futan_per_barei'].clip(lower=0.1))
    X['futan_per_barei_log'] = df['futan_per_barei_log']
    
    # æœŸå¾…æ–¤é‡ã‹ã‚‰ã®å·®åˆ†ï¼ˆå¹´é½¢åˆ¥æœŸå¾…æ–¤é‡ã¨ã®å·®ï¼‰
    expected_weight_by_age = {2: 48, 3: 52, 4: 55, 5: 57, 6: 57, 7: 56, 8: 55}
    df['futan_deviation'] = df.apply(
        lambda row: row['futan_juryo'] - expected_weight_by_age.get(row['barei'], 55), 
        axis=1
    )
    X['futan_deviation'] = df['futan_deviation']

    # é¦¬ç•ªÃ—è·é›¢ã®ç›¸äº’ä½œç”¨ï¼ˆå†…å¤–æ ã®è·é›¢é©æ€§ï¼‰
    df['umaban_kyori_interaction'] = df['umaban_numeric'] * df['kyori'] / 1000  # ã‚¹ã‚±ãƒ¼ãƒ«èª¿æ•´
    X['umaban_kyori_interaction'] = df['umaban_kyori_interaction']
    
    # 4. è¤‡æ•°ã®ãƒ”ãƒ¼ã‚¯å¹´é½¢ãƒ‘ã‚¿ãƒ¼ãƒ³
    # df['barei_peak_distance'] = abs(df['barei'] - 4)  # 4æ­³ã‚’ãƒ”ãƒ¼ã‚¯ã¨ä»®å®šï¼ˆæ—¢å­˜ï¼‰
    # X['barei_peak_distance'] = df['barei_peak_distance']
    
    # 3æ­³çŸ­è·é›¢ãƒ”ãƒ¼ã‚¯ï¼ˆæ—©ç†Ÿå‹ï¼‰
    # df['barei_peak_short'] = abs(df['barei'] - 3)
    # X['barei_peak_short'] = df['barei_peak_short']
    
    # # 5æ­³é•·è·é›¢ãƒ”ãƒ¼ã‚¯ï¼ˆæ™©æˆå‹ï¼‰
    # df['barei_peak_long'] = abs(df['barei'] - 5)
    # X['barei_peak_long'] = df['barei_peak_long']

    # 5. æ ç•ªãƒã‚¤ã‚¢ã‚¹ã‚¹ã‚³ã‚¢ï¼ˆæ ç•ªã®æ­´å²çš„å„ªä½æ€§ã‚’æ•°å€¤åŒ–ï¼‰
    # æ ç•ªåˆ¥ã®æ­´å²çš„ç€é †åˆ†å¸ƒã‚’è¨ˆç®—
    wakuban_stats = df.groupby('wakuban').agg({
        'kakutei_chakujun_numeric': ['mean', 'std', 'count']
    }).round(4)
    wakuban_stats.columns = ['waku_avg_rank', 'waku_std_rank', 'waku_count']
    wakuban_stats = wakuban_stats.reset_index()
    
    # å…¨ä½“å¹³å‡ã‹ã‚‰ã®åå·®ã§ãƒã‚¤ã‚¢ã‚¹ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
    overall_avg_rank = df['kakutei_chakujun_numeric'].mean()
    wakuban_stats['wakuban_bias_score'] = (overall_avg_rank - wakuban_stats['waku_avg_rank']) / wakuban_stats['waku_std_rank']
    wakuban_stats['wakuban_bias_score'] = wakuban_stats['wakuban_bias_score'].fillna(0)  # NaNã‚’0ã§åŸ‹ã‚ã‚‹
    
    # DataFrameã«ãƒãƒ¼ã‚¸
    df = df.merge(wakuban_stats[['wakuban', 'wakuban_bias_score']], on='wakuban', how='left')
    # X['wakuban_bias_score'] = df['wakuban_bias_score']

    # ãƒ¬ãƒ¼ã‚¹å†…ã§ã®é¦¬ç•ªç›¸å¯¾ä½ç½®ï¼ˆé ­æ•°ã«ã‚ˆã‚‹æ­£è¦åŒ–ï¼‰
    df['umaban_percentile'] = df.groupby(['kaisai_nen', 'kaisai_tsukihi', 'race_bango'])['umaban_numeric'].transform(
        lambda x: x.rank(pct=True)
    )
    X['umaban_percentile'] = df['umaban_percentile']
    
    # ç ”ç©¶ç”¨ç‰¹å¾´é‡ è¿½åŠ 
    # æ–¤é‡åå·®å€¤ï¼ˆãƒ¬ãƒ¼ã‚¹å†…ã§æ¨™æº–åŒ–ï¼‰
    # ãƒ¬ãƒ¼ã‚¹å†…ã®å¹³å‡ã¨æ¨™æº–åå·®ã‚’è¨ˆç®—ã—ã¦ã€å„é¦¬ã®æ–¤é‡ãŒã©ã‚Œãã‚‰ã„é‡ã„/è»½ã„ã‹ã‚’è¡¨ç¾
    race_group = df.groupby(['kaisai_nen', 'kaisai_tsukihi', 'race_bango'])['futan_juryo']
    df['futan_mean'] = race_group.transform('mean')
    df['futan_std'] = race_group.transform('std')
    
    # æ¨™æº–åå·®ãŒ0ã®å ´åˆï¼ˆå…¨é ­åŒã˜æ–¤é‡ï¼‰ã¯0ã«ã™ã‚‹
    df['futan_zscore'] = np.where(
        df['futan_std'] > 0,
        (df['futan_juryo'] - df['futan_mean']) / df['futan_std'],
        0
    )
    X['futan_zscore'] = df['futan_zscore']
    
    # ãƒ¬ãƒ¼ã‚¹å†…ã§ã®æ–¤é‡é †ä½ï¼ˆãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ï¼‰
    # 0.0=æœ€è»½é‡ã€1.0=æœ€é‡é‡
    df['futan_percentile'] = race_group.transform(lambda x: x.rank(pct=True))
    X['futan_percentile'] = df['futan_percentile']

    # ğŸ”¥æ–°æ©Ÿèƒ½: è·é›¢é©æ€§ã‚¹ã‚³ã‚¢ã‚’è¿½åŠ ï¼ˆ3ç¨®é¡ï¼‰ğŸ”¥
    # model_creator.pyã¨åŒã˜å‡¦ç†ã‚’å®Ÿè¡Œ
    
    # è·é›¢ã‚«ãƒ†ã‚´ãƒªåˆ†é¡é–¢æ•°
    def categorize_distance(kyori):
        """è·é›¢ã‚’4ã‚«ãƒ†ã‚´ãƒªã«åˆ†é¡"""
        if kyori <= 1400:
            return 'short'  # çŸ­è·é›¢
        elif kyori <= 1800:
            return 'mile'   # ãƒã‚¤ãƒ«
        elif kyori <= 2400:
            return 'middle' # ä¸­è·é›¢
        else:
            return 'long'   # é•·è·é›¢
    
    # ä»Šå›ã®ãƒ¬ãƒ¼ã‚¹ã®è·é›¢ã‚«ãƒ†ã‚´ãƒªã‚’è¿½åŠ 
    df['distance_category'] = df['kyori'].apply(categorize_distance)
    
    # ğŸ”¥é‡è¦: é¦¬å ´æƒ…å ±ã‚‚å…ˆã«è¿½åŠ ï¼ˆdf_sortedã§ä½¿ã†ãŸã‚ï¼‰ğŸ”¥
    # èŠ/ãƒ€ãƒ¼ãƒˆåˆ†é¡é–¢æ•°
    def categorize_surface(track_code):
        """ãƒˆãƒ©ãƒƒã‚¯ã‚³ãƒ¼ãƒ‰ã‹ã‚‰èŠ/ãƒ€ãƒ¼ãƒˆã‚’åˆ¤å®š"""
        track_code_int = int(track_code)
        if 10 <= track_code_int <= 22:
            return 'turf'
        elif 23 <= track_code_int <= 24:
            return 'dirt'
        else:
            return 'unknown'
    
    # é¦¬å ´çŠ¶æ…‹åˆ†é¡é–¢æ•°
    def categorize_baba_condition(baba_code):
        """é¦¬å ´çŠ¶æ…‹ã‚³ãƒ¼ãƒ‰ã‚’åˆ†é¡"""
        if baba_code == 1:
            return 'good'
        elif baba_code == 2:
            return 'slightly'
        elif baba_code == 3:
            return 'heavy'
        elif baba_code == 4:
            return 'bad'
        else:
            return 'unknown'
    
    # ä»Šå›ã®ãƒ¬ãƒ¼ã‚¹ã®é¦¬å ´æƒ…å ±ã‚’è¿½åŠ 
    df['surface_type'] = df['track_code'].apply(categorize_surface)
    df['baba_condition'] = df['babajotai_code'].apply(categorize_baba_condition)
    
    # æ™‚ç³»åˆ—é †ã«ã‚½ãƒ¼ãƒˆï¼ˆé¦¬ã”ã¨ã«éå»ãƒ‡ãƒ¼ã‚¿ã‚’å‚ç…§ã™ã‚‹ãŸã‚ï¼‰
    df_sorted = df.sort_values(['ketto_toroku_bango', 'kaisai_nen', 'kaisai_tsukihi']).copy()
    
    # 1ï¸âƒ£ è·é›¢ã‚«ãƒ†ã‚´ãƒªåˆ¥é©æ€§ã‚¹ã‚³ã‚¢
    def calc_distance_category_score(group):
        scores = []
        for idx in range(len(group)):
            if idx == 0:
                scores.append(0.5)  # âœ… ä¿®æ­£: ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã¯ä¸­ç«‹å€¤
                continue
            
            current_category = group.iloc[idx]['distance_category']
            past_same_category = group.iloc[:idx][
                group.iloc[:idx]['distance_category'] == current_category
            ].tail(5)
            
            if len(past_same_category) > 0:
                avg_score = (1 - (past_same_category['kakutei_chakujun_numeric'] / 18.0)).mean()
                scores.append(avg_score)
            else:
                scores.append(0.5)  # âœ… ä¿®æ­£: ãƒ‡ãƒ¼ã‚¿ãªã—ã¯ä¸­ç«‹å€¤
        
        return pd.Series(scores, index=group.index)
    
    df_sorted['distance_category_score'] = df_sorted.groupby('ketto_toroku_bango', group_keys=False).apply(
        calc_distance_category_score
    ).values
    
    # 2ï¸âƒ£ è¿‘ä¼¼è·é›¢ã§ã®æˆç¸¾
    def calc_similar_distance_score(group):
        scores = []
        for idx in range(len(group)):
            if idx == 0:
                scores.append(0.5)  # âœ… ä¿®æ­£: ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã¯ä¸­ç«‹å€¤
                continue
            
            current_kyori = group.iloc[idx]['kyori']
            past_similar = group.iloc[:idx][
                abs(group.iloc[:idx]['kyori'] - current_kyori) <= 200
            ].tail(10)
            
            if len(past_similar) > 0:
                avg_score = (1 - (past_similar['kakutei_chakujun_numeric'] / 18.0)).mean()
                scores.append(avg_score)
            else:
                scores.append(0.5)  # âœ… ä¿®æ­£: ãƒ‡ãƒ¼ã‚¿ãªã—ã¯ä¸­ç«‹å€¤
        
        return pd.Series(scores, index=group.index)
    
    df_sorted['similar_distance_score'] = df_sorted.groupby('ketto_toroku_bango', group_keys=False).apply(
        calc_similar_distance_score
    ).values
    
    # 3ï¸âƒ£ è·é›¢å¤‰åŒ–å¯¾å¿œåŠ›
    def calc_distance_change_adaptability(group):
        scores = []
        for idx in range(len(group)):
            if idx < 2:
                scores.append(0.5)  # âœ… ä¿®æ­£: ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã¯ä¸­ç«‹å€¤
                continue
            
            # âœ… ä¿®æ­£: éå»6èµ°åˆ†ã‚’å–å¾—ï¼ˆå‰èµ°ã¨ã®å·®åˆ†ã‚’è¦‹ã‚‹ãŸã‚ï¼‰
            past_races = group.iloc[max(0, idx-6):idx].copy()
            
            if len(past_races) >= 3:  # âœ… ä¿®æ­£: æœ€ä½3èµ°å¿…è¦ï¼ˆå·®åˆ†2å€‹ï¼‰
                past_races['kyori_diff'] = past_races['kyori'].diff().abs()
                
                # âœ… ä¿®æ­£: æœ€æ–°5èµ°ã®ã¿ã‚’è©•ä¾¡ï¼ˆæœ€åˆã®1è¡Œã¯NaNãªã®ã§é™¤å¤–ï¼‰
                past_races_eval = past_races.tail(5)
                changed_races = past_races_eval[past_races_eval['kyori_diff'] >= 100]
                
                if len(changed_races) > 0:
                    avg_score = (1 - (changed_races['kakutei_chakujun_numeric'] / 18.0)).mean()
                    scores.append(avg_score)
                else:
                    scores.append(0.5)  # âœ… ä¿®æ­£: å¤‰åŒ–ãªã—ã¯ä¸­ç«‹
            else:
                scores.append(0.5)  # âœ… ä¿®æ­£: ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã¯ä¸­ç«‹å€¤
        
        return pd.Series(scores, index=group.index)
    
    df_sorted['distance_change_adaptability'] = df_sorted.groupby('ketto_toroku_bango', group_keys=False).apply(
        calc_distance_change_adaptability
    ).values
    
    # å…ƒã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹é †ã«æˆ»ã™
    df = df.copy()
    df['distance_category_score'] = df_sorted.sort_index()['distance_category_score']
    df['similar_distance_score'] = df_sorted.sort_index()['similar_distance_score']
    df['distance_change_adaptability'] = df_sorted.sort_index()['distance_change_adaptability']
    
    # ç‰¹å¾´é‡ã«è¿½åŠ 
    X['distance_category_score'] = df['distance_category_score']
    X['similar_distance_score'] = df['similar_distance_score']
    # X['distance_change_adaptability'] = df['distance_change_adaptability']

    # ğŸ”¥æ–°æ©Ÿèƒ½: é¦¬å ´é©æ€§ã‚¹ã‚³ã‚¢ã‚’è¿½åŠ ï¼ˆ3ç¨®é¡ï¼‰ğŸ”¥
    # é¦¬å ´æƒ…å ±ã¯æ—¢ã«df_sortedã«å«ã¾ã‚Œã¦ã„ã‚‹ã®ã§ã€ãã®ã¾ã¾ä½¿ç”¨
    
    # 1ï¸âƒ£ èŠ/ãƒ€ãƒ¼ãƒˆåˆ¥é©æ€§ã‚¹ã‚³ã‚¢
    def calc_surface_score(group):
        scores = []
        for idx in range(len(group)):
            if idx == 0:
                scores.append(0.5)  # âœ… ä¿®æ­£: ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã¯ä¸­ç«‹å€¤
                continue
            
            current_surface = group.iloc[idx]['surface_type']
            past_same_surface = group.iloc[:idx][
                group.iloc[:idx]['surface_type'] == current_surface
            ].tail(10)
            
            if len(past_same_surface) > 0:
                avg_score = (1 - (past_same_surface['kakutei_chakujun_numeric'] / 18.0)).mean()
                scores.append(avg_score)
            else:
                scores.append(0.5)  # âœ… ä¿®æ­£: ãƒ‡ãƒ¼ã‚¿ãªã—ã¯ä¸­ç«‹å€¤
        
        return pd.Series(scores, index=group.index)
    
    df_sorted['surface_aptitude_score'] = df_sorted.groupby('ketto_toroku_bango', group_keys=False).apply(
        calc_surface_score
    ).values
    
    # 2ï¸âƒ£ é¦¬å ´çŠ¶æ…‹åˆ¥é©æ€§ã‚¹ã‚³ã‚¢
    def calc_baba_condition_score(group):
        scores = []
        for idx in range(len(group)):
            if idx == 0:
                scores.append(0.5)  # âœ… ä¿®æ­£: ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã¯ä¸­ç«‹å€¤
                continue
            
            current_condition = group.iloc[idx]['baba_condition']
            past_same_condition = group.iloc[:idx][
                group.iloc[:idx]['baba_condition'] == current_condition
            ].tail(10)
            
            if len(past_same_condition) > 0:
                avg_score = (1 - (past_same_condition['kakutei_chakujun_numeric'] / 18.0)).mean()
                scores.append(avg_score)
            else:
                scores.append(0.5)  # âœ… ä¿®æ­£: ãƒ‡ãƒ¼ã‚¿ãªã—ã¯ä¸­ç«‹å€¤
        
        return pd.Series(scores, index=group.index)
    
    df_sorted['baba_condition_score'] = df_sorted.groupby('ketto_toroku_bango', group_keys=False).apply(
        calc_baba_condition_score
    ).values
    
    # 3ï¸âƒ£ é¦¬å ´å¤‰åŒ–å¯¾å¿œåŠ›
    def calc_baba_change_adaptability(group):
        scores = []
        for idx in range(len(group)):
            if idx < 2:
                scores.append(0.5)  # âœ… ä¿®æ­£: ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã¯ä¸­ç«‹å€¤
                continue
            
            # âœ… ä¿®æ­£: éå»6èµ°åˆ†ã‚’å–å¾—ï¼ˆå‰èµ°ã¨ã®å¤‰åŒ–ã‚’è¦‹ã‚‹ãŸã‚ï¼‰
            past_races = group.iloc[max(0, idx-6):idx].copy()
            
            if len(past_races) >= 3:  # âœ… ä¿®æ­£: æœ€ä½3èµ°å¿…è¦
                past_races['baba_changed'] = past_races['baba_condition'].shift(1) != past_races['baba_condition']
                
                # âœ… ä¿®æ­£: æœ€æ–°5èµ°ã®ã¿ã‚’è©•ä¾¡
                past_races_eval = past_races.tail(5)
                changed_races = past_races_eval[past_races_eval['baba_changed'] == True]
                
                if len(changed_races) > 0:
                    avg_score = (1 - (changed_races['kakutei_chakujun_numeric'] / 18.0)).mean()
                    scores.append(avg_score)
                else:
                    scores.append(0.5)  # âœ… ä¿®æ­£: å¤‰åŒ–ãªã—ã¯ä¸­ç«‹
            else:
                scores.append(0.5)  # âœ… ä¿®æ­£: ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã¯ä¸­ç«‹å€¤
        
        return pd.Series(scores, index=group.index)
    
    df_sorted['baba_change_adaptability'] = df_sorted.groupby('ketto_toroku_bango', group_keys=False).apply(
        calc_baba_change_adaptability
    ).values
    
    # å…ƒã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹é †ã«æˆ»ã™
    df['surface_aptitude_score'] = df_sorted.sort_index()['surface_aptitude_score']
    df['baba_condition_score'] = df_sorted.sort_index()['baba_condition_score']
    df['baba_change_adaptability'] = df_sorted.sort_index()['baba_change_adaptability']
    
    # ç‰¹å¾´é‡ã«è¿½åŠ 
    X['surface_aptitude_score'] = df['surface_aptitude_score']
    # X['baba_condition_score'] = df['baba_condition_score']
    X['baba_change_adaptability'] = df['baba_change_adaptability']

    # ğŸ”¥æ–°æ©Ÿèƒ½: é¨æ‰‹ãƒ»èª¿æ•™å¸«ã®å‹•çš„èƒ½åŠ›ã‚¹ã‚³ã‚¢ã‚’è¿½åŠ ï¼ˆ4ç¨®é¡ï¼‰ğŸ”¥
    # model_creator.pyã¨å®Œå…¨ã«åŒã˜ãƒ­ã‚¸ãƒƒã‚¯
    
    # âœ… ä¿®æ­£: race_bangoã‚’è¿½åŠ ã—ã¦æ™‚ç³»åˆ—ãƒªãƒ¼ã‚¯ã‚’é˜²æ­¢
    df_sorted_kishu = df.sort_values(['kishu_code', 'kaisai_nen', 'kaisai_tsukihi', 'race_bango']).copy()
    
    # 1ï¸âƒ£ é¨æ‰‹ã®å®ŸåŠ›è£œæ­£ã‚¹ã‚³ã‚¢ï¼ˆæœŸå¾…ç€é †ã¨ã®å·®åˆ†ã€ç›´è¿‘3ãƒ¶æœˆï¼‰
    def calc_kishu_skill_adjusted_score(group):
        """é¨æ‰‹ã®ç´”ç²‹ãªæŠ€è¡“ã‚’è©•ä¾¡ï¼ˆé¦¬ã®å®ŸåŠ›ã‚’è£œæ­£ï¼‰"""
        scores = []
        
        for idx in range(len(group)):
            # é¨æ‰‹ã‚³ãƒ¼ãƒ‰ãŒãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            if pd.isna(group.iloc[idx]['kishu_code']) or group.iloc[idx]['kishu_code'] == '':
                scores.append(0.5)
                continue
                
            current_date = pd.to_datetime(
                str(int(group.iloc[idx]['kaisai_nen'])) + str(int(group.iloc[idx]['kaisai_tsukihi'])).zfill(4),
                format='%Y%m%d'
            )
            
            # 3ãƒ¶æœˆå‰ã®æ—¥ä»˜
            three_months_ago = current_date - pd.DateOffset(months=3)
            
            # éå»3ãƒ¶æœˆã®ãƒ¬ãƒ¼ã‚¹ã‚’æŠ½å‡ºï¼ˆæœªæ¥ã®ãƒ‡ãƒ¼ã‚¿ã¯è¦‹ãªã„ï¼ï¼‰
            past_races = group.iloc[:idx]
            
            if len(past_races) > 0:
                past_races = past_races.copy()
                past_races['kaisai_date'] = pd.to_datetime(
                    past_races['kaisai_nen'].astype(str) + past_races['kaisai_tsukihi'].astype(str).str.zfill(4),
                    format='%Y%m%d'
                )
                recent_races = past_races[past_races['kaisai_date'] >= three_months_ago]
                
                if len(recent_races) >= 3:  # æœ€ä½3ãƒ¬ãƒ¼ã‚¹å¿…è¦
                    # âœ… ä¿®æ­£: é¨æ‰‹ã®ç´”ç²‹ãªæˆç¸¾ã‚’è©•ä¾¡ï¼ˆé¦¬ã®å®ŸåŠ›è£œæ­£ã§ã¯ãªãã€é¨æ‰‹ã®å¹³å‡æˆç¸¾ï¼‰
                    # ç€é †ã‚’ã‚¹ã‚³ã‚¢åŒ–ï¼ˆ1ç€=1.0, 18ç€=0.0ï¼‰
                    recent_races['rank_score'] = 1.0 - ((18 - recent_races['kakutei_chakujun_numeric'] + 1) / 18.0)
                    
                    # é¨æ‰‹ã®å¹³å‡ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
                    avg_score = recent_races['rank_score'].mean()
                    
                    # 0-1ã®ç¯„å›²ã«ã‚¯ãƒªãƒƒãƒ—ï¼ˆæ—¢ã«ç¯„å›²å†…ã ãŒå¿µã®ãŸã‚ï¼‰
                    normalized_score = max(0.0, min(1.0, avg_score))
                    
                    scores.append(normalized_score)
                else:
                    scores.append(0.5)  # ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã¯ä¸­ç«‹
            else:
                scores.append(0.5)  # åˆå›ã¯ä¸­ç«‹
        
        return pd.Series(scores, index=group.index)
    
    df_sorted_kishu['kishu_skill_score'] = df_sorted_kishu.groupby('kishu_code', group_keys=False).apply(
        calc_kishu_skill_adjusted_score
    ).values
    
    # 2ï¸âƒ£ é¨æ‰‹ã®äººæ°—å·®ã‚¹ã‚³ã‚¢ï¼ˆã‚ªãƒƒã‚ºè£œæ­£ã€ç›´è¿‘3ãƒ¶æœˆï¼‰
    def calc_kishu_popularity_adjusted_score(group):
        """é¨æ‰‹ã®äººæ°—è£œæ­£ã‚¹ã‚³ã‚¢ï¼ˆäººæ°—ã‚ˆã‚Šä¸Šä½ã«æ¥ã‚Œã‚‹ã‹ï¼‰"""
        scores = []
        
        for idx in range(len(group)):
            if pd.isna(group.iloc[idx]['kishu_code']) or group.iloc[idx]['kishu_code'] == '':
                scores.append(0.5)
                continue
                
            current_date = pd.to_datetime(
                str(int(group.iloc[idx]['kaisai_nen'])) + str(int(group.iloc[idx]['kaisai_tsukihi'])).zfill(4),
                format='%Y%m%d'
            )
            
            three_months_ago = current_date - pd.DateOffset(months=3)
            
            past_races = group.iloc[:idx]
            
            if len(past_races) > 0:
                past_races = past_races.copy()
                past_races['kaisai_date'] = pd.to_datetime(
                    past_races['kaisai_nen'].astype(str) + past_races['kaisai_tsukihi'].astype(str).str.zfill(4),
                    format='%Y%m%d'
                )
                recent_races = past_races[past_races['kaisai_date'] >= three_months_ago]
                
                if len(recent_races) >= 3:
                    # ã‚ªãƒƒã‚ºãŒ0ã‚„ç•°å¸¸å€¤ã®å ´åˆã‚’é™¤å¤–
                    valid_races = recent_races[recent_races['tansho_odds'] > 0]
                    
                    if len(valid_races) >= 3:
                        # âœ… ä¿®æ­£: ã‚ªãƒƒã‚ºãƒ™ãƒ¼ã‚¹ã®æœŸå¾…æˆç¸¾ã¨å®Ÿéš›ã®æˆç¸¾ã‚’æ¯”è¼ƒ
                        # ã‚ªãƒƒã‚ºãŒä½ã„ = æœŸå¾…å€¤ãŒé«˜ã„ï¼ˆ1ã«è¿‘ã„ï¼‰
                        # ã‚ªãƒƒã‚ºãŒé«˜ã„ = æœŸå¾…å€¤ãŒä½ã„ï¼ˆ0ã«è¿‘ã„ï¼‰
                        max_odds = valid_races['tansho_odds'].max()
                        valid_races['odds_expectation'] = 1.0 - (valid_races['tansho_odds'] / (max_odds + 1.0))
                        
                        # å®Ÿéš›ã®æˆç¸¾ã‚¹ã‚³ã‚¢
                        valid_races['actual_score'] = 1.0 - ((18 - valid_races['kakutei_chakujun_numeric'] + 1) / 18.0)
                        
                        # æœŸå¾…ã‚’ä¸Šå›ã£ãŸåº¦åˆã„ï¼ˆãƒ—ãƒ©ã‚¹ãªã‚‰æœŸå¾…ä»¥ä¸Šï¼‰
                        valid_races['performance_diff'] = valid_races['actual_score'] - valid_races['odds_expectation']
                        
                        # å¹³å‡å·®åˆ†ã‚’ã‚¹ã‚³ã‚¢åŒ–ï¼ˆ0.5ãŒä¸­ç«‹ï¼‰
                        avg_diff = valid_races['performance_diff'].mean()
                        normalized_score = 0.5 + (avg_diff * 0.5)  # Â±0.5ã®ç¯„å›²ã«åã‚ã‚‹
                        normalized_score = max(0.0, min(1.0, normalized_score))
                        
                        scores.append(normalized_score)
                    else:
                        scores.append(0.5)
                else:
                    scores.append(0.5)
            else:
                scores.append(0.5)
        
        return pd.Series(scores, index=group.index)
    
    df_sorted_kishu['kishu_popularity_score'] = df_sorted_kishu.groupby('kishu_code', group_keys=False).apply(
        calc_kishu_popularity_adjusted_score
    ).values
    
    # 3ï¸âƒ£ é¨æ‰‹ã®èŠ/ãƒ€ãƒ¼ãƒˆåˆ¥ã‚¹ã‚³ã‚¢ï¼ˆé¦¬å ´é©æ€§è€ƒæ…®ã€ç›´è¿‘6ãƒ¶æœˆï¼‰
    def calc_kishu_surface_score(group):
        """é¨æ‰‹ã®é¦¬å ´ã‚¿ã‚¤ãƒ—åˆ¥ç›´è¿‘6ãƒ¶æœˆæˆç¸¾"""
        scores = []
        
        for idx in range(len(group)):
            if pd.isna(group.iloc[idx]['kishu_code']) or group.iloc[idx]['kishu_code'] == '':
                scores.append(0.5)
                continue
                
            current_date = pd.to_datetime(
                str(int(group.iloc[idx]['kaisai_nen'])) + str(int(group.iloc[idx]['kaisai_tsukihi'])).zfill(4),
                format='%Y%m%d'
            )
            current_surface = group.iloc[idx]['surface_type']
            
            six_months_ago = current_date - pd.DateOffset(months=6)
            
            past_races = group.iloc[:idx]
            
            if len(past_races) > 0:
                past_races = past_races.copy()
                past_races['kaisai_date'] = pd.to_datetime(
                    past_races['kaisai_nen'].astype(str) + past_races['kaisai_tsukihi'].astype(str).str.zfill(4),
                    format='%Y%m%d'
                )
                # åŒã˜é¦¬å ´ã‚¿ã‚¤ãƒ—ã§ã®ç›´è¿‘6ãƒ¶æœˆ
                recent_same_surface = past_races[
                    (past_races['kaisai_date'] >= six_months_ago) &
                    (past_races['surface_type'] == current_surface)
                ]
                
                if len(recent_same_surface) >= 5:  # æœ€ä½5ãƒ¬ãƒ¼ã‚¹å¿…è¦
                    avg_score = (1 - ((18 - recent_same_surface['kakutei_chakujun_numeric'] + 1) / 18.0)).mean()
                    scores.append(avg_score)
                else:
                    scores.append(0.5)
            else:
                scores.append(0.5)
        
        return pd.Series(scores, index=group.index)
    
    df_sorted_kishu['kishu_surface_score'] = df_sorted_kishu.groupby('kishu_code', group_keys=False).apply(
        calc_kishu_surface_score
    ).values
    
    # âœ… ä¿®æ­£: race_bangoã‚’è¿½åŠ ã—ã¦æ™‚ç³»åˆ—ãƒªãƒ¼ã‚¯ã‚’é˜²æ­¢
    df_sorted_chokyoshi = df.sort_values(['chokyoshi_code', 'kaisai_nen', 'kaisai_tsukihi', 'race_bango']).copy()
    
    # 4ï¸âƒ£ èª¿æ•™å¸«ã®ç›´è¿‘3ãƒ¶æœˆæˆç¸¾ã‚¹ã‚³ã‚¢
    def calc_chokyoshi_recent_score(group):
        """èª¿æ•™å¸«ã®ç›´è¿‘3ãƒ¶æœˆæˆç¸¾"""
        scores = []
        
        for idx in range(len(group)):
            if pd.isna(group.iloc[idx]['chokyoshi_code']) or group.iloc[idx]['chokyoshi_code'] == '':
                scores.append(0.5)
                continue
                
            current_date = pd.to_datetime(
                str(int(group.iloc[idx]['kaisai_nen'])) + str(int(group.iloc[idx]['kaisai_tsukihi'])).zfill(4),
                format='%Y%m%d'
            )
            
            three_months_ago = current_date - pd.DateOffset(months=3)
            
            past_races = group.iloc[:idx]
            
            if len(past_races) > 0:
                past_races = past_races.copy()
                past_races['kaisai_date'] = pd.to_datetime(
                    past_races['kaisai_nen'].astype(str) + past_races['kaisai_tsukihi'].astype(str).str.zfill(4),
                    format='%Y%m%d'
                )
                recent_races = past_races[past_races['kaisai_date'] >= three_months_ago]
                
                if len(recent_races) >= 5:  # âœ… ä¿®æ­£: 5ãƒ¬ãƒ¼ã‚¹ã«å¤‰æ›´ï¼ˆ10ãƒ¬ãƒ¼ã‚¹ã§ã¯å¤§éƒ¨åˆ†ãŒä¸­ç«‹å€¤ã«ãªã‚‹ï¼‰
                    avg_score = (1 - ((18 - recent_races['kakutei_chakujun_numeric'] + 1) / 18.0)).mean()
                    scores.append(avg_score)
                else:
                    scores.append(0.5)
            else:
                scores.append(0.5)
        
        return pd.Series(scores, index=group.index)
    
    df_sorted_chokyoshi['chokyoshi_recent_score'] = df_sorted_chokyoshi.groupby('chokyoshi_code', group_keys=False).apply(
        calc_chokyoshi_recent_score
    ).values
    
    # å…ƒã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹é †ã«æˆ»ã™
    df['kishu_skill_score'] = df_sorted_kishu.sort_index()['kishu_skill_score']
    df['kishu_popularity_score'] = df_sorted_kishu.sort_index()['kishu_popularity_score']
    df['kishu_surface_score'] = df_sorted_kishu.sort_index()['kishu_surface_score']
    df['chokyoshi_recent_score'] = df_sorted_chokyoshi.sort_index()['chokyoshi_recent_score']
    
    # ç‰¹å¾´é‡ã«è¿½åŠ 
    X['kishu_skill_score'] = df['kishu_skill_score']
    X['kishu_popularity_score'] = df['kishu_popularity_score']
    X['kishu_surface_score'] = df['kishu_surface_score']
    X['chokyoshi_recent_score'] = df['chokyoshi_recent_score']

    # éå»ãƒ¬ãƒ¼ã‚¹ã§ã€Œäººæ°—è–„ãªã®ã«å¥½èµ°ã—ãŸå›æ•°ã€
    # df['upset_count'] = df.groupby('ketto_toroku_bango').apply(
    #     lambda g: ((g['tansho_ninkijun_numeric'] >= 5) & (g['kakutei_chakujun_numeric'] <= 3)).sum()
    # )
    # X['upset_count'] = df['upset_count']

    # # ç ”ç©¶ç”¨ç‰¹å¾´é‡ è¿½åŠ 

    # ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã‚’ä½œæˆ
    # X['kyori'] = X['kyori'].astype('category')
    # X['tenko_code'] = X['tenko_code'].astype('category')
    # X['babajotai_code'] = X['babajotai_code'].astype('category')
    # X['seibetsu_code'] = X['seibetsu_code'].astype('category')

    # ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
    try:
        with open(model_filename, 'rb') as model_file:
            model = pickle.load(model_file)
    except FileNotFoundError:
        print(f"âŒ ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ« {model_filename} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return None, None, 0

    # ã‚·ã‚°ãƒ¢ã‚¤ãƒ‰é–¢æ•°ã‚’å®šç¾©
    def sigmoid(x):
        """å€¤ã‚’0-1ã®ç¯„å›²ã«åã‚ã‚‹ã‚ˆï½"""
        return 1 / (1 + np.exp(-x))

    # äºˆæ¸¬ã‚’å®Ÿè¡Œã—ã¦ã€ã‚·ã‚°ãƒ¢ã‚¤ãƒ‰é–¢æ•°ã§å¤‰æ›
    raw_scores = model.predict(X)
    df['predicted_chakujun_score'] = sigmoid(raw_scores)

    # ãƒ‡ãƒ¼ã‚¿ã‚’ã‚½ãƒ¼ãƒˆ
    df = df.sort_values(by=['kaisai_nen', 'kaisai_tsukihi', 'race_bango', 'umaban'], ascending=True)

    # ã‚°ãƒ«ãƒ¼ãƒ—å†…ã§ã®ã‚¹ã‚³ã‚¢é †ä½ã‚’è¨ˆç®—
    df['score_rank'] = df.groupby(['kaisai_nen', 'kaisai_tsukihi', 'race_bango'])['predicted_chakujun_score'].rank(method='min', ascending=False)

    # kakutei_chakujun_numeric ã¨ score_rank ã‚’æ•´æ•°ã«å¤‰æ›
    df['kakutei_chakujun_numeric'] = df['kakutei_chakujun_numeric'].fillna(0).astype(int)
    df['tansho_ninkijun_numeric'] = df['tansho_ninkijun_numeric'].fillna(0).astype(int)
    df['score_rank'] = df['score_rank'].fillna(0).astype(int)
    
    # surface_typeåˆ—ã‚’è¿½åŠ ï¼ˆèŠãƒ»ãƒ€ãƒ¼ãƒˆåŒºåˆ†ï¼‰
    from keiba_constants import get_surface_name
    df['surface_type_name'] = get_surface_name(surface_type)

    # å¿…è¦ãªåˆ—ã‚’é¸æŠ
    output_columns = ['keibajo_name',
                      'kaisai_nen', 
                      'kaisai_tsukihi', 
                      'race_bango',
                      'surface_type_name',
                      'kyori',
                      'umaban', 
                      'bamei', 
                      'tansho_odds', 
                      'tansho_ninkijun_numeric', 
                      'kakutei_chakujun_numeric', 
                      'score_rank', 
                      'predicted_chakujun_score',
                      'è¤‡å‹1ç€é¦¬ç•ª',
                      'è¤‡å‹1ç€ã‚ªãƒƒã‚º',
                      'è¤‡å‹1ç€äººæ°—',
                      'è¤‡å‹2ç€é¦¬ç•ª',
                      'è¤‡å‹2ç€ã‚ªãƒƒã‚º',
                      'è¤‡å‹2ç€äººæ°—',
                      'è¤‡å‹3ç€é¦¬ç•ª',
                      'è¤‡å‹3ç€ã‚ªãƒƒã‚º',
                      'è¤‡å‹3ç€äººæ°—',
                      'é¦¬é€£é¦¬ç•ª1',
                      'é¦¬é€£é¦¬ç•ª2',
                      'é¦¬é€£ã‚ªãƒƒã‚º',
                      'ãƒ¯ã‚¤ãƒ‰1_2é¦¬ç•ª1',
                      'ãƒ¯ã‚¤ãƒ‰1_2é¦¬ç•ª2',
                      'ãƒ¯ã‚¤ãƒ‰2_3ç€é¦¬ç•ª1',
                      'ãƒ¯ã‚¤ãƒ‰2_3ç€é¦¬ç•ª2',
                      'ãƒ¯ã‚¤ãƒ‰1_3ç€é¦¬ç•ª1',
                      'ãƒ¯ã‚¤ãƒ‰1_3ç€é¦¬ç•ª2',
                      'ãƒ¯ã‚¤ãƒ‰1_2ã‚ªãƒƒã‚º',
                      'ãƒ¯ã‚¤ãƒ‰2_3ã‚ªãƒƒã‚º',
                      'ãƒ¯ã‚¤ãƒ‰1_3ã‚ªãƒƒã‚º',
                      'é¦¬å˜é¦¬ç•ª1',
                      'é¦¬å˜é¦¬ç•ª2',
                      'é¦¬å˜ã‚ªãƒƒã‚º',
                      'ï¼“é€£è¤‡ã‚ªãƒƒã‚º',]
    output_df = df[output_columns]

    # åˆ—åã‚’å¤‰æ›´
    output_df = output_df.rename(columns={
        'keibajo_name': 'ç«¶é¦¬å ´',
        'kaisai_nen': 'é–‹å‚¬å¹´',
        'kaisai_tsukihi': 'é–‹å‚¬æ—¥',
        'race_bango': 'ãƒ¬ãƒ¼ã‚¹ç•ªå·',
        'surface_type_name': 'èŠãƒ€åŒºåˆ†',
        'kyori': 'è·é›¢',
        'umaban': 'é¦¬ç•ª',
        'bamei': 'é¦¬å',
        'tansho_odds': 'å˜å‹ã‚ªãƒƒã‚º',
        'tansho_ninkijun_numeric': 'äººæ°—é †',
        'kakutei_chakujun_numeric': 'ç¢ºå®šç€é †',
        'score_rank': 'äºˆæ¸¬é †ä½',
        'predicted_chakujun_score': 'äºˆæ¸¬ã‚¹ã‚³ã‚¢'
    })

    # æ­£ã—ã„ãƒ¬ãƒ¼ã‚¹æ•°ã®è¨ˆç®—æ–¹æ³•ã¯ã“ã‚Œï½ï¼
    race_count = len(output_df.groupby(['é–‹å‚¬å¹´', 'é–‹å‚¬æ—¥', 'ãƒ¬ãƒ¼ã‚¹ç•ªå·']))

    # çš„ä¸­ç‡ãƒ»å›åç‡è¨ˆç®—ï¼ˆå…ƒã®test.pyã‹ã‚‰ç§»æ¤ï¼‰
    # å˜å‹ã®çš„ä¸­ç‡ã¨å›åç‡
    tansho_hit = (output_df['ç¢ºå®šç€é †'] == 1) & (output_df['äºˆæ¸¬é †ä½'] == 1)
    tansho_hitrate = 100 * tansho_hit.sum() / race_count
    tansho_recoveryrate = 100 * (tansho_hit * output_df['å˜å‹ã‚ªãƒƒã‚º']).sum() / race_count

    # è¤‡å‹ã®çš„ä¸­ç‡ã¨å›åç‡
    fukusho_hit = (output_df['ç¢ºå®šç€é †'].isin([1, 2, 3])) & (output_df['äºˆæ¸¬é †ä½'].isin([1, 2, 3]))
    fukusho_hitrate = fukusho_hit.sum() / (race_count * 3) * 100

    # çš„ä¸­é¦¬ã ã‘å–ã‚Šå‡ºã™
    hit_rows = output_df[fukusho_hit].copy()

    def extract_odds(row):
        if row['ç¢ºå®šç€é †'] == 1:
            return row['è¤‡å‹1ç€ã‚ªãƒƒã‚º']
        elif row['ç¢ºå®šç€é †'] == 2:
            return row['è¤‡å‹2ç€ã‚ªãƒƒã‚º']
        elif row['ç¢ºå®šç€é †'] == 3:
            return row['è¤‡å‹3ç€ã‚ªãƒƒã‚º']
        else:
            return 0

    # çš„ä¸­é¦¬ã«å¯¾å¿œã™ã‚‹æ‰•æˆ»ã‚’è¨ˆç®—ï¼ˆ100å††è³­ã‘ãŸã¨ã—ã¦ï¼‰
    hit_rows['çš„ä¸­ã‚ªãƒƒã‚º'] = hit_rows.apply(extract_odds, axis=1)
    total_payout = (hit_rows['çš„ä¸­ã‚ªãƒƒã‚º'] * 100).sum()

    # ç·è³¼å…¥é¡ï¼ˆæ¯ãƒ¬ãƒ¼ã‚¹ã§3é ­ã«100å††ãšã¤ï¼‰
    total_bet = race_count * 3 * 100
    fukusho_recoveryrate = total_payout / total_bet * 100

    # é¦¬é€£ã®çš„ä¸­ç‡ã¨å›åç‡
    umaren_hit = output_df.groupby(['é–‹å‚¬å¹´', 'é–‹å‚¬æ—¥', 'ãƒ¬ãƒ¼ã‚¹ç•ªå·']).apply(
        lambda x: set([1, 2]).issubset(set(x.sort_values('äºˆæ¸¬ã‚¹ã‚³ã‚¢', ascending=False).head(2)['ç¢ºå®šç€é †'].values))
    )
    umaren_hitrate = 100 * umaren_hit.sum() / race_count
    umaren_recoveryrate = 100 * (umaren_hit * output_df.groupby(['é–‹å‚¬å¹´', 'é–‹å‚¬æ—¥', 'ãƒ¬ãƒ¼ã‚¹ç•ªå·'])['é¦¬é€£ã‚ªãƒƒã‚º'].first()).sum() / race_count

    # ãƒ¯ã‚¤ãƒ‰çš„ä¸­ç‡ãƒ»å›åç‡ã‚‚è¨ˆç®—ï¼ˆçœç•¥ã—ã¦ç°¡ç•¥åŒ–ï¼‰
    wide_hitrate = 0  # è¨ˆç®—ãŒè¤‡é›‘ãªã®ã§çœç•¥
    wide_recoveryrate = 0

    # é¦¬å˜ã®çš„ä¸­ç‡ã¨å›åç‡
    umatan_hit = output_df.groupby(['é–‹å‚¬å¹´', 'é–‹å‚¬æ—¥', 'ãƒ¬ãƒ¼ã‚¹ç•ªå·']).apply(
        lambda x: list(x.sort_values('äºˆæ¸¬ã‚¹ã‚³ã‚¢', ascending=False).head(2)['ç¢ºå®šç€é †'].values) == [1, 2]
    )
    umatan_hitrate = 100 * umatan_hit.sum() / race_count
    
    umatan_odds_sum = 0
    for name, race_group in output_df.groupby(['é–‹å‚¬å¹´', 'é–‹å‚¬æ—¥', 'ãƒ¬ãƒ¼ã‚¹ç•ªå·']):
        top_horses = race_group.sort_values('äºˆæ¸¬ã‚¹ã‚³ã‚¢', ascending=False).head(2)
        if list(top_horses['ç¢ºå®šç€é †'].values) == [1, 2]:
            umatan_odds_sum += race_group['é¦¬å˜ã‚ªãƒƒã‚º'].iloc[0]

    umatan_recoveryrate = 100 * umatan_odds_sum / race_count

    # ä¸‰é€£è¤‡ã®çš„ä¸­ç‡ã¨å›åç‡
    sanrenpuku_hit = output_df.groupby(['é–‹å‚¬å¹´', 'é–‹å‚¬æ—¥', 'ãƒ¬ãƒ¼ã‚¹ç•ªå·']).apply(
        lambda x: set([1, 2, 3]).issubset(set(x.sort_values('äºˆæ¸¬ã‚¹ã‚³ã‚¢', ascending=False).head(3)['ç¢ºå®šç€é †'].values))
    )
    sanrenpuku_hitrate = 100 * sanrenpuku_hit.sum() / len(sanrenpuku_hit)
    sanrenpuku_recoveryrate = 100 * (sanrenpuku_hit * output_df.groupby(['é–‹å‚¬å¹´', 'é–‹å‚¬æ—¥', 'ãƒ¬ãƒ¼ã‚¹ç•ªå·'])['ï¼“é€£è¤‡ã‚ªãƒƒã‚º'].first()).sum() / len(sanrenpuku_hit)

    # çµæœã‚’ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«ã¾ã¨ã‚ã‚‹
    summary_df = pd.DataFrame({
        'çš„ä¸­æ•°': [tansho_hit.sum(), fukusho_hit.sum(), umaren_hit.sum(), 0, umatan_hit.sum(), sanrenpuku_hit.sum()],
        'çš„ä¸­ç‡(%)': [tansho_hitrate, fukusho_hitrate, umaren_hitrate, wide_hitrate, umatan_hitrate, sanrenpuku_hitrate],
        'å›åç‡(%)': [tansho_recoveryrate, fukusho_recoveryrate, umaren_recoveryrate, wide_recoveryrate, umatan_recoveryrate, sanrenpuku_recoveryrate]
    }, index=['å˜å‹', 'è¤‡å‹', 'é¦¬é€£', 'ãƒ¯ã‚¤ãƒ‰', 'é¦¬å˜', 'ï¼“é€£è¤‡'])

    return output_df, summary_df, race_count


def test_multiple_models(test_year_start=2023, test_year_end=2023):
    """
    è¤‡æ•°ã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ†ã‚¹ãƒˆã—ã¦çµæœã‚’æ¯”è¼ƒã™ã‚‹é–¢æ•°(è¨­å®šã¯JSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿)
    
    Args:
        test_year_start (int): ãƒ†ã‚¹ãƒˆå¯¾è±¡é–‹å§‹å¹´ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 2023)
        test_year_end (int): ãƒ†ã‚¹ãƒˆå¯¾è±¡çµ‚äº†å¹´ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 2023)
    """
    
    # JSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å…¨ãƒ¢ãƒ‡ãƒ«è¨­å®šã‚’èª­ã¿è¾¼ã¿
    try:
        model_configs = get_all_models()
    except Exception as e:
        print(f"âŒ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return
    
    if not model_configs:
        print("âš ï¸  ãƒ†ã‚¹ãƒˆå¯¾è±¡ã®ãƒ¢ãƒ‡ãƒ«è¨­å®šãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        return
    
    print("ğŸ‡ è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆã‚’é–‹å§‹ã—ã¾ã™ï¼")
    print("=" * 60)
    
    all_results = {}
    # çµ±åˆãƒ•ã‚¡ã‚¤ãƒ«ã®åˆå›æ›¸ãè¾¼ã¿ãƒ•ãƒ©ã‚°
    first_unified_write = True
    
    for i, config in enumerate(model_configs, 1):
        model_filename = config['model_filename']
        description = config.get('description', f"ãƒ¢ãƒ‡ãƒ«{i}")
        
        print(f"\nã€{i}/{len(model_configs)}ã€‘ {description} ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ†ã‚¹ãƒˆä¸­...")
        print(f"ğŸ“ ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«: {model_filename}")
        
        # ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèªï¼ˆmodelsãƒ•ã‚©ãƒ«ãƒ€ã‚‚ç¢ºèªï¼‰
        model_path = model_filename
        if not os.path.exists(model_path):
            models_path = f"models/{model_filename}"
            if os.path.exists(models_path):
                model_path = models_path
                print(f"ğŸ“‚ modelsãƒ•ã‚©ãƒ«ãƒ€å†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨: {models_path}")
            else:
                print(f"âš ï¸  ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ« {model_filename} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                print(f"    ç¢ºèªå ´æ‰€: ./{model_filename}, ./models/{model_filename}")
                continue
        
        try:
            output_df, summary_df, race_count = predict_with_model(
                model_filename=model_path,  # å­˜åœ¨ç¢ºèªæ¸ˆã¿ã®ãƒ‘ã‚¹ã‚’ä½¿ç”¨
                track_code=config['track_code'],
                kyoso_shubetsu_code=config['kyoso_shubetsu_code'],
                surface_type=config['surface_type'],
                min_distance=config['min_distance'],
                max_distance=config['max_distance'],
                test_year_start=test_year_start,
                test_year_end=test_year_end
            )
            
            if output_df is not None:
                # çµæœã‚’ä¿å­˜ï¼ˆè¿½è¨˜ãƒ¢ãƒ¼ãƒ‰ï¼‰
                base_filename = model_filename.replace('.sav', '').replace('models/', '')
                individual_output_file = f"predicted_results_{base_filename}.tsv"
                summary_file = f"betting_summary_{base_filename}.tsv"
                
                # å€‹åˆ¥ãƒ¢ãƒ‡ãƒ«çµæœã‚’è¿½è¨˜ä¿å­˜
                save_results_with_append(output_df, individual_output_file, append_mode=True)
                
                # å…¨ãƒ¢ãƒ‡ãƒ«çµ±åˆãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ï¼ˆåˆå›ã¯ä¸Šæ›¸ãã€ä»¥é™ã¯è¿½è¨˜ï¼‰
                unified_output_file = "predicted_results.tsv"
                save_results_with_append(output_df, unified_output_file, append_mode=not first_unified_write)
                first_unified_write = False  # åˆå›æ›¸ãè¾¼ã¿å®Œäº†
                
                # ã‚µãƒãƒªãƒ¼ã¯å€‹åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
                results_dir = Path('results')
                results_dir.mkdir(exist_ok=True)
                summary_filepath = results_dir / summary_file
                summary_df.to_csv(summary_filepath, index=True, sep='\t', encoding='utf-8-sig')
                
                print(f"âœ… å®Œäº†ï¼ãƒ¬ãƒ¼ã‚¹æ•°: {race_count}")
                print(f"  - å€‹åˆ¥çµæœ: {individual_output_file}")
                print(f"  - çµ±åˆçµæœ: {unified_output_file}")
                print(f"  - ã‚µãƒãƒªãƒ¼: {summary_file}")
                
                # çµæœã‚’ä¿å­˜ï¼ˆå¾Œã§æ¯”è¼ƒç”¨ï¼‰
                all_results[description] = {
                    'summary': summary_df,
                    'race_count': race_count,
                    'model_filename': model_filename
                }
                
                # ä¸»è¦ãªçµæœã‚’è¡¨ç¤º
                print(f"  - å˜å‹çš„ä¸­ç‡: {summary_df.loc['å˜å‹', 'çš„ä¸­ç‡(%)']:.2f}%")
                print(f"  - å˜å‹å›åç‡: {summary_df.loc['å˜å‹', 'å›åç‡(%)']:.2f}%")
                print(f"  - è¤‡å‹çš„ä¸­ç‡: {summary_df.loc['è¤‡å‹', 'çš„ä¸­ç‡(%)']:.2f}%")
                print(f"  - è¤‡å‹å›åç‡: {summary_df.loc['è¤‡å‹', 'å›åç‡(%)']:.2f}%")
                
            else:
                print(f"âŒ ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                
        except Exception as e:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            import traceback
            traceback.print_exc()
        
        print("-" * 60)
    
    # è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒçµæœã‚’ä½œæˆ
    if len(all_results) > 1:
        print("\nğŸ“Š ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒçµæœ")
        print("=" * 60)
        
        comparison_data = []
        for description, result in all_results.items():
            summary = result['summary']
            comparison_data.append({
                'ãƒ¢ãƒ‡ãƒ«': description,
                'ãƒ¬ãƒ¼ã‚¹æ•°': result['race_count'],
                'å˜å‹çš„ä¸­ç‡': f"{summary.loc['å˜å‹', 'çš„ä¸­ç‡(%)']:.2f}%",
                'å˜å‹å›åç‡': f"{summary.loc['å˜å‹', 'å›åç‡(%)']:.2f}%",
                'è¤‡å‹çš„ä¸­ç‡': f"{summary.loc['è¤‡å‹', 'çš„ä¸­ç‡(%)']:.2f}%",
                'è¤‡å‹å›åç‡': f"{summary.loc['è¤‡å‹', 'å›åç‡(%)']:.2f}%",
                'ä¸‰é€£è¤‡çš„ä¸­ç‡': f"{summary.loc['ï¼“é€£è¤‡', 'çš„ä¸­ç‡(%)']:.2f}%",
                'ä¸‰é€£è¤‡å›åç‡': f"{summary.loc['ï¼“é€£è¤‡', 'å›åç‡(%)']:.2f}%"
            })
        
        comparison_df = pd.DataFrame(comparison_data)
        
        # æ¯”è¼ƒçµæœã‚’ä¿å­˜
        comparison_file = 'model_comparison.tsv'
        results_dir = Path('results')
        results_dir.mkdir(exist_ok=True)
        comparison_filepath = results_dir / comparison_file
        
        comparison_df.to_csv(comparison_filepath, index=False, sep='\t', encoding='utf-8-sig')
        
        print(comparison_df.to_string(index=False))
        print(f"\nğŸ“‹ æ¯”è¼ƒçµæœã‚’ {comparison_filepath} ã«ä¿å­˜ã—ã¾ã—ãŸï¼")
    
    print("\nğŸ ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆãŒå®Œäº†ã—ã¾ã—ãŸï¼")


def predict_and_save_results():
    """
    æ—§ãƒãƒ¼ã‚¸ãƒ§ãƒ³äº’æ›æ€§ã®ãŸã‚ã®é–¢æ•°
    é˜ªç¥ç«¶é¦¬å ´ã®ï¼“æ­³ä»¥ä¸ŠèŠä¸­é•·è·é›¢ãƒ¢ãƒ‡ãƒ«ã§ãƒ†ã‚¹ãƒˆ
    """
    output_df, summary_df, race_count = predict_with_model(
        model_filename='hanshin_shiba_3ageup_model.sav',
        track_code='09',  # é˜ªç¥
        kyoso_shubetsu_code='13',  # 3æ­³ä»¥ä¸Š
        surface_type='turf',  # èŠ
        min_distance=1700,  # ä¸­é•·è·é›¢
        max_distance=9999  # ä¸Šé™ãªã—
    )
    
    if output_df is not None:
        # resultsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        results_dir = Path('results')
        results_dir.mkdir(exist_ok=True)
        
        # çµæœã‚’TSVã«ä¿å­˜ï¼ˆè¿½è¨˜ãƒ¢ãƒ¼ãƒ‰ï¼‰
        output_file = 'predicted_results.tsv'
        save_results_with_append(output_df, output_file, append_mode=True)
        print(f"äºˆæ¸¬çµæœã‚’ results/{output_file} ã«ä¿å­˜ã—ã¾ã—ãŸï¼")

        # çš„ä¸­ç‡ã¨å›åç‡ã‚’åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        summary_file = 'betting_summary.tsv'
        summary_filepath = results_dir / summary_file
        summary_df.to_csv(summary_filepath, index=True, sep='\t', encoding='utf-8-sig')
        print(f"çš„ä¸­ç‡ãƒ»å›åç‡ãƒ»çš„ä¸­æ•°ã‚’ results/{summary_file} ã«ä¿å­˜ã—ã¾ã—ãŸï¼")


if __name__ == '__main__':
    # å®Ÿè¡Œæ–¹æ³•ã‚’é¸æŠã§ãã‚‹ã‚ˆã†ã«
    import sys
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒ†ã‚¹ãƒˆå¹´ç¯„å›²
    test_year_start = 2023
    test_year_end = 2023
    
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã‚’è§£æ
    mode = 'single'  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯å˜ä¸€ãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆ
    
    for arg in sys.argv[1:]:
        if arg == 'multi':
            mode = 'multi'
        elif '-' in arg and arg[0].isdigit():
            # "2020-2023" å½¢å¼ã®å¹´ç¯„å›²æŒ‡å®š
            try:
                years = arg.split('-')
                if len(years) == 2:
                    test_year_start = int(years[0])
                    test_year_end = int(years[1])
                    print(f"ğŸ“… ãƒ†ã‚¹ãƒˆå¹´ç¯„å›²æŒ‡å®š: {test_year_start}å¹´~{test_year_end}å¹´")
            except ValueError:
                print(f"âš ï¸  ç„¡åŠ¹ãªå¹´ç¯„å›²ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ: {arg} (ä¾‹: 2020-2023)")
        elif arg.isdigit() and len(arg) == 4:
            # "2023" å½¢å¼ã®å˜ä¸€å¹´æŒ‡å®š
            test_year_start = test_year_end = int(arg)
            print(f"ğŸ“… ãƒ†ã‚¹ãƒˆå¹´æŒ‡å®š: {test_year_start}å¹´")
    
    if mode == 'multi':
        # python universal_test.py multi [å¹´ç¯„å›²]
        test_multiple_models(test_year_start=test_year_start, test_year_end=test_year_end)
    else:
        # python universal_test.py [å¹´ç¯„å›²] (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ)
        # å˜ä¸€ãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆã§å¹´ç¯„å›²ã‚’ä½¿ç”¨
        output_df, summary_df, race_count = predict_with_model(
            model_filename='hanshin_shiba_3ageup_model.sav',
            track_code='09',  # é˜ªç¥
            kyoso_shubetsu_code='13',  # 3æ­³ä»¥ä¸Š
            surface_type='turf',  # èŠ
            min_distance=1700,  # ä¸­é•·è·é›¢
            max_distance=9999,  # ä¸Šé™ãªã—
            test_year_start=test_year_start,
            test_year_end=test_year_end
        )
        
        if output_df is not None:
            # resultsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
            results_dir = Path('results')
            results_dir.mkdir(exist_ok=True)
            
            # çµæœã‚’TSVã«ä¿å­˜ï¼ˆè¿½è¨˜ãƒ¢ãƒ¼ãƒ‰ï¼‰
            output_file = 'predicted_results.tsv'
            save_results_with_append(output_df, output_file, append_mode=True)
            print(f"äºˆæ¸¬çµæœã‚’ results/{output_file} ã«ä¿å­˜ã—ã¾ã—ãŸ!")

            # çš„ä¸­ç‡ã¨å›åç‡ã‚’åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            summary_file = 'betting_summary.tsv'
            summary_filepath = results_dir / summary_file
            summary_df.to_csv(summary_filepath, index=True, sep='\t', encoding='utf-8-sig')
            print(f"çš„ä¸­ç‡ãƒ»å›åç‡ãƒ»çš„ä¸­æ•°ã‚’ results/{summary_file} ã«ä¿å­˜ã—ã¾ã—ãŸ!")