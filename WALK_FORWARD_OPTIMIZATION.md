# Walk-Forwardæ¤œè¨¼ åŠ¹ç‡åŒ–ãƒ—ãƒ©ãƒ³

## ğŸ“Š ç¾çŠ¶ã®å•é¡Œåˆ†æ

### ç¾åœ¨ã®å‡¦ç†æ™‚é–“
**å˜ä¸€æœŸé–“ãƒ¢ãƒ¼ãƒ‰ï¼ˆ10ãƒ¢ãƒ‡ãƒ«ã€1å¹´ãƒ†ã‚¹ãƒˆï¼‰**: **ç´„12-19æ™‚é–“/è©¦è¡Œ**

- ãƒ¢ãƒ‡ãƒ«ä½œæˆ: 10ãƒ¢ãƒ‡ãƒ« Ã— (30åˆ† + 40-80åˆ†UPSET) = **11.6-18.3æ™‚é–“**
- ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ: 10ãƒ¢ãƒ‡ãƒ« Ã— 5åˆ† = **50åˆ†**

## âœ… å®Ÿè£…æ¸ˆã¿æœ€é©åŒ–

### Phase 1: UPSETåˆ†é¡å™¨å…±é€šåŒ–ï¼ˆå®Œäº†ï¼‰âœ…

**å„ªå…ˆåº¦**: â­â­â­â­â­  
**é›£æ˜“åº¦**: ä½ï¼ˆ1-2æ™‚é–“ï¼‰  
**æœŸå¾…åŠ¹æœ**: **50-70%å‰Šæ¸›** (12-19h â†’ 5.6-6.3h)  
**å®Ÿè£…æ—¥**: 2025-01-XX  
**å®Ÿè£…çŠ¶æ…‹**: âœ… å®Œäº†

#### å®Ÿè£…å†…å®¹
- `walk_forward_validation.py` 826-860è¡ŒãŠã‚ˆã³995-1030è¡Œ:
  - `run_single_period_mode()`ã¨`run_compare_periods_mode()`ã§UPSETåˆ†é¡å™¨ã‚’ç‹¬ç«‹ãƒã‚§ãƒƒã‚¯
  - å…¨ãƒ¢ãƒ‡ãƒ«ãƒ«ãƒ¼ãƒ—å‰ã«UPSETåˆ†é¡å™¨ã‚’1å›ã ã‘ä½œæˆ
  - progress.jsonã«è¨˜éŒ²ã—ã¦ã‚¹ã‚­ãƒƒãƒ—åˆ¶å¾¡
- Universal Rankerã‚‚è¨˜éŒ² (`universal_ranker_{train_start}-{train_end}`)
- 541-615è¡Œ: `_create_upset_classifier()`ãƒã‚°ä¿®æ­£
  - Universal Rankerå­˜åœ¨æ™‚ã«UPSETæœªå­˜åœ¨ãªã‚‰ä½œæˆç¶šè¡Œ
  - `universal_config`ã®UnboundLocalErrorä¿®æ­£

**åŠ¹æœ**: UPSETåˆ†é¡å™¨ä½œæˆ 40-80åˆ† Ã— (ãƒ¢ãƒ‡ãƒ«æ•°-1) ã®å‰Šæ¸›

---

### Phase 2: ãƒ¢ãƒ‡ãƒ«ä½œæˆä¸¦åˆ—åŒ–ï¼ˆå®Œäº†ï¼‰âœ…

**å„ªå…ˆåº¦**: â­â­â­â­  
**é›£æ˜“åº¦**: ä¸­ï¼ˆ3-5æ™‚é–“ï¼‰  
**æœŸå¾…åŠ¹æœ**: **è¿½åŠ ã§60-75%å‰Šæ¸›** (5.6-6.3h â†’ 2.1-2.6h)  
**å®Ÿè£…æ—¥**: 2025-01-XX  
**å®Ÿè£…çŠ¶æ…‹**: âœ… å®Œäº†

#### å®Ÿè£…å†…å®¹
- `walk_forward_validation.py`:
  - 1-30è¡Œ: multiprocessing, threading, ProcessPoolExecutorè¿½åŠ 
  - 58è¡Œ: progress.jsonæ’ä»–åˆ¶å¾¡ç”¨`threading.Lock`è¿½åŠ 
  - 214-217è¡Œ: `_save_progress()`ã«ãƒ­ãƒƒã‚¯æ©Ÿæ§‹è¿½åŠ 
  - 451-527è¡Œ: `_create_model_worker()`é™çš„ãƒ¡ã‚½ãƒƒãƒ‰ä½œæˆ
    - å„ãƒ—ãƒ­ã‚»ã‚¹ã§ç‹¬ç«‹ã—ãŸDBæ¥ç¶šã¨ãƒ­ã‚¬ãƒ¼
    - ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«åç”Ÿæˆã¨create_universal_modelå‘¼ã³å‡ºã—
  - 912-971è¡Œ: `run_single_period_mode()`ãƒ¢ãƒ‡ãƒ«ä½œæˆãƒ•ã‚§ãƒ¼ã‚ºä¸¦åˆ—åŒ–
    - max_workers=4ã§ProcessPoolExecutorä½¿ç”¨
    - as_completed()ã§å®Œäº†é †ã«çµæœå–å¾—
    - progress.jsonæ’ä»–ãƒ­ãƒƒã‚¯ä»˜ãè¨˜éŒ²
  - 1185-1244è¡Œ: `run_compare_periods_mode()`ã‚‚åŒæ§˜ã«ä¸¦åˆ—åŒ–

**åŠ¹æœ**: 
- 4ä¸¦åˆ—å®Ÿè¡Œã§ãƒ¢ãƒ‡ãƒ«ä½œæˆã‚’4å€é«˜é€ŸåŒ–
- ãƒ¡ãƒ¢ãƒªä½¿ç”¨: ~4GB Ã— 4 = 16GB (ãƒ”ãƒ¼ã‚¯)
- DBæ¥ç¶šã¯ãƒ—ãƒ­ã‚»ã‚¹ã”ã¨ã«ç‹¬ç«‹

---

## ğŸš€ æ®‹ã‚Šã®åŠ¹ç‡åŒ–ãƒ—ãƒ©ãƒ³ï¼ˆPhase 3-5ï¼‰
                test_year,
                training_years,
                period,
                False  # create_upset_classifier=False
            ): model_name
            for model_name in target_models
        }
        
        for future in as_completed(futures):
            model_name = futures[future]
            try:
                success, model_path = future.result()
                if success:
                    self.log(f"âœ… {model_name} å®Œäº†")
                else:
                    self.log(f"âŒ {model_name} å¤±æ•—")
            except Exception as e:
                self.log(f"âŒ {model_name} ã‚¨ãƒ©ãƒ¼: {e}")

def _create_single_model(self, model_name, test_year, training_years, period, create_upset):
    """å˜ä¸€ãƒ¢ãƒ‡ãƒ«ä½œæˆï¼ˆä¸¦åˆ—å®Ÿè¡Œç”¨ï¼‰"""
    # DBæ¥ç¶šã¯ãƒ—ãƒ­ã‚»ã‚¹ã”ã¨ã«ç‹¬ç«‹ã•ã›ã‚‹
    return self.create_model_for_year(
        model_name=model_name,
        test_year=test_year,
        training_years=training_years,
        period=period,
        create_upset_classifier=create_upset
    )
```

**æ³¨æ„ç‚¹**:
- `progress.json` æ›´æ–°æ™‚ã®æ’ä»–åˆ¶å¾¡ãŒå¿…è¦ï¼ˆ`threading.Lock` ã¾ãŸã¯ `fasteners` ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ­ãƒƒã‚¯ï¼‰
- DBæ¥ç¶šã¯å„ãƒ—ãƒ­ã‚»ã‚¹ã§ç‹¬ç«‹ã—ã¦ç¢ºç«‹
- ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã«æ³¨æ„ï¼ˆ4ä¸¦åˆ— Ã— 1ãƒ¢ãƒ‡ãƒ«åˆ†ã®ãƒ¡ãƒ¢ãƒªï¼‰

---

### Phase 3: DBã‚¯ã‚¨ãƒªæœ€é©åŒ–ï¼ˆä¸­æœŸæ”¹å–„ï¼‰

**å„ªå…ˆåº¦**: â­â­â­  
**é›£æ˜“åº¦**: é«˜ï¼ˆ8-12æ™‚é–“ï¼‰  
**æœŸå¾…åŠ¹æœ**: **è¿½åŠ ã§30-50%å‰Šæ¸›** (2.1-2.6h â†’ 1.3-1.6h)

#### å®Ÿè£…å†…å®¹

**ãƒ•ã‚¡ã‚¤ãƒ«**: `db_query_builder.py`  
**å¯¾è±¡é–¢æ•°**: `build_race_data_query()` (129-320è¡Œ)

#### 3-1. ã‚µãƒ–ã‚¯ã‚¨ãƒªã‚’CTEã«å¤‰æ›

**ç¾åœ¨ã®ã‚³ãƒ¼ãƒ‰**ï¼ˆ2æ®µéšãƒã‚¹ãƒˆï¼‰:
```sql
SELECT 
    base_features.*,
    (base_features.past_score_mean - AVG(base_features.past_score_mean) OVER race_window) 
        / NULLIF(STDDEV(base_features.past_score_mean) OVER race_window, 0) 
        AS relative_ability
FROM (
    -- å†…å´ã‚¯ã‚¨ãƒª: base_features
    SELECT ...
    FROM jvd_sed_uma
    ...
) base_features
```

**æ”¹å–„å¾Œã®ã‚³ãƒ¼ãƒ‰**ï¼ˆCTEä½¿ç”¨ï¼‰:
```sql
WITH base_features AS (
    SELECT 
        uma.*,
        AVG(score) OVER (PARTITION BY ketto_toroku_bango ...) AS past_score_mean,
        ...
    FROM jvd_sed_uma uma
    WHERE ...
),
race_stats AS (
    SELECT 
        kaisai_nen, kaisai_tsukihi, keibajo_code, race_bango,
        AVG(past_score_mean) AS avg_past_score,
        STDDEV(past_score_mean) AS std_past_score
    FROM base_features
    GROUP BY kaisai_nen, kaisai_tsukihi, keibajo_code, race_bango
)
SELECT 
    bf.*,
    (bf.past_score_mean - rs.avg_past_score) 
        / NULLIF(rs.std_past_score, 0) AS relative_ability
FROM base_features bf
LEFT JOIN race_stats rs
    ON bf.kaisai_nen = rs.kaisai_nen
    AND bf.kaisai_tsukihi = rs.kaisai_tsukihi
    AND bf.keibajo_code = rs.keibajo_code
    AND bf.race_bango = rs.race_bango
```

**æœŸå¾…åŠ¹æœ**: ã‚¯ã‚¨ãƒªãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ãŒCTEã‚’æœ€é©åŒ–ã—ã‚„ã™ãã€å®Ÿè¡Œæ™‚é–“20-40%å‰Šæ¸›

---

#### 3-2. ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è¿½åŠ 

**å®Ÿè£…**: PostgreSQLå´ã§å®Ÿè¡Œ

```sql
-- é¦¬ã®éå»ãƒ¬ãƒ¼ã‚¹æ¤œç´¢ç”¨
CREATE INDEX IF NOT EXISTS idx_uma_ketto_kaisai 
    ON jvd_sed_uma (ketto_toroku_bango, kaisai_nen, kaisai_tsukihi);

-- é¨æ‰‹ã®éå»æˆç¸¾æ¤œç´¢ç”¨
CREATE INDEX IF NOT EXISTS idx_uma_kishu_kaisai
    ON jvd_sed_uma (kishu_code, kaisai_nen, kaisai_tsukihi);

-- èª¿æ•™å¸«ã®éå»æˆç¸¾æ¤œç´¢ç”¨
CREATE INDEX IF NOT EXISTS idx_uma_chokyoshi_kaisai
    ON jvd_sed_uma (chokyoshi_code, kaisai_nen, kaisai_tsukihi);

-- ãƒ¬ãƒ¼ã‚¹æƒ…å ±æ¤œç´¢ç”¨
CREATE INDEX IF NOT EXISTS idx_uma_race
    ON jvd_sed_uma (kaisai_nen, kaisai_tsukihi, keibajo_code, race_bango);

-- ç€é †æ¤œç´¢ç”¨ï¼ˆé›†è¨ˆã«ä½¿ç”¨ï¼‰
CREATE INDEX IF NOT EXISTS idx_uma_chakujun
    ON jvd_sed_uma (kakutei_chakujun);
```

**æœŸå¾…åŠ¹æœ**: ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦é–¢æ•°ã®å®Ÿè¡Œé€Ÿåº¦30-50%å‘ä¸Š

**ç¢ºèªæ–¹æ³•**:
```sql
-- æ—¢å­˜ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç¢ºèª
SELECT indexname, indexdef 
FROM pg_indexes 
WHERE tablename = 'jvd_sed_uma';

-- ã‚¯ã‚¨ãƒªãƒ—ãƒ©ãƒ³ç¢ºèª
EXPLAIN ANALYZE <your query>;
```

---

#### 3-3. ãƒãƒ†ãƒªã‚¢ãƒ©ã‚¤ã‚ºãƒ‰ãƒ“ãƒ¥ãƒ¼ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

**å¯¾è±¡**: é »ç¹ã«å‚ç…§ã•ã‚Œã‚‹é›†è¨ˆãƒ‡ãƒ¼ã‚¿

```sql
-- éå»ãƒ¬ãƒ¼ã‚¹ã‚¹ã‚³ã‚¢ã®äº‹å‰è¨ˆç®—
CREATE MATERIALIZED VIEW past_score_cache AS
SELECT 
    ketto_toroku_bango,
    kaisai_nen,
    kaisai_tsukihi,
    keibajo_code,
    race_bango,
    AVG(score) OVER (
        PARTITION BY ketto_toroku_bango 
        ORDER BY kaisai_nen, kaisai_tsukihi 
        ROWS BETWEEN 3 PRECEDING AND 1 PRECEDING
    ) AS past_score_mean,
    STDDEV(score) OVER (
        PARTITION BY ketto_toroku_bango 
        ORDER BY kaisai_nen, kaisai_tsukihi 
        ROWS BETWEEN 3 PRECEDING AND 1 PRECEDING
    ) AS past_score_std
FROM jvd_sed_uma;

-- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è¿½åŠ 
CREATE INDEX idx_past_score_cache_uma ON past_score_cache (ketto_toroku_bango, kaisai_nen, kaisai_tsukihi);

-- å®šæœŸæ›´æ–°ï¼ˆæ—¥æ¬¡ãƒãƒƒãƒãªã©ï¼‰
REFRESH MATERIALIZED VIEW past_score_cache;
```

**ã‚¯ã‚¨ãƒªã§ã®ä½¿ç”¨**:
```sql
-- db_query_builder.py ã§ past_score_cache ã‚’ JOIN
SELECT 
    uma.*,
    psc.past_score_mean,
    psc.past_score_std,
    ...
FROM jvd_sed_uma uma
LEFT JOIN past_score_cache psc
    ON uma.ketto_toroku_bango = psc.ketto_toroku_bango
    AND uma.kaisai_nen = psc.kaisai_nen
    AND uma.kaisai_tsukihi = psc.kaisai_tsukihi
    AND uma.keibajo_code = psc.keibajo_code
    AND uma.race_bango = psc.race_bango
```

**æœŸå¾…åŠ¹æœ**: ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦é–¢æ•°ã®è¨ˆç®—ä¸è¦ â†’ 50-70%é«˜é€ŸåŒ–

**æ³¨æ„ç‚¹**:
- ãƒ‡ãƒ¼ã‚¿æ›´æ–°æ™‚ã« `REFRESH MATERIALIZED VIEW` ãŒå¿…è¦
- ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸å®¹é‡å¢—åŠ 
- walk-forward validation ã§ã¯éå»ãƒ‡ãƒ¼ã‚¿ã®ã¿ä½¿ç”¨ã™ã‚‹ãŸã‚ã€äº‹å‰è¨ˆç®—ã¨ç›¸æ€§è‰¯ã„

---

### Phase 4: ç‰¹å¾´é‡ã‚­ãƒ£ãƒƒã‚·ãƒ¥å°å…¥ï¼ˆ2å›ç›®ä»¥é™é«˜é€ŸåŒ–ï¼‰

**å„ªå…ˆåº¦**: â­â­  
**é›£æ˜“åº¦**: ä¸­ï¼ˆ4-6æ™‚é–“ï¼‰  
**æœŸå¾…åŠ¹æœ**: **2å›ç›®ä»¥é™80-90%å‰Šæ¸›** (1.3-1.6h â†’ 10-20m)

#### å®Ÿè£…å†…å®¹

**æ–°è¦ãƒ•ã‚¡ã‚¤ãƒ«**: `feature_cache.py`

```python
"""
ç‰¹å¾´é‡ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°æ©Ÿæ§‹

ç‰¹å¾´é‡è¨ˆç®—çµæœã‚’Parquetå½¢å¼ã§ãƒ‡ã‚£ã‚¹ã‚¯ã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã€
2å›ç›®ä»¥é™ã®å®Ÿè¡Œã‚’é«˜é€ŸåŒ–ã™ã‚‹ã€‚
"""

import hashlib
import json
from pathlib import Path
import pandas as pd


class FeatureCache:
    """ç‰¹å¾´é‡ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼"""
    
    def __init__(self, cache_dir='feature_cache'):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        self.version = self._compute_code_version()
    
    def _compute_code_version(self):
        """ã‚³ãƒ¼ãƒ‰ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ãƒãƒƒã‚·ãƒ¥ã§è¨ˆç®—"""
        # db_query_builder.py ã¨ feature_engineering.py ã®å†…å®¹ã‹ã‚‰ãƒãƒƒã‚·ãƒ¥ç”Ÿæˆ
        files_to_hash = [
            'db_query_builder.py',
            'feature_engineering.py'
        ]
        
        hasher = hashlib.md5()
        for file_path in files_to_hash:
            if Path(file_path).exists():
                with open(file_path, 'rb') as f:
                    hasher.update(f.read())
        
        return hasher.hexdigest()[:8]
    
    def get_cache_key(self, year, track_code, surface_type):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ã‚’ç”Ÿæˆ"""
        return f"{self.version}_{year}_{track_code}_{surface_type}"
    
    def get_cache_path(self, cache_key):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’å–å¾—"""
        return self.cache_dir / f"{cache_key}.parquet"
    
    def exists(self, year, track_code, surface_type):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª"""
        cache_key = self.get_cache_key(year, track_code, surface_type)
        cache_path = self.get_cache_path(cache_key)
        return cache_path.exists()
    
    def load(self, year, track_code, surface_type):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰èª­ã¿è¾¼ã¿"""
        cache_key = self.get_cache_key(year, track_code, surface_type)
        cache_path = self.get_cache_path(cache_key)
        
        if not cache_path.exists():
            return None
        
        try:
            df = pd.read_parquet(cache_path)
            print(f"âœ… ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆ: {cache_key}")
            return df
        except Exception as e:
            print(f"âš ï¸ ã‚­ãƒ£ãƒƒã‚·ãƒ¥èª­ã¿è¾¼ã¿å¤±æ•—: {e}")
            return None
    
    def save(self, df, year, track_code, surface_type):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜"""
        cache_key = self.get_cache_key(year, track_code, surface_type)
        cache_path = self.get_cache_path(cache_key)
        
        try:
            df.to_parquet(cache_path, compression='snappy')
            print(f"ğŸ’¾ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜: {cache_key}")
        except Exception as e:
            print(f"âš ï¸ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜å¤±æ•—: {e}")
    
    def clear_old_versions(self):
        """å¤ã„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å‰Šé™¤"""
        current_prefix = f"{self.version}_"
        
        deleted_count = 0
        for cache_file in self.cache_dir.glob("*.parquet"):
            if not cache_file.name.startswith(current_prefix):
                cache_file.unlink()
                deleted_count += 1
        
        if deleted_count > 0:
            print(f"ğŸ—‘ï¸  å¤ã„ã‚­ãƒ£ãƒƒã‚·ãƒ¥å‰Šé™¤: {deleted_count}ãƒ•ã‚¡ã‚¤ãƒ«")


def get_data_with_features_cached(year, track_code, surface_type, compute_fn):
    """
    ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ãã§ãƒ‡ãƒ¼ã‚¿+ç‰¹å¾´é‡ã‚’å–å¾—
    
    Args:
        year: å¹´
        track_code: ç«¶é¦¬å ´ã‚³ãƒ¼ãƒ‰
        surface_type: è·¯é¢ç¨®åˆ¥
        compute_fn: è¨ˆç®—é–¢æ•°ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹æ™‚ã«å®Ÿè¡Œï¼‰
    
    Returns:
        DataFrame (ç‰¹å¾´é‡ä»˜ã)
    """
    cache = FeatureCache()
    
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
    df = cache.load(year, track_code, surface_type)
    if df is not None:
        return df
    
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹ â†’ è¨ˆç®—
    print(f"â³ ç‰¹å¾´é‡è¨ˆç®—ä¸­: {year}å¹´ ç«¶é¦¬å ´{track_code} {surface_type}")
    df = compute_fn()
    
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜
    cache.save(df, year, track_code, surface_type)
    
    return df
```

#### çµ±åˆæ–¹æ³•

**ãƒ•ã‚¡ã‚¤ãƒ«**: `model_creator.py`

```python
from feature_cache import get_data_with_features_cached

def create_model(track_code, year_start, year_end, ...):
    """ãƒ¢ãƒ‡ãƒ«ä½œæˆï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥å¯¾å¿œç‰ˆï¼‰"""
    
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ãã§ãƒ‡ãƒ¼ã‚¿å–å¾—
    def compute_features():
        # æ—¢å­˜ã®ãƒ­ã‚¸ãƒƒã‚¯
        query = build_race_data_query(...)
        df = pd.read_sql_query(query, conn)
        df = preprocess_race_data(df)
        df = create_features(df)
        df = add_advanced_features(df, ...)
        return df
    
    df = get_data_with_features_cached(
        year=year_start,
        track_code=track_code,
        surface_type=surface_type,
        compute_fn=compute_features
    )
    
    # ãƒ¢ãƒ‡ãƒ«è¨“ç·´ï¼ˆä»¥é™ã¯æ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
    ...
```

**ãƒ•ã‚¡ã‚¤ãƒ«**: `universal_test.py`

åŒæ§˜ã®å¤‰æ›´ã‚’é©ç”¨

---

### Phase 5: ç«¶é¦¬å ´åˆ¥ä¸¦åˆ—åŒ–ï¼ˆUPSETåˆ†é¡å™¨ä½œæˆé«˜é€ŸåŒ–ï¼‰

**å„ªå…ˆåº¦**: â­â­  
**é›£æ˜“åº¦**: ä¸­ï¼ˆ2-3æ™‚é–“ï¼‰  
**æœŸå¾…åŠ¹æœ**: **UPSETä½œæˆ70-80%å‰Šæ¸›** (40-80åˆ† â†’ 4-8åˆ†)

#### å®Ÿè£…å†…å®¹

**ãƒ•ã‚¡ã‚¤ãƒ«**: `analyze_upset_patterns.py`  
**å¯¾è±¡é–¢æ•°**: `get_data_with_predictions()` (88-148è¡Œ)

**ç¾åœ¨ã®ã‚³ãƒ¼ãƒ‰**ï¼ˆã‚·ãƒªã‚¢ãƒ«å‡¦ç†ï¼‰:
```python
# analyze_upset_patterns.py 88-148è¡Œ
all_data = []

for year in years:
    for track_code in track_codes:
        for surface in surfaces:
            # 1ã¤ãšã¤é †æ¬¡å‡¦ç†
            df = get_single_track_data(...)
            all_data.append(df)

df = pd.concat(all_data, ignore_index=True)
```

**æ”¹å–„å¾Œã®ã‚³ãƒ¼ãƒ‰**ï¼ˆä¸¦åˆ—å‡¦ç†ï¼‰:
```python
from concurrent.futures import ProcessPoolExecutor, as_completed
import multiprocessing

def get_data_with_predictions(model_path, years, track_codes, surfaces, ...):
    """ç«¶é¦¬å ´åˆ¥ã«ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚’ä¸¦åˆ—åŒ–"""
    
    # ã‚¿ã‚¹ã‚¯ãƒªã‚¹ãƒˆä½œæˆ
    tasks = [
        (year, track_code, surface)
        for year in years
        for track_code in track_codes
        for surface in surfaces
    ]
    
    max_workers = min(10, multiprocessing.cpu_count())
    print(f"ğŸš€ ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸¦åˆ—åŒ–: {len(tasks)}ã‚¿ã‚¹ã‚¯ Ã— {max_workers}ä¸¦åˆ—")
    
    # ä¸¦åˆ—å®Ÿè¡Œ
    all_data = []
    with ProcessPoolExecutor(max_workers=max_workers) as executor:
        futures = {
            executor.submit(
                _get_single_track_data_worker,
                model_path, year, track_code, surface, ...
            ): (year, track_code, surface)
            for year, track_code, surface in tasks
        }
        
        for future in as_completed(futures):
            year, track_code, surface = futures[future]
            try:
                df = future.result()
                if df is not None and len(df) > 0:
                    all_data.append(df)
                    print(f"âœ… {year}å¹´ {track_code} {surface}: {len(df):,}é ­")
            except Exception as e:
                print(f"âŒ {year}å¹´ {track_code} {surface}: {e}")
    
    # çµåˆ
    if not all_data:
        return None
    
    df = pd.concat(all_data, ignore_index=True)
    print(f"âœ… ãƒ‡ãƒ¼ã‚¿çµåˆå®Œäº†: {len(df):,}é ­")
    
    return df


def _get_single_track_data_worker(model_path, year, track_code, surface, ...):
    """å˜ä¸€ç«¶é¦¬å ´ã®ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆãƒ¯ãƒ¼ã‚«ãƒ¼ãƒ—ãƒ­ã‚»ã‚¹ç”¨ï¼‰"""
    # DBæ¥ç¶šã¯ãƒ—ãƒ­ã‚»ã‚¹ã”ã¨ã«ç‹¬ç«‹
    conn = get_db_connection()
    
    try:
        query = build_race_data_query(
            track_code=track_code,
            year_start=year,
            year_end=year,
            surface_type=surface,
            ...
        )
        df = pd.read_sql_query(query, conn)
        
        # ç‰¹å¾´é‡è¨ˆç®—
        df = preprocess_race_data(df)
        df = create_features(df)
        df = add_advanced_features(df, ...)
        
        # äºˆæ¸¬
        model = load_model(model_path)
        df['predicted_score'] = model.predict(df[feature_cols])
        
        return df
    finally:
        conn.close()
```

---

## ğŸ“ˆ åŠ¹ç‡åŒ–åŠ¹æœã¾ã¨ã‚

| Phase | æ”¹å–„å†…å®¹ | é›£æ˜“åº¦ | æ™‚é–“å‰Šæ¸› | ç´¯è¨ˆå‰Šæ¸›ç‡ | å‡¦ç†æ™‚é–“ |
|-------|---------|--------|---------|-----------|---------|
| **ç¾çŠ¶** | - | - | - | - | **12-19h** |
| **Phase 1** | UPSETåˆ†é¡å™¨å…±é€šåŒ– | ä½ | 50-70% | 50-70% | **5.6-6.3h** |
| **Phase 2** | ãƒ¢ãƒ‡ãƒ«ä½œæˆä¸¦åˆ—åŒ– | ä¸­ | 60-75% | 82-86% | **2.1-2.6h** |
| **Phase 3** | DBã‚¯ã‚¨ãƒªæœ€é©åŒ– | é«˜ | 30-50% | 89-92% | **1.3-1.6h** |
| **Phase 4** | ç‰¹å¾´é‡ã‚­ãƒ£ãƒƒã‚·ãƒ¥ | ä¸­ | 80-90% (2å›ç›®ä»¥é™) | 97-98% | **10-20m** |
| **Phase 5** | ç«¶é¦¬å ´åˆ¥ä¸¦åˆ—åŒ– | ä¸­ | UPSETä½œæˆ70-80% | Phase 1ã‚’å¼·åŒ– | - |

---

## ğŸ¯ å®Ÿè£…ã®æ¨å¥¨é †åº

### å„ªå…ˆåº¦1ï¼ˆå³å®Ÿè£…æ¨å¥¨ï¼‰
1. **Phase 1: UPSETåˆ†é¡å™¨å…±é€šåŒ–**
   - ç†ç”±: æœ€é«˜åŠ¹æœãƒ»æœ€ä½ãƒªã‚¹ã‚¯ãƒ»æœ€çŸ­å®Ÿè£…æ™‚é–“
   - å®Ÿè£…æ™‚é–“: 1-2æ™‚é–“
   - ãƒªã‚¹ã‚¯: ä½ï¼ˆæ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯ã®å°ä¿®æ­£ã®ã¿ï¼‰

### å„ªå…ˆåº¦2ï¼ˆçŸ­æœŸå®Ÿè£…æ¨å¥¨ï¼‰
2. **Phase 2: ãƒ¢ãƒ‡ãƒ«ä½œæˆä¸¦åˆ—åŒ–**
   - ç†ç”±: é«˜åŠ¹æœãƒ»ä¸­ç¨‹åº¦ã®ãƒªã‚¹ã‚¯
   - å®Ÿè£…æ™‚é–“: 3-5æ™‚é–“
   - ãƒªã‚¹ã‚¯: ä¸­ï¼ˆä¸¦åˆ—å‡¦ç†ã®ãƒ‡ãƒãƒƒã‚°ãŒå¿…è¦ï¼‰
   - å‰æ: Phase 1å®Œäº†å¾Œ

3. **Phase 5: ç«¶é¦¬å ´åˆ¥ä¸¦åˆ—åŒ–**
   - ç†ç”±: Phase 1ã®åŠ¹æœã‚’ã•ã‚‰ã«å¼·åŒ–
   - å®Ÿè£…æ™‚é–“: 2-3æ™‚é–“
   - ãƒªã‚¹ã‚¯: ä¸­ï¼ˆPhase 2ã¨åŒæ§˜ã®ä¸¦åˆ—å‡¦ç†ï¼‰

### å„ªå…ˆåº¦3ï¼ˆä¸­æœŸå®Ÿè£…ï¼‰
4. **Phase 4: ç‰¹å¾´é‡ã‚­ãƒ£ãƒƒã‚·ãƒ¥**
   - ç†ç”±: 2å›ç›®ä»¥é™ã®å®Ÿè¡Œã§åŠ¹æœç™ºæ®
   - å®Ÿè£…æ™‚é–“: 4-6æ™‚é–“
   - ãƒªã‚¹ã‚¯: ä½ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ç„¡åŠ¹åŒ–ã®ä»•çµ„ã¿ãŒå¿…è¦ï¼‰

### å„ªå…ˆåº¦4ï¼ˆé•·æœŸå®Ÿè£…ãƒ»è¦æ³¨æ„ï¼‰
5. **Phase 3: DBã‚¯ã‚¨ãƒªæœ€é©åŒ–**
   - ç†ç”±: å½±éŸ¿ç¯„å›²ãŒåºƒã„ãƒ»æ…é‡ãªãƒ†ã‚¹ãƒˆãŒå¿…è¦
   - å®Ÿè£…æ™‚é–“: 8-12æ™‚é–“
   - ãƒªã‚¹ã‚¯: é«˜ï¼ˆSQLå¤‰æ›´ã«ã‚ˆã‚ŠçµæœãŒå¤‰ã‚ã‚‹å¯èƒ½æ€§ï¼‰
   - æ³¨æ„: 
     - æ—¢å­˜çµæœã¨ã®æ•´åˆæ€§ç¢ºèªå¿…é ˆ
     - ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è¿½åŠ ã¯æ¯”è¼ƒçš„å®‰å…¨ï¼ˆPhase 3-2ã‹ã‚‰å®Ÿæ–½å¯èƒ½ï¼‰

---

## âš ï¸ Further Considerationsï¼ˆé‡è¦ãªè€ƒæ…®äº‹é …ï¼‰

### 1. å®Ÿè£…ã®å„ªå…ˆé †ä½ã¨ãƒªã‚¹ã‚¯ç®¡ç†

#### Phase 1ï¼ˆUPSETå…±é€šåŒ–ï¼‰
- **æœ€å„ªå…ˆã§å®Ÿè£…ã™ã¹ã**: åŠ¹æœãŒæœ€ã‚‚é«˜ãã€å®Ÿè£…ã‚‚ç°¡å˜ï¼ˆ1-2æ™‚é–“ï¼‰
- **ãƒªã‚¹ã‚¯**: ä½ - æ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯ã®å°ä¿®æ­£ã®ã¿
- **ãƒ†ã‚¹ãƒˆæ–¹æ³•**: 1ãƒ¢ãƒ‡ãƒ«ã¨10ãƒ¢ãƒ‡ãƒ«ã§å®Ÿè¡Œæ™‚é–“ã‚’æ¯”è¼ƒ
- **æ³¨æ„ç‚¹**: `_create_upset_classifier()` 594-597è¡Œã®ãƒã‚°ä¿®æ­£ã‚’å¿˜ã‚Œãšã«

#### Phase 2ï¼ˆä¸¦åˆ—åŒ–ï¼‰
- **ä¸­ç¨‹åº¦ã®é›£æ˜“åº¦**: ä¸¦åˆ—å‡¦ç†ã®ãƒ‡ãƒãƒƒã‚°ã«æ™‚é–“ãŒã‹ã‹ã‚‹å¯èƒ½æ€§ï¼ˆ3-5æ™‚é–“ï¼‰
- **ãƒªã‚¹ã‚¯**: ä¸­ - `progress.json`ã®æ’ä»–åˆ¶å¾¡ãŒå¿…é ˆ
- **ãƒ†ã‚¹ãƒˆæ–¹æ³•**: 
  - 2ãƒ¢ãƒ‡ãƒ«ã§ä¸¦åˆ—åŒ–ã‚’è©¦ã—ã€progress.json ãŒæ­£ã—ãæ›´æ–°ã•ã‚Œã‚‹ã‹ç¢ºèª
  - ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ï¼ˆ`max_workers`èª¿æ•´ãŒå¿…è¦ãªå ´åˆã‚ã‚Šï¼‰
- **æ³¨æ„ç‚¹**: 
  - DBæ¥ç¶šã¯ãƒ—ãƒ­ã‚»ã‚¹ã”ã¨ã«ç‹¬ç«‹ã•ã›ã‚‹ï¼ˆpsycopg2æ¥ç¶šã¯ãƒ—ãƒ­ã‚»ã‚¹é–“ã§å…±æœ‰ä¸å¯ï¼‰
  - Windowsç’°å¢ƒã§ã¯ `if __name__ == '__main__':` ã‚¬ãƒ¼ãƒ‰ãŒå¿…é ˆ

#### Phase 3ï¼ˆDBæœ€é©åŒ–ï¼‰
- **å½±éŸ¿ç¯„å›²ãŒåºƒã„**: æ…é‡ãªãƒ†ã‚¹ãƒˆãŒå¿…è¦
- **ãƒªã‚¹ã‚¯**: é«˜ - SQLå¤‰æ›´ã«ã‚ˆã‚Šç‰¹å¾´é‡ã®å€¤ãŒå¤‰ã‚ã‚‹å¯èƒ½æ€§
- **æ®µéšçš„å®Ÿè£…**:
  1. **Phase 3-2ï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è¿½åŠ ï¼‰ã‹ã‚‰é–‹å§‹**: æ¯”è¼ƒçš„å®‰å…¨ã§åŠ¹æœã‚‚é«˜ã„
  2. ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŠ¹æœã‚’ç¢ºèªå¾Œã€Phase 3-1ï¼ˆCTEå¤‰æ›ï¼‰ã‚’å®Ÿæ–½
  3. Phase 3-3ï¼ˆãƒãƒ†ãƒªã‚¢ãƒ©ã‚¤ã‚ºãƒ‰ãƒ“ãƒ¥ãƒ¼ï¼‰ã¯æœ€å¾Œï¼ˆé‹ç”¨è² è·ãŒå¢—åŠ ï¼‰
- **ãƒ†ã‚¹ãƒˆæ–¹æ³•**:
  - SQLå¤‰æ›´å‰å¾Œã§ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®ç‰¹å¾´é‡ã‚’æ¯”è¼ƒï¼ˆå·®ç•°ãŒãªã„ã“ã¨ã‚’ç¢ºèªï¼‰
  - `EXPLAIN ANALYZE` ã§ã‚¯ã‚¨ãƒªãƒ—ãƒ©ãƒ³ã‚’æ¯”è¼ƒ
  - æ—¢å­˜ã®è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã¨æ–°è¦ãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬ç²¾åº¦ã‚’æ¯”è¼ƒ
- **æ³¨æ„ç‚¹**: 
  - ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è¿½åŠ ã§ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡å¢—åŠ ï¼ˆæ•°GBã€œï¼‰
  - ãƒãƒ†ãƒªã‚¢ãƒ©ã‚¤ã‚ºãƒ‰ãƒ“ãƒ¥ãƒ¼ã¯å®šæœŸæ›´æ–°ãŒå¿…è¦ï¼ˆcronç­‰ï¼‰

### 2. GPUåˆ©ç”¨ã®æ¤œè¨

#### LightGBM GPUç‰ˆ
```python
# LightGBM GPUç‰ˆã®è¨­å®šä¾‹
params = {
    'device': 'gpu',
    'gpu_platform_id': 0,
    'gpu_device_id': 0,
    'gpu_use_dp': False,  # å˜ç²¾åº¦æµ®å‹•å°æ•°ç‚¹ï¼ˆé«˜é€Ÿï¼‰
    ...
}
```

**æœŸå¾…åŠ¹æœ**: ãƒ¢ãƒ‡ãƒ«è¨“ç·´ãŒ **2-5å€é«˜é€ŸåŒ–**

**å‰ææ¡ä»¶**:
- CUDAå¯¾å¿œGPUï¼ˆNVIDIAï¼‰ãŒå¿…è¦
- LightGBM GPUç‰ˆã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«: `pip install lightgbm --install-option=--gpu`
- CUDAãƒ„ãƒ¼ãƒ«ã‚­ãƒƒãƒˆã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆ10.0ä»¥é™æ¨å¥¨ï¼‰

**æ¨å¥¨åˆ¤æ–­**:
- GPUãŒã‚ã‚‹å ´åˆ: Phase 1-2å®Œäº†å¾Œã«è©¦ã™ä¾¡å€¤ã‚ã‚Š
- GPUãŒãªã„å ´åˆ: Phase 1-3ã®åŠ¹æœã§ååˆ†ï¼ˆè¿½åŠ æŠ•è³‡ä¸è¦ï¼‰

**æ³¨æ„ç‚¹**:
- GPUç‰ˆã¯ `categorical_feature` ã®æ‰±ã„ãŒç•°ãªã‚‹å ´åˆã‚ã‚Š
- ãƒ¡ãƒ¢ãƒªä¸è¶³ã‚¨ãƒ©ãƒ¼ã«æ³¨æ„ï¼ˆGPU RAMã‚µã‚¤ã‚ºç¢ºèªï¼‰

### 3. ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç„¡åŠ¹åŒ–æˆ¦ç•¥

#### Phase 4 ç‰¹å¾´é‡ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®èª²é¡Œ
- **å•é¡Œ**: `db_query_builder.py` ã‚„ `feature_engineering.py` ã‚’å¤‰æ›´ã—ãŸå ´åˆã€å¤ã„ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒä½¿ã‚ã‚Œã‚‹
- **è§£æ±ºç­–**: ã‚³ãƒ¼ãƒ‰ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãƒãƒƒã‚·ãƒ¥ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ã«å«ã‚ã‚‹ï¼ˆå®Ÿè£…æ¸ˆã¿ï¼‰

#### ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç®¡ç†ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹
```python
# feature_cache.py ã«è¿½åŠ 
class FeatureCache:
    def invalidate_all(self):
        """å…¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å‰Šé™¤"""
        for cache_file in self.cache_dir.glob("*.parquet"):
            cache_file.unlink()
        print(f"ğŸ—‘ï¸  å…¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥å‰Šé™¤å®Œäº†")
    
    def get_cache_stats(self):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥çµ±è¨ˆã‚’è¡¨ç¤º"""
        cache_files = list(self.cache_dir.glob("*.parquet"))
        total_size = sum(f.stat().st_size for f in cache_files)
        
        print(f"\nğŸ“Š ã‚­ãƒ£ãƒƒã‚·ãƒ¥çµ±è¨ˆ")
        print(f"  ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(cache_files)}")
        print(f"  ç·å®¹é‡: {total_size / 1024**3:.2f} GB")
        print(f"  ç¾åœ¨ãƒãƒ¼ã‚¸ãƒ§ãƒ³: {self.version}")
```

#### ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥åˆ¶å¾¡
```python
# walk_forward_validation.py ã«è¿½åŠ 
parser.add_argument('--clear-cache', action='store_true', 
                    help='å®Ÿè¡Œå‰ã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢')
parser.add_argument('--no-cache', action='store_true',
                    help='ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä½¿ç”¨ã—ãªã„')

if args.clear_cache:
    FeatureCache().invalidate_all()
```

### 4. ãƒ¡ãƒ¢ãƒªç®¡ç†

#### ä¸¦åˆ—åŒ–æ™‚ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡
- **Phase 2**: `max_workers=4` ã®å ´åˆã€4ãƒ¢ãƒ‡ãƒ«åˆ†ã®ãƒ¡ãƒ¢ãƒªãŒå¿…è¦
- **æ¨å®š**: 1ãƒ¢ãƒ‡ãƒ« = 2-4GB â†’ 4ä¸¦åˆ— = **8-16GB**
- **å¯¾ç­–**: 
  ```python
  # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã«å¿œã˜ã¦ä¸¦åˆ—æ•°ã‚’èª¿æ•´
  import psutil
  available_memory_gb = psutil.virtual_memory().available / 1024**3
  max_workers = min(4, int(available_memory_gb / 4))  # 1ãƒ¢ãƒ‡ãƒ«=4GBæƒ³å®š
  ```

#### ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ãƒ¡ãƒ¢ãƒªå‰Šæ¸›
```python
# model_creator.py, universal_test.py ã«è¿½åŠ 
def reduce_memory_usage(df):
    """ãƒ‡ãƒ¼ã‚¿å‹ã‚’æœ€é©åŒ–ã—ã¦ãƒ¡ãƒ¢ãƒªå‰Šæ¸›"""
    for col in df.columns:
        if df[col].dtype == 'float64':
            df[col] = df[col].astype('float32')
        elif df[col].dtype == 'int64':
            df[col] = df[col].astype('int32')
    return df

df = reduce_memory_usage(df)  # ç‰¹å¾´é‡ä½œæˆå¾Œã«å®Ÿè¡Œ
```

**æœŸå¾…åŠ¹æœ**: ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ **30-50%å‰Šæ¸›**

### 5. é€²æ—ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã®æ”¹å–„

#### Phase 2 ä¸¦åˆ—åŒ–æ™‚ã®é€²æ—è¡¨ç¤º
```python
# walk_forward_validation.py ã«è¿½åŠ 
from tqdm import tqdm

with ProcessPoolExecutor(max_workers=max_workers) as executor:
    futures = {...}
    
    # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ä»˜ã
    with tqdm(total=len(target_models), desc="ãƒ¢ãƒ‡ãƒ«ä½œæˆ") as pbar:
        for future in as_completed(futures):
            model_name = futures[future]
            success, model_path = future.result()
            pbar.set_description(f"å®Œäº†: {model_name}")
            pbar.update(1)
```

#### ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é€²æ—ãƒ­ã‚°
```python
# å„ãƒ¯ãƒ¼ã‚«ãƒ¼ã‹ã‚‰ãƒ­ã‚°ã‚’åé›†
import logging
from logging.handlers import QueueHandler

# ãƒ¡ã‚¤ãƒ³ãƒ—ãƒ­ã‚»ã‚¹
log_queue = multiprocessing.Queue()
listener = logging.handlers.QueueListener(log_queue, *handlers)
listener.start()

# ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒ—ãƒ­ã‚»ã‚¹
logger = logging.getLogger()
logger.addHandler(QueueHandler(log_queue))
```

### 6. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨ãƒªãƒˆãƒ©ã‚¤

#### Phase 2 ä¸¦åˆ—åŒ–æ™‚ã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
```python
def _create_single_model_with_retry(self, model_name, max_retries=3, ...):
    """ãƒªãƒˆãƒ©ã‚¤ä»˜ããƒ¢ãƒ‡ãƒ«ä½œæˆ"""
    for attempt in range(max_retries):
        try:
            return self._create_single_model(model_name, ...)
        except Exception as e:
            if attempt < max_retries - 1:
                self.log(f"âš ï¸ {model_name} å¤±æ•—ï¼ˆãƒªãƒˆãƒ©ã‚¤ {attempt+1}/{max_retries}ï¼‰: {e}")
                time.sleep(5)  # 5ç§’å¾…æ©Ÿ
            else:
                self.log(f"âŒ {model_name} æœ€çµ‚å¤±æ•—: {e}")
                return False, None
```

### 7. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ—ãƒ¼ãƒ«

#### psycopg2 æ¥ç¶šãƒ—ãƒ¼ãƒ«ã®å°å…¥
```python
# db_connector.pyï¼ˆæ–°è¦ï¼‰
from psycopg2 import pool

class DatabasePool:
    _pool = None
    
    @classmethod
    def get_pool(cls):
        if cls._pool is None:
            config = load_db_config()
            cls._pool = pool.ThreadedConnectionPool(
                minconn=2,
                maxconn=10,
                host=config['host'],
                port=config['port'],
                user=config['user'],
                password=config['password'],
                dbname=config['dbname']
            )
        return cls._pool
    
    @classmethod
    def get_connection(cls):
        return cls.get_pool().getconn()
    
    @classmethod
    def return_connection(cls, conn):
        cls.get_pool().putconn(conn)

# ä½¿ç”¨ä¾‹
conn = DatabasePool.get_connection()
try:
    df = pd.read_sql_query(query, conn)
finally:
    DatabasePool.return_connection(conn)
```

**æœŸå¾…åŠ¹æœ**: DBæ¥ç¶šã®ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰å‰Šæ¸›ã€ä¸¦åˆ—å‡¦ç†æ™‚ã®æ¥ç¶šã‚¨ãƒ©ãƒ¼é˜²æ­¢

### 8. ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã¨ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯

#### åŠ¹ç‡åŒ–å®Ÿè£…ã®ãƒ–ãƒ©ãƒ³ãƒæˆ¦ç•¥
```bash
# å„Phaseã”ã¨ã«ãƒ–ãƒ©ãƒ³ãƒä½œæˆ
git checkout -b optimize/phase1-upset-sharing
# Phase 1 å®Ÿè£… + ãƒ†ã‚¹ãƒˆ
git commit -m "Phase 1: UPSETåˆ†é¡å™¨å…±é€šåŒ–"

git checkout -b optimize/phase2-parallel
# Phase 2 å®Ÿè£… + ãƒ†ã‚¹ãƒˆ
git commit -m "Phase 2: ãƒ¢ãƒ‡ãƒ«ä½œæˆä¸¦åˆ—åŒ–"
```

#### æ€§èƒ½æ¸¬å®šã®è¨˜éŒ²
```python
# performance_tracker.pyï¼ˆæ–°è¦ï¼‰
import time
import json
from pathlib import Path

class PerformanceTracker:
    def __init__(self, log_file='performance_log.json'):
        self.log_file = Path(log_file)
        self.metrics = []
    
    def record(self, phase, duration, models_count, test_year):
        self.metrics.append({
            'timestamp': time.time(),
            'phase': phase,
            'duration_seconds': duration,
            'duration_hours': duration / 3600,
            'models_count': models_count,
            'test_year': test_year
        })
        
        with open(self.log_file, 'w') as f:
            json.dump(self.metrics, f, indent=2)

# walk_forward_validation.py ã§ä½¿ç”¨
tracker = PerformanceTracker()
start_time = time.time()

# ... ãƒ¢ãƒ‡ãƒ«ä½œæˆ ...

duration = time.time() - start_time
tracker.record('baseline', duration, len(target_models), test_year)
```

### 9. å®Ÿè£…å¾Œã®æ¤œè¨¼é …ç›®

#### Phase 1 å®Ÿè£…å¾Œ
- [ ] 1ãƒ¢ãƒ‡ãƒ«å®Ÿè¡Œæ™‚: UPSETåˆ†é¡å™¨ãŒ1å›ã ã‘ä½œæˆã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
- [ ] 10ãƒ¢ãƒ‡ãƒ«å®Ÿè¡Œæ™‚: å‡¦ç†æ™‚é–“ãŒ 12-19h â†’ 5.6-6.3h ã«å‰Šæ¸›ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
- [ ] UPSETåˆ†é¡å™¨ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ­£ã—ãä¿å­˜ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
- [ ] å„ãƒ¢ãƒ‡ãƒ«ãŒUPSETåˆ†é¡å™¨ã‚’æ­£ã—ãå‚ç…§ã§ãã‚‹ã“ã¨ã‚’ç¢ºèª

#### Phase 2 å®Ÿè£…å¾Œ
- [ ] ä¸¦åˆ—å®Ÿè¡Œæ™‚ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãªã„ã“ã¨ã‚’ç¢ºèª
- [ ] progress.json ãŒæ­£ã—ãæ›´æ–°ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
- [ ] ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒè¨±å®¹ç¯„å›²å†…ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
- [ ] å‡¦ç†æ™‚é–“ãŒ 5.6-6.3h â†’ 2.1-2.6h ã«å‰Šæ¸›ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª

#### Phase 3 å®Ÿè£…å¾Œ
- [ ] SQLå¤‰æ›´å‰å¾Œã§ç‰¹å¾´é‡ã®å€¤ãŒä¸€è‡´ã™ã‚‹ã“ã¨ã‚’ç¢ºèªï¼ˆã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ï¼‰
- [ ] ã‚¯ã‚¨ãƒªå®Ÿè¡Œæ™‚é–“ãŒå‰Šæ¸›ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèªï¼ˆEXPLAIN ANALYZEï¼‰
- [ ] äºˆæ¸¬ç²¾åº¦ã«å¤‰åŒ–ãŒãªã„ã“ã¨ã‚’ç¢ºèªï¼ˆæ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã¨æ¯”è¼ƒï¼‰

#### Phase 4 å®Ÿè£…å¾Œ
- [ ] åˆå›å®Ÿè¡Œã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒä½œæˆã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
- [ ] 2å›ç›®å®Ÿè¡Œã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒä½¿ç”¨ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
- [ ] ã‚³ãƒ¼ãƒ‰å¤‰æ›´æ™‚ã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒç„¡åŠ¹åŒ–ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
- [ ] å‡¦ç†æ™‚é–“ãŒ 1.3-1.6h â†’ 10-20m ã«å‰Šæ¸›ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèªï¼ˆ2å›ç›®ä»¥é™ï¼‰

---

## ğŸ“ å®Ÿè£…ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

### Phase 1: UPSETåˆ†é¡å™¨å…±é€šåŒ–
- [ ] `walk_forward_validation.py` 826-852è¡Œã‚’ä¿®æ­£
- [ ] `upset_created` ãƒ•ãƒ©ã‚°è¿½åŠ 
- [ ] `_create_upset_classifier()` 594-597è¡Œã®ãƒã‚°ä¿®æ­£
- [ ] 1ãƒ¢ãƒ‡ãƒ«ã¨10ãƒ¢ãƒ‡ãƒ«ã§ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
- [ ] å‡¦ç†æ™‚é–“ã‚’è¨˜éŒ²ãƒ»æ¯”è¼ƒ

### Phase 2: ãƒ¢ãƒ‡ãƒ«ä½œæˆä¸¦åˆ—åŒ–
- [ ] `ProcessPoolExecutor` å°å…¥
- [ ] `_create_single_model()` ãƒ¡ã‚½ãƒƒãƒ‰å®Ÿè£…
- [ ] progress.json æ’ä»–åˆ¶å¾¡å®Ÿè£…
- [ ] ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°
- [ ] ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ»ãƒªãƒˆãƒ©ã‚¤å®Ÿè£…
- [ ] 2ãƒ¢ãƒ‡ãƒ«ã€4ãƒ¢ãƒ‡ãƒ«ã€10ãƒ¢ãƒ‡ãƒ«ã§ãƒ†ã‚¹ãƒˆ

### Phase 3: DBã‚¯ã‚¨ãƒªæœ€é©åŒ–
- [ ] Phase 3-2: PostgreSQLã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è¿½åŠ 
- [ ] ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŠ¹æœã‚’ `EXPLAIN ANALYZE` ã§ç¢ºèª
- [ ] Phase 3-1: CTEå¤‰æ›å®Ÿè£…
- [ ] SQLå¤‰æ›´å‰å¾Œã§ç‰¹å¾´é‡æ¯”è¼ƒ
- [ ] Phase 3-3: ãƒãƒ†ãƒªã‚¢ãƒ©ã‚¤ã‚ºãƒ‰ãƒ“ãƒ¥ãƒ¼æ¤œè¨ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

### Phase 4: ç‰¹å¾´é‡ã‚­ãƒ£ãƒƒã‚·ãƒ¥
- [ ] `feature_cache.py` å®Ÿè£…
- [ ] `model_creator.py` ã«çµ±åˆ
- [ ] `universal_test.py` ã«çµ±åˆ
- [ ] ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç„¡åŠ¹åŒ–ãƒ†ã‚¹ãƒˆ
- [ ] 2å›ç›®å®Ÿè¡Œã§é«˜é€ŸåŒ–ã‚’ç¢ºèª

### Phase 5: ç«¶é¦¬å ´åˆ¥ä¸¦åˆ—åŒ–
- [ ] `analyze_upset_patterns.py` ä¸¦åˆ—åŒ–å®Ÿè£…
- [ ] `_get_single_track_data_worker()` å®Ÿè£…
- [ ] 10ç«¶é¦¬å ´ã§ãƒ†ã‚¹ãƒˆ
- [ ] UPSETåˆ†é¡å™¨ä½œæˆæ™‚é–“ã‚’è¨˜éŒ²ãƒ»æ¯”è¼ƒ

---

## ğŸ“ å‚è€ƒæƒ…å ±

### ä¸¦åˆ—å‡¦ç†ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹
- [Python multiprocessing documentation](https://docs.python.org/3/library/multiprocessing.html)
- [concurrent.futures documentation](https://docs.python.org/3/library/concurrent.futures.html)

### PostgreSQLæœ€é©åŒ–
- [PostgreSQL Performance Tips](https://wiki.postgresql.org/wiki/Performance_Optimization)
- [PostgreSQL Indexes](https://www.postgresql.org/docs/current/indexes.html)
- [Materialized Views](https://www.postgresql.org/docs/current/rules-materializedviews.html)

### LightGBM
- [LightGBM GPU Tutorial](https://lightgbm.readthedocs.io/en/latest/GPU-Tutorial.html)
- [LightGBM Parameters Tuning](https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html)

---

## ğŸ“Š UPSETåˆ†é¡å™¨ã®ç‰¹å¾´é‡ä¸€è¦§ï¼ˆPhase 3.5.1å®Œäº†æ™‚ç‚¹ï¼‰

### å…¨ä½“ã‚µãƒãƒªãƒ¼
- **ç·ç‰¹å¾´é‡æ•°**: 35å€‹
- **ç‰¹å¾´é‡ã‚«ãƒ†ã‚´ãƒª**: 8ã¤
- **æœ€çµ‚æ›´æ–°æ—¥**: 2026å¹´1æœˆ20æ—¥ï¼ˆPhase 3.5.1å®Œäº†ï¼‰

---

### 1. ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›ï¼ˆ2å€‹ï¼‰
Universal Rankerã®äºˆæ¸¬çµæœã‚’æ´»ç”¨ã—ãŸç‰¹å¾´é‡

| ç‰¹å¾´é‡å | èª¬æ˜ | é‡è¦åº¦é †ä½ |
|---------|------|-----------|
| `predicted_rank` | Universal Rankerã«ã‚ˆã‚‹äºˆæ¸¬é †ä½ï¼ˆ1-18ä½ï¼‰ | 18ä½ |
| `predicted_score` | Universal Rankerã®äºˆæ¸¬ã‚¹ã‚³ã‚¢ï¼ˆé«˜ã„ã»ã©ä¸Šä½äºˆæ¸¬ï¼‰ | 22ä½ |

---

### 2. äººæ°—ãƒ»ã‚ªãƒƒã‚ºæƒ…å ±ï¼ˆ3å€‹ï¼‰
é¦¬åˆ¸å¸‚å ´ã®è©•ä¾¡ã¨äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã¨ã®ä¹–é›¢ã‚’ç¤ºã™ç‰¹å¾´é‡

| ç‰¹å¾´é‡å | èª¬æ˜ | é‡è¦åº¦é †ä½ |
|---------|------|-----------|
| `popularity_rank` | å˜å‹äººæ°—é †ä½ï¼ˆ1-18ä½ï¼‰ | **2ä½** â­ |
| `tansho_odds` | å˜å‹ã‚ªãƒƒã‚ºï¼ˆå€ï¼‰ | 11ä½ |
| `value_gap` | äºˆæ¸¬é †ä½ - äººæ°—é †ä½ï¼ˆè² ã®å€¤ï¼éå°è©•ä¾¡ï¼‰ | 17ä½ |

---

### 3. æ—¢å­˜ã®é‡è¦ç‰¹å¾´é‡ï¼ˆ8å€‹ï¼‰
Universal Rankerã§ã‚‚ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹åŸºæœ¬ç‰¹å¾´é‡

| ç‰¹å¾´é‡å | èª¬æ˜ | é‡è¦åº¦é †ä½ |
|---------|------|-----------|
| `past_score` | éå»3èµ°ã®ã‚°ãƒ¬ãƒ¼ãƒ‰åˆ¥ã‚¹ã‚³ã‚¢åˆè¨ˆï¼ˆ1ç€100ç‚¹ã€G1ã¯3å€ï¼‰ | 10ä½ |
| `past_avg_sotai_chakujun` | éå»3èµ°ã®ç›¸å¯¾ç€é †å¹³å‡ï¼ˆæ™‚è¨ˆå·®è€ƒæ…®ï¼‰ | 9ä½ |
| `kohan_3f_index` | éå»3èµ°ã®å¾ŒåŠ3Få¹³å‡ - è·é›¢åˆ¥åŸºæº–å€¤ | 21ä½ |
| `time_index` | éå»3èµ°ã®èµ°ç ´æ™‚è¨ˆæŒ‡æ•°ï¼ˆè·é›¢/ç§’ï¼‰ | 12ä½ |
| `relative_ability` | ãƒ¬ãƒ¼ã‚¹å†…ã§ã®ç›¸å¯¾èƒ½åŠ›å€¤ï¼ˆpast_score_meanã®z-scoreï¼‰ | 24ä½ |
| `current_class_score` | ä»Šå›ãƒ¬ãƒ¼ã‚¹ã®ã‚¯ãƒ©ã‚¹ã‚¹ã‚³ã‚¢ï¼ˆG1=3.0ã€æœªå‹åˆ©=0.2ï¼‰ | 34ä½ |
| `class_score_change` | ã‚¯ãƒ©ã‚¹ã‚¹ã‚³ã‚¢å¤‰åŒ–ï¼ˆå‰èµ°æ¯”ã€æ­£=æ˜‡ç´šã€è² =é™ç´šï¼‰ | 7ä½ |
| `past_score_mean` | éå»3èµ°ã®past_scoreã®å¹³å‡å€¤ | **5ä½** â­ |

---

### 4. å±•é–‹è¦å› ï¼ˆ2å€‹ï¼‰
ãƒ¬ãƒ¼ã‚¹å±•é–‹ã‚’äºˆæ¸¬ã™ã‚‹ãŸã‚ã®ç‰¹å¾´é‡ï¼ˆPhase 2.5è¿½åŠ ï¼‰

| ç‰¹å¾´é‡å | èª¬æ˜ | é‡è¦åº¦é †ä½ |
|---------|------|-----------|
| `avg_4corner_position` | éå»ã®4ã‚³ãƒ¼ãƒŠãƒ¼å¹³å‡ä½ç½®ï¼ˆ1-18ï¼‰ | **4ä½** â­ |
| `prev_rank_change` | å‰èµ°ç€é †å¤‰åŒ–ï¼ˆå‰èµ°ç€é † - ä»Šå›ç€é †ï¼‰ | **1ä½** ğŸ”¥ |

**Note**: `prev_rank_change`ã¯**åœ§å€’çš„1ä½**ï¼ˆé‡è¦åº¦43.8%ï¼‰ã§ã€ç©´é¦¬äºˆæ¸¬ã®æœ€é‡è¦ç‰¹å¾´é‡

---

### 5. Phase 3: ç©´é¦¬ç‰¹åŒ–ç‰¹å¾´é‡ï¼ˆ4å€‹ï¼‰
æˆç¸¾ã®ä¸å®‰å®šã•ã‚„å±•é–‹çš„æœ‰åˆ©ã•ã‚’ç¤ºã™ç‰¹å¾´é‡

| ç‰¹å¾´é‡å | èª¬æ˜ | é‡è¦åº¦é †ä½ |
|---------|------|-----------|
| `past_score_std` | éå»5èµ°ã®æˆç¸¾ã‚¹ã‚³ã‚¢æ¨™æº–åå·®ï¼ˆé«˜ã„ã»ã©æ³¢ãŒã‚ã‚‹ï¼‰ | 31ä½ |
| `past_chakujun_variance` | éå»5èµ°ã®ç€é †åˆ†æ•£ï¼ˆé«˜ã„ã»ã©ä¸å®‰å®šï¼‰ | 30ä½ |
| `zenso_oikomi_power` | å‰èµ°è¿½ã„è¾¼ã¿åŠ›ï¼ˆ4ã‚³ãƒ¼ãƒŠãƒ¼ä½ç½® - ç€é †ã€æ­£=è¿½è¾¼ï¼‰ | 27ä½ |
| `zenso_kakoi_komon` | å‰èµ°åŒ…ã¾ã‚Œåº¦ï¼ˆ2ã‚³ãƒ¼ãƒŠãƒ¼ä½ç½® - 4ã‚³ãƒ¼ãƒŠãƒ¼ä½ç½®ã€æ­£=å¤–ã¸ï¼‰ | 34ä½ |

---

### 6. Phase 3.5: å‰èµ°ãƒ‘ã‚¿ãƒ¼ãƒ³ç‰¹å¾´é‡ï¼ˆ5å€‹ï¼‰
å‰èµ°ã®ãƒ¬ãƒ¼ã‚¹å†…å®¹ã‚„æˆç¸¾å¤‰åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç¤ºã™ç‰¹å¾´é‡

| ç‰¹å¾´é‡å | èª¬æ˜ | é‡è¦åº¦é †ä½ |
|---------|------|-----------|
| `zenso_ninki_gap` | å‰èµ°äººæ°—ç€é †ã‚®ãƒ£ãƒƒãƒ—ï¼ˆäººæ°— - ç€é †ã€æ­£=éå°è©•ä¾¡ã ã£ãŸï¼‰ | 20ä½ |
| `zenso_nigeba` | å‰èµ°é€ƒã’æˆåŠŸãƒ•ãƒ©ã‚°ï¼ˆ1ã‚³ãƒ¼ãƒŠãƒ¼1ä½=1ï¼‰ | 29ä½ |
| `zenso_taihai` | å‰èµ°å¤§æ•—ãƒ•ãƒ©ã‚°ï¼ˆ10ç€ä»¥ä¸‹=1ï¼‰ | **3ä½** ğŸ”¥ |
| `zenso_agari_rank` | å‰èµ°ä¸ŠãŒã‚Š3Fé †ä½ï¼ˆãƒ¬ãƒ¼ã‚¹å†…ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼‰ | 14ä½ |
| `saikin_kaikakuritsu` | ç›´è¿‘3èµ°æ”¹å–„ç‡ï¼ˆå‰èµ°ã‚ˆã‚Šç€é †æ”¹å–„ã—ãŸå‰²åˆ0-1.0ï¼‰ | 15ä½ |

**Note**: `zenso_taihai`ã¯**3ä½**ï¼ˆé‡è¦åº¦8.4%ï¼‰ã§ã€å‰èµ°å¤§æ•—å¾Œã®å·»ãè¿”ã—ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ‰ãˆã‚‹

---

### 7. Phase 3.5.1: é¨æ‰‹ãƒ»èª¿æ•™å¸«ãƒ»é¦¬çµ±è¨ˆï¼ˆ9å€‹ï¼‰
é–¢ä¿‚è€…ã®æˆç¸¾çµ±è¨ˆã«ã‚ˆã‚‹ç©´é¦¬ã®å…†å€™ã‚’ç¤ºã™ç‰¹å¾´é‡ï¼ˆ2026-01-20è¿½åŠ ï¼‰

| ç‰¹å¾´é‡å | èª¬æ˜ | é‡è¦åº¦é †ä½ | åŠ¹æœ |
|---------|------|-----------|-----|
| `jockey_win_rate` | é¨æ‰‹å‹ç‡ï¼ˆéå»50èµ°ã§1ç€ã®å‰²åˆï¼‰ | 13ä½ | âœ… æœ‰åŠ¹ |
| `jockey_place_rate` | é¨æ‰‹é€£å¯¾ç‡ï¼ˆéå»50èµ°ã§3ç€ä»¥å†…ã®å‰²åˆï¼‰ | 23ä½ | â–³ å¾®å¦™ |
| `jockey_recent_form` | é¨æ‰‹æœ€è¿‘æˆç¸¾ï¼ˆéå»10èµ°å¹³å‡ç€é †ã‚¹ã‚³ã‚¢ï¼‰ | 19ä½ | âœ… æœ‰åŠ¹ |
| `trainer_win_rate` | èª¿æ•™å¸«å‹ç‡ï¼ˆéå»50èµ°ã§1ç€ã®å‰²åˆï¼‰ | 28ä½ | â–³ å¾®å¦™ |
| `trainer_place_rate` | èª¿æ•™å¸«é€£å¯¾ç‡ï¼ˆéå»50èµ°ã§3ç€ä»¥å†…ã®å‰²åˆï¼‰ | **8ä½** ğŸ”¥ | âœ… æœ‰åŠ¹ |
| `trainer_recent_form` | èª¿æ•™å¸«æœ€è¿‘æˆç¸¾ï¼ˆéå»20èµ°å¹³å‡ç€é †ã‚¹ã‚³ã‚¢ï¼‰ | 16ä½ | âœ… æœ‰åŠ¹ |
| `horse_career_win_rate` | é¦¬é€šç®—å‹ç‡ï¼ˆå…¨ãƒ¬ãƒ¼ã‚¹ã§1ç€ã®å‰²åˆï¼‰ | 35ä½ï¼ˆæœ€ä¸‹ä½ï¼‰ | âŒ ç„¡åŠ¹ |
| `horse_career_place_rate` | é¦¬é€šç®—é€£å¯¾ç‡ï¼ˆå…¨ãƒ¬ãƒ¼ã‚¹ã§3ç€ä»¥å†…ã®å‰²åˆï¼‰ | 33ä½ | âŒ ç„¡åŠ¹ |
| `rest_weeks` | ä¼‘é¤Šé€±æ•°ï¼ˆå‰èµ°ã‹ã‚‰ä»Šå›ã¾ã§ã®é€±æ•°ï¼‰ | 26ä½ | â–³ å¾®å¦™ |

**ç·åˆè©•ä¾¡**: 
- âœ… **trainer_place_rate**ãŒ8ä½ã§**æœ€ã‚‚æœ‰åŠ¹**
- âœ… é¨æ‰‹ãƒ»èª¿æ•™å¸«ã®çµ±è¨ˆã¯ä¸€å®šã®åŠ¹æœã‚ã‚Š
- âŒ é¦¬ã®é€šç®—æˆç¸¾ã¯**ã»ã¼ç„¡åŠ¹**ï¼ˆç©´é¦¬äºˆæ¸¬ã«ä¸é©ï¼‰
- ğŸ“Š **Precisionæ”¹å–„åŠ¹æœ**: 5.29% â†’ 6.20%ï¼ˆ+0.91%ï¼‰

---

### 8. ãƒ¬ãƒ¼ã‚¹æ¡ä»¶ï¼ˆ3å€‹ï¼‰
ãƒ¬ãƒ¼ã‚¹ã®åŸºæœ¬æ¡ä»¶

| ç‰¹å¾´é‡å | èª¬æ˜ | é‡è¦åº¦é †ä½ |
|---------|------|-----------|
| `kyori` | ãƒ¬ãƒ¼ã‚¹è·é›¢ï¼ˆmï¼‰ | **6ä½** â­ |
| `baba_jotai_code_numeric` | é¦¬å ´çŠ¶æ…‹ã‚³ãƒ¼ãƒ‰ï¼ˆ1=è‰¯ã€2=ç¨é‡ã€3=é‡ã€4=ä¸è‰¯ï¼‰ | - |
| `keibajo_code_numeric` | ç«¶é¦¬å ´ã‚³ãƒ¼ãƒ‰ï¼ˆ1=æœ­å¹Œã€9=é˜ªç¥ãªã©ï¼‰ | 25ä½ |

---

### ğŸ“ˆ ç‰¹å¾´é‡é‡è¦åº¦ãƒˆãƒƒãƒ—10

| é †ä½ | ç‰¹å¾´é‡å | é‡è¦åº¦ | ç´¯ç©å‰²åˆ | ã‚«ãƒ†ã‚´ãƒª |
|-----|---------|-------|---------|---------|
| 1 | `prev_rank_change` | 43.8% | 43.8% | å±•é–‹è¦å›  |
| 2 | `popularity_rank` | 27.7% | 71.5% | äººæ°—ãƒ»ã‚ªãƒƒã‚º |
| 3 | `zenso_taihai` | 8.4% | 79.9% | Phase 3.5 |
| 4 | `avg_4corner_position` | 2.6% | 82.5% | å±•é–‹è¦å›  |
| 5 | `past_score_mean` | 2.5% | 85.0% | åŸºæœ¬ç‰¹å¾´é‡ |
| 6 | `kyori` | 2.1% | 87.1% | ãƒ¬ãƒ¼ã‚¹æ¡ä»¶ |
| 7 | `class_score_change` | 1.7% | 88.8% | åŸºæœ¬ç‰¹å¾´é‡ |
| 8 | `trainer_place_rate` | 1.6% | 90.4% | Phase 3.5.1 |
| 9 | `past_avg_sotai_chakujun` | 1.4% | 91.8% | åŸºæœ¬ç‰¹å¾´é‡ |
| 10 | `past_score` | 1.3% | 93.1% | åŸºæœ¬ç‰¹å¾´é‡ |

**åˆ†æçµæœ**:
- ãƒˆãƒƒãƒ—3ç‰¹å¾´é‡ã§**80%ã‚’èª¬æ˜**
- ä¸Šä½9ç‰¹å¾´é‡ã§**95%ã‚’é”æˆ**
- **å±•é–‹è¦å› ï¼ˆprev_rank_changeï¼‰ãŒåœ§å€’çš„**

---

### ğŸ—‘ï¸ å‰Šé™¤æ¸ˆã¿ç‰¹å¾´é‡

ä»¥ä¸‹ã®ç‰¹å¾´é‡ã¯Phase 3.5ã§å‰Šé™¤ã•ã‚Œã¾ã—ãŸï¼š

| ç‰¹å¾´é‡å | å‰Šé™¤ç†ç”± |
|---------|---------|
| `wakuban_inner` | çŸ­è·é›¢å°‚ç”¨ã§æ±ç”¨æ€§ã«æ¬ ã‘ã‚‹ |
| `wakuban_outer` | çŸ­è·é›¢å°‚ç”¨ã§æ±ç”¨æ€§ã«æ¬ ã‘ã‚‹ |
| `estimated_running_style` | æ¨å®šå€¤ã§ãƒã‚¤ã‚ºãŒå¤šã„ |
| `tenko_code` | åŠ¹æœä¸æ˜ç­ |
| `distance_change` | è·é›¢é©æ€§ã‚¹ã‚³ã‚¢ã§å¸åæ¸ˆã¿ |
| `weight_change` | é€Ÿå ±ãƒ‡ãƒ¼ã‚¿ã§åˆ©ç”¨ä¸å¯ï¼ˆé¦¬ä½“é‡æœªç¢ºå®šï¼‰ |

---

### ğŸ“Š ä»Šå¾Œã®æ”¹å–„æ–¹å‘æ€§

#### âœ… æœ‰åŠ¹ãªæ–¹å‘
1. **å±•é–‹è¦å› ã®å¼·åŒ–**: prev_rank_changeãŒåœ§å€’çš„1ä½
   - ãƒšãƒ¼ã‚¹äºˆæ¸¬ã€é€ƒã’é¦¬æ•°ã€è„šè³ªåˆ†å¸ƒãªã©
2. **å‰èµ°ãƒ‘ã‚¿ãƒ¼ãƒ³**: zenso_taihaiãŒ3ä½
   - å‰èµ°æ•—å› åˆ†æã€ãƒ¬ãƒ¼ã‚¹è³ªã®å¤‰åŒ–ãªã©
3. **èª¿æ•™å¸«çµ±è¨ˆ**: trainer_place_rateãŒ8ä½
   - èª¿æ•™å¸«Ã—é¨æ‰‹ã‚³ãƒ³ãƒ“ã€å©èˆåˆ¥å‚¾å‘ãªã©

#### âŒ åŠ¹æœè–„ã„æ–¹å‘
1. **é¦¬ã®é€šç®—æˆç¸¾**: æœ€ä¸‹ä½ã‚°ãƒ«ãƒ¼ãƒ—
   - ç©´é¦¬ã¯ã€Œæ³¢ãŒã‚ã‚‹é¦¬ã€ãªã®ã§é€šç®—æˆç¸¾ã¯ç„¡æ„å‘³
2. **åŸºæœ¬ç‰¹å¾´é‡ã®è¿½åŠ **: ã™ã§ã«é£½å’Œæ°—å‘³
   - ã“ã‚Œä»¥ä¸Šè¿½åŠ ã—ã¦ã‚‚åŠ¹æœã¯é™å®šçš„

---

**ä½œæˆæ—¥**: 2026å¹´1æœˆ20æ—¥  
**å¯¾è±¡**: walk_forward_validation.py, analyze_upset_patterns.py, db_query_builder.py, feature_engineering.py, model_creator.py  
**ç›®æ¨™**: Walk-Forwardæ¤œè¨¼ã®å‡¦ç†æ™‚é–“ã‚’ 12-19æ™‚é–“ â†’ 10-20åˆ†ï¼ˆ2å›ç›®ä»¥é™ï¼‰ã«çŸ­ç¸®
