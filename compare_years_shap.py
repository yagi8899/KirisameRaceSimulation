#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¹´åº¦é–“SHAPå€¤æ¯”è¼ƒãƒ„ãƒ¼ãƒ«

è¤‡æ•°å¹´åº¦ã®SHAPå€¤ã‚’æ¯”è¼ƒã—ã¦ã€ç‰¹å¾´é‡ã®é‡è¦åº¦å¤‰åŒ–ã‚’åˆ†æã—ã¾ã™ã€‚

ä½¿ç”¨ä¾‹:
    # æ±äº¬èŠä¸­é•·è·é›¢ã®2021-2023å¹´ã‚’æ¯”è¼ƒ
    python compare_years_shap.py --model tokyo_turf_3ageup_long --years 2021 2022 2023
    
    # é˜ªç¥ãƒ€ãƒ¼ãƒˆçŸ­è·é›¢ã®2022-2024å¹´ã‚’æ¯”è¼ƒ
    python compare_years_shap.py --model hanshin_dirt_3ageup_short --years 2022 2023 2024
    
    # å‡ºåŠ›å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º
    python compare_years_shap.py --model tokyo_turf_3ageup_long --years 2021 2022 2023 --output shap_year_comparison
"""

import argparse
import sys
from pathlib import Path
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib import rcParams
from scipy.stats import pearsonr, spearmanr

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
rcParams['font.sans-serif'] = ['MS Gothic', 'Yu Gothic', 'Meiryo', 'DejaVu Sans']
rcParams['axes.unicode_minus'] = False


def load_shap_csv(model_name, year, base_dir='shap_analysis'):
    """
    æŒ‡å®šã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¨å¹´åº¦ã®SHAP CSVã‚’èª­ã¿è¾¼ã‚€
    
    Args:
        model_name (str): ãƒ¢ãƒ‡ãƒ«å
        year (int): å¹´åº¦
        base_dir (str): SHAPåˆ†æçµæœã®ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        
    Returns:
        pd.DataFrame or None: SHAPé‡è¦åº¦ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ï¼ˆèª­ã¿è¾¼ã¿å¤±æ•—æ™‚ã¯Noneï¼‰
    """
    csv_path = Path(base_dir) / f"{model_name}_importance.csv"
    
    if not csv_path.exists():
        print(f"âš ï¸  SHAP CSVãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {csv_path}")
        return None
    
    try:
        df = pd.read_csv(csv_path)
        df['year'] = year  # å¹´åº¦ã‚«ãƒ©ãƒ è¿½åŠ 
        print(f"âœ… {year}å¹´ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿æˆåŠŸ: {len(df)} features")
        return df
    except Exception as e:
        print(f"âŒ {year}å¹´ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return None


def calculate_year_correlation(df1, df2, year1, year2):
    """
    2å¹´åº¦é–“ã®SHAPå€¤ç›¸é–¢ã‚’è¨ˆç®—
    
    Args:
        df1 (pd.DataFrame): å¹´åº¦1ã®SHAPãƒ‡ãƒ¼ã‚¿
        df2 (pd.DataFrame): å¹´åº¦2ã®SHAPãƒ‡ãƒ¼ã‚¿
        year1 (int): å¹´åº¦1
        year2 (int): å¹´åº¦2
        
    Returns:
        dict: ç›¸é–¢çµ±è¨ˆæƒ…å ±
    """
    # å…±é€šç‰¹å¾´é‡ã®æŠ½å‡º
    common_features = set(df1['feature'].values) & set(df2['feature'].values)
    
    if not common_features:
        return {
            'year1': year1,
            'year2': year2,
            'common_features': 0,
            'pearson_r': np.nan,
            'spearman_r': np.nan
        }
    
    # å…±é€šç‰¹å¾´é‡ã§ã‚½ãƒ¼ãƒˆã—ã¦ãƒ‡ãƒ¼ã‚¿å–å¾—
    sorted_features = sorted(common_features)
    
    df1_filtered = df1[df1['feature'].isin(sorted_features)].set_index('feature').loc[sorted_features]
    df2_filtered = df2[df2['feature'].isin(sorted_features)].set_index('feature').loc[sorted_features]
    
    # Pearsonç›¸é–¢ï¼ˆç·šå½¢ç›¸é–¢ï¼‰
    pearson_r, pearson_p = pearsonr(df1_filtered['mean_abs_shap'], df2_filtered['mean_abs_shap'])
    
    # Spearmanç›¸é–¢ï¼ˆé †ä½ç›¸é–¢ï¼‰
    spearman_r, spearman_p = spearmanr(df1_filtered['mean_abs_shap'], df2_filtered['mean_abs_shap'])
    
    return {
        'year1': year1,
        'year2': year2,
        'common_features': len(common_features),
        'pearson_r': pearson_r,
        'pearson_p': pearson_p,
        'spearman_r': spearman_r,
        'spearman_p': spearman_p
    }


def plot_year_comparison(dfs_dict, model_name, output_dir, top_n=20):
    """
    å¹´åº¦é–“SHAPå€¤æ¯”è¼ƒãƒ—ãƒ­ãƒƒãƒˆã‚’ç”Ÿæˆ
    
    Args:
        dfs_dict (dict): {year: DataFrame} å½¢å¼ã®è¾æ›¸
        model_name (str): ãƒ¢ãƒ‡ãƒ«å
        output_dir (Path): å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        top_n (int): è¡¨ç¤ºã™ã‚‹ä¸Šä½ç‰¹å¾´é‡æ•°
    """
    years = sorted(dfs_dict.keys())
    
    if len(years) < 2:
        print("âš ï¸  æ¯”è¼ƒã«ã¯æœ€ä½2å¹´åº¦ã®ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ã§ã™")
        return
    
    # 1. ä¸Šä½ç‰¹å¾´é‡ã®å¹´åº¦é–“æ¯”è¼ƒï¼ˆæ£’ã‚°ãƒ©ãƒ•ï¼‰
    fig, axes = plt.subplots(1, len(years), figsize=(6*len(years), 8), sharey=True)
    
    if len(years) == 1:
        axes = [axes]
    
    # å…¨å¹´åº¦ã§å…±é€šã®ä¸Šä½ç‰¹å¾´é‡ã‚’æŠ½å‡ºï¼ˆæœ€åˆã®å¹´åº¦åŸºæº–ï¼‰
    base_year = years[0]
    top_features = dfs_dict[base_year].nlargest(top_n, 'mean_abs_shap')['feature'].values
    
    for i, year in enumerate(years):
        df = dfs_dict[year]
        df_filtered = df[df['feature'].isin(top_features)].set_index('feature').loc[top_features]
        
        axes[i].barh(range(len(top_features)), df_filtered['mean_abs_shap'].values)
        axes[i].set_yticks(range(len(top_features)))
        axes[i].set_yticklabels(top_features, fontsize=9)
        axes[i].set_xlabel('Mean |SHAP value|', fontsize=10)
        axes[i].set_title(f'{year}å¹´', fontsize=12, fontweight='bold')
        axes[i].grid(axis='x', alpha=0.3)
    
    axes[0].invert_yaxis()
    plt.suptitle(f'{model_name} - å¹´åº¦åˆ¥ä¸Šä½{top_n}ç‰¹å¾´é‡', fontsize=14, fontweight='bold')
    plt.tight_layout()
    plt.savefig(output_dir / f'{model_name}_year_comparison_bars.png', dpi=150, bbox_inches='tight')
    plt.close()
    print(f"   ğŸ“Š æ£’ã‚°ãƒ©ãƒ•ä¿å­˜: {output_dir / f'{model_name}_year_comparison_bars.png'}")
    
    
    # 2. å¹´åº¦é–“ç›¸é–¢ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
    if len(years) >= 2:
        # å…¨ãƒšã‚¢ã®ç›¸é–¢ã‚’è¨ˆç®—
        corr_results = []
        for i in range(len(years)):
            for j in range(i+1, len(years)):
                result = calculate_year_correlation(
                    dfs_dict[years[i]], 
                    dfs_dict[years[j]], 
                    years[i], 
                    years[j]
                )
                corr_results.append(result)
        
        # ç›¸é–¢è¡Œåˆ—ä½œæˆ
        corr_matrix = pd.DataFrame(index=years, columns=years, dtype=float)
        
        for year in years:
            corr_matrix.loc[year, year] = 1.0
        
        for result in corr_results:
            y1, y2 = result['year1'], result['year2']
            corr_matrix.loc[y1, y2] = result['spearman_r']
            corr_matrix.loc[y2, y1] = result['spearman_r']
        
        # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—æç”»
        fig, ax = plt.subplots(figsize=(8, 6))
        sns.heatmap(
            corr_matrix.astype(float), 
            annot=True, 
            fmt='.3f', 
            cmap='RdYlGn', 
            vmin=-1, 
            vmax=1, 
            center=0,
            square=True,
            linewidths=1,
            cbar_kws={"shrink": 0.8}
        )
        plt.title(f'{model_name} - å¹´åº¦é–“SHAPå€¤ç›¸é–¢ (Spearman)', fontsize=14, fontweight='bold')
        plt.xlabel('å¹´åº¦', fontsize=12)
        plt.ylabel('å¹´åº¦', fontsize=12)
        plt.tight_layout()
        plt.savefig(output_dir / f'{model_name}_year_correlation_heatmap.png', dpi=150, bbox_inches='tight')
        plt.close()
        print(f"   ğŸ“Š ç›¸é–¢ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ä¿å­˜: {output_dir / f'{model_name}_year_correlation_heatmap.png'}")
    
    
    # 3. æ™‚ç³»åˆ—ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ—ãƒ­ãƒƒãƒˆï¼ˆä¸Šä½ç‰¹å¾´é‡ã®ã¿ï¼‰
    if len(years) >= 3:
        # å…¨å¹´åº¦å…±é€šã®ç‰¹å¾´é‡
        common_features = set(dfs_dict[years[0]]['feature'])
        for year in years[1:]:
            common_features &= set(dfs_dict[year]['feature'])
        
        # æœ€åˆã®å¹´åº¦ã§ä¸Šä½ã®ç‰¹å¾´é‡ã‚’é¸æŠ
        top_common = dfs_dict[years[0]][dfs_dict[years[0]]['feature'].isin(common_features)]\
            .nlargest(10, 'mean_abs_shap')['feature'].values
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ—ãƒ­ãƒƒãƒˆ
        fig, ax = plt.subplots(figsize=(12, 7))
        
        for feature in top_common:
            values = []
            for year in years:
                df = dfs_dict[year]
                value = df[df['feature'] == feature]['mean_abs_shap'].values
                values.append(value[0] if len(value) > 0 else np.nan)
            
            ax.plot(years, values, marker='o', label=feature, linewidth=2)
        
        ax.set_xlabel('å¹´åº¦', fontsize=12)
        ax.set_ylabel('Mean |SHAP value|', fontsize=12)
        ax.set_title(f'{model_name} - ä¸Šä½ç‰¹å¾´é‡ã®æ™‚ç³»åˆ—å¤‰åŒ–', fontsize=14, fontweight='bold')
        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9)
        ax.grid(alpha=0.3)
        plt.tight_layout()
        plt.savefig(output_dir / f'{model_name}_year_trend.png', dpi=150, bbox_inches='tight')
        plt.close()
        print(f"   ğŸ“Š æ™‚ç³»åˆ—ãƒˆãƒ¬ãƒ³ãƒ‰ä¿å­˜: {output_dir / f'{model_name}_year_trend.png'}")


def generate_comparison_report(dfs_dict, model_name, output_dir, corr_results):
    """
    å¹´åº¦é–“æ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆï¼ˆMarkdownï¼‰ã‚’ç”Ÿæˆ
    
    Args:
        dfs_dict (dict): {year: DataFrame} å½¢å¼ã®è¾æ›¸
        model_name (str): ãƒ¢ãƒ‡ãƒ«å
        output_dir (Path): å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        corr_results (list): ç›¸é–¢è¨ˆç®—çµæœãƒªã‚¹ãƒˆ
    """
    years = sorted(dfs_dict.keys())
    
    report_lines = [
        f"# {model_name} - å¹´åº¦é–“SHAPå€¤æ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆ\n",
        f"**åˆ†æå¯¾è±¡å¹´åº¦**: {', '.join(map(str, years))}\n",
        f"**ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆæ—¥æ™‚**: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
        "\n---\n\n",
        "## 1. å¹´åº¦åˆ¥ä¸Šä½ç‰¹å¾´é‡\n\n"
    ]
    
    for year in years:
        df = dfs_dict[year]
        top_10 = df.nlargest(10, 'mean_abs_shap')
        
        report_lines.append(f"### {year}å¹´\n\n")
        report_lines.append("| é †ä½ | ç‰¹å¾´é‡ | Mean |SHAP| |\n")
        report_lines.append("|------|--------|-------------|\n")
        
        for i, row in enumerate(top_10.itertuples(), 1):
            report_lines.append(f"| {i} | {row.feature} | {row.mean_abs_shap:.6f} |\n")
        
        report_lines.append("\n")
    
    
    # ç›¸é–¢çµ±è¨ˆ
    if corr_results:
        report_lines.append("\n## 2. å¹´åº¦é–“ç›¸é–¢çµ±è¨ˆ\n\n")
        report_lines.append("| å¹´åº¦1 | å¹´åº¦2 | å…±é€šç‰¹å¾´é‡æ•° | Pearson r | Spearman Ï |\n")
        report_lines.append("|-------|-------|--------------|-----------|------------|\n")
        
        for result in corr_results:
            report_lines.append(
                f"| {result['year1']} | {result['year2']} | "
                f"{result['common_features']} | "
                f"{result['pearson_r']:.4f} | "
                f"{result['spearman_r']:.4f} |\n"
            )
        
        report_lines.append("\n")
    
    
    # ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æï¼ˆä¸Šæ˜‡/ä¸‹é™ï¼‰
    if len(years) >= 3:
        report_lines.append("\n## 3. ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ\n\n")
        
        # å…±é€šç‰¹å¾´é‡
        common_features = set(dfs_dict[years[0]]['feature'])
        for year in years[1:]:
            common_features &= set(dfs_dict[year]['feature'])
        
        trend_data = []
        for feature in common_features:
            values = []
            for year in years:
                df = dfs_dict[year]
                value = df[df['feature'] == feature]['mean_abs_shap'].values
                values.append(value[0] if len(value) > 0 else np.nan)
            
            # ç·šå½¢ãƒˆãƒ¬ãƒ³ãƒ‰è¨ˆç®—
            if not any(np.isnan(values)):
                slope = np.polyfit(range(len(years)), values, 1)[0]
                trend_data.append({
                    'feature': feature,
                    'slope': slope,
                    'start_value': values[0],
                    'end_value': values[-1],
                    'change_pct': ((values[-1] - values[0]) / values[0]) * 100 if values[0] != 0 else 0
                })
        
        # ä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰ Top 5
        trend_df = pd.DataFrame(trend_data).sort_values('slope', ascending=False)
        
        report_lines.append("### é‡è¦åº¦ä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰ Top 5\n\n")
        report_lines.append("| ç‰¹å¾´é‡ | å¤‰åŒ–ç‡ | é–‹å§‹å€¤ | çµ‚äº†å€¤ |\n")
        report_lines.append("|--------|--------|--------|--------|\n")
        
        for row in trend_df.head(5).itertuples():
            report_lines.append(
                f"| {row.feature} | {row.change_pct:+.2f}% | "
                f"{row.start_value:.6f} | {row.end_value:.6f} |\n"
            )
        
        report_lines.append("\n")
        
        # ä¸‹é™ãƒˆãƒ¬ãƒ³ãƒ‰ Top 5
        report_lines.append("### é‡è¦åº¦ä¸‹é™ãƒˆãƒ¬ãƒ³ãƒ‰ Top 5\n\n")
        report_lines.append("| ç‰¹å¾´é‡ | å¤‰åŒ–ç‡ | é–‹å§‹å€¤ | çµ‚äº†å€¤ |\n")
        report_lines.append("|--------|--------|--------|--------|\n")
        
        for row in trend_df.tail(5).itertuples():
            report_lines.append(
                f"| {row.feature} | {row.change_pct:+.2f}% | "
                f"{row.start_value:.6f} | {row.end_value:.6f} |\n"
            )
        
        report_lines.append("\n")
    
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
    report_path = output_dir / f'{model_name}_year_comparison_report.md'
    with open(report_path, 'w', encoding='utf-8') as f:
        f.writelines(report_lines)
    
    print(f"   ğŸ“„ æ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {report_path}")


def main():
    parser = argparse.ArgumentParser(
        description='å¹´åº¦é–“SHAPå€¤æ¯”è¼ƒåˆ†æ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=__doc__
    )
    
    parser.add_argument(
        '--model',
        type=str,
        required=True,
        help='ãƒ¢ãƒ‡ãƒ«åï¼ˆä¾‹: tokyo_turf_3ageup_longï¼‰'
    )
    
    parser.add_argument(
        '--years',
        type=int,
        nargs='+',
        required=True,
        help='æ¯”è¼ƒå¯¾è±¡å¹´åº¦ï¼ˆã‚¹ãƒšãƒ¼ã‚¹åŒºåˆ‡ã‚Šã€ä¾‹: 2021 2022 2023ï¼‰'
    )
    
    parser.add_argument(
        '--output',
        type=str,
        default=None,
        help='å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: shap_analysis/{model}/year_comparisonï¼‰'
    )
    
    parser.add_argument(
        '--top-n',
        type=int,
        default=20,
        help='è¡¨ç¤ºã™ã‚‹ä¸Šä½ç‰¹å¾´é‡æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 20ï¼‰'
    )
    
    args = parser.parse_args()
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š
    if args.output:
        output_dir = Path(args.output)
    else:
        output_dir = Path('shap_analysis') / args.model / 'year_comparison'
    
    output_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"\n{'='*60}")
    print(f"ğŸ“Š å¹´åº¦é–“SHAPå€¤æ¯”è¼ƒåˆ†æ")
    print(f"{'='*60}")
    print(f"ãƒ¢ãƒ‡ãƒ«: {args.model}")
    print(f"å¯¾è±¡å¹´åº¦: {', '.join(map(str, args.years))}")
    print(f"å‡ºåŠ›å…ˆ: {output_dir}")
    print(f"{'='*60}\n")
    
    # å„å¹´åº¦ã®SHAP CSVã‚’èª­ã¿è¾¼ã¿
    dfs_dict = {}
    
    for year in args.years:
        df = load_shap_csv(args.model, year)
        if df is not None:
            dfs_dict[year] = df
    
    if len(dfs_dict) < 2:
        print("\nâŒ ã‚¨ãƒ©ãƒ¼: æ¯”è¼ƒã«ã¯æœ€ä½2å¹´åº¦ã®ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ã§ã™")
        sys.exit(1)
    
    print(f"\nâœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(dfs_dict)}/{len(args.years)} å¹´åº¦\n")
    
    # å¹´åº¦é–“ç›¸é–¢è¨ˆç®—
    years = sorted(dfs_dict.keys())
    corr_results = []
    
    print("ğŸ” å¹´åº¦é–“ç›¸é–¢ã‚’è¨ˆç®—ä¸­...\n")
    for i in range(len(years)):
        for j in range(i+1, len(years)):
            result = calculate_year_correlation(
                dfs_dict[years[i]], 
                dfs_dict[years[j]], 
                years[i], 
                years[j]
            )
            corr_results.append(result)
            print(f"   {years[i]} vs {years[j]}: Spearman Ï = {result['spearman_r']:.4f}")
    
    print()
    
    # ãƒ—ãƒ­ãƒƒãƒˆç”Ÿæˆ
    print("ğŸ“Š ãƒ—ãƒ­ãƒƒãƒˆç”Ÿæˆä¸­...\n")
    plot_year_comparison(dfs_dict, args.model, output_dir, top_n=args.top_n)
    
    # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    print("\nğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­...\n")
    generate_comparison_report(dfs_dict, args.model, output_dir, corr_results)
    
    print(f"\n{'='*60}")
    print(f"âœ… å¹´åº¦é–“æ¯”è¼ƒåˆ†æå®Œäº†!")
    print(f"{'='*60}\n")


if __name__ == '__main__':
    main()
